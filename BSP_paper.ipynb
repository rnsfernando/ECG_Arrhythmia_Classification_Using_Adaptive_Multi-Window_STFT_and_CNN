{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75ja6zg14FST",
        "outputId": "1badf76f-9b48-4b2e-9249-c680e4c86a76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/163.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hNumPy: 2.0.2\n",
            "Python: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n"
          ]
        }
      ],
      "source": [
        "!pip install wfdb --no-deps -q\n",
        "\n",
        "\n",
        "import numpy as np, sys\n",
        "print(\"NumPy:\", np.__version__)\n",
        "print(\"Python:\", sys.version)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLLLUGJqwnbe"
      },
      "outputs": [],
      "source": [
        "!pip install -q tensorflow\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4CwKPhw4uud",
        "outputId": "83a2f409-427f-4e33-986c-6bdd36d1d182"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config ready.\n"
          ]
        }
      ],
      "source": [
        "import os, random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import wfdb\n",
        "from wfdb import processing\n",
        "\n",
        "# Reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\n",
        "\n",
        "# MIT-BIH records per class (as in paper, Table 1)\n",
        "RECORDS = {\n",
        "    \"NOR\": [100, 105, 215],\n",
        "    \"LBB\": [109, 111, 214],\n",
        "    \"RBB\": [118, 124, 212],\n",
        "    \"PVC\": [106, 233],\n",
        "    \"APC\": [207, 209, 232]\n",
        "}\n",
        "\n",
        "# Target sample counts\n",
        "TARGET_TRAIN = {\"NOR\":450, \"LBB\":450, \"RBB\":450, \"APC\":450, \"PVC\":300}\n",
        "TARGET_TEST  = {\"NOR\": 90, \"LBB\": 90, \"RBB\": 90, \"APC\": 90, \"PVC\": 60}\n",
        "\n",
        "# Sampling details\n",
        "FS = 360           # Hz\n",
        "WIN_SEC = 10       # 10-second windows\n",
        "WIN_SAMPLES = FS * WIN_SEC\n",
        "\n",
        "# Class mapping\n",
        "class_to_idx = {\"NOR\":0, \"LBB\":1, \"RBB\":2, \"PVC\":3, \"APC\":4}\n",
        "idx_to_class = {v:k for k,v in class_to_idx.items()}\n",
        "\n",
        "print(\"Config ready.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syiNxLJr5L8G",
        "outputId": "bd0738bf-1477-4bc0-9894-91bfcba7de10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOR segments extracted: 7936\n",
            "LBB segments extracted: 6600\n",
            "RBB segments extracted: 5513\n",
            "PVC segments extracted: 1347\n",
            "APC segments extracted: 1860\n"
          ]
        }
      ],
      "source": [
        "def read_signal(record_num, fs_target=FS):\n",
        "    \"\"\"Read one MIT-BIH record and resample to fs_target.\"\"\"\n",
        "    rec = wfdb.rdrecord(str(record_num), pn_dir=\"mitdb\")\n",
        "    names = [n.lower() for n in rec.sig_name]\n",
        "    if \"v5\" in names:\n",
        "        ch = names.index(\"v5\")\n",
        "    elif \"mlii\" in names:\n",
        "        ch = names.index(\"mlii\")\n",
        "    else:\n",
        "        ch = 0\n",
        "    sig = rec.p_signal[:, ch].astype(np.float32)\n",
        "    fs = int(rec.fs)\n",
        "    if fs != fs_target:\n",
        "        sig = processing.resample_sig(sig, fs, fs_target)[0]\n",
        "        fs = fs_target\n",
        "    return sig, fs\n",
        "\n",
        "def extract_segments(record_num, label, win_samples=WIN_SAMPLES):\n",
        "    \"\"\"Extract 10s windows centered on annotated beats of a given label.\"\"\"\n",
        "    sig, fs = read_signal(record_num)\n",
        "    ann = wfdb.rdann(str(record_num), \"atr\", pn_dir=\"mitdb\")\n",
        "\n",
        "    out = []\n",
        "    for idx, sym in zip(ann.sample, ann.symbol):\n",
        "        # Symbol filtering: map MIT-BIH symbols to classes\n",
        "        if label == \"NOR\" and sym == \"N\":\n",
        "            center = idx\n",
        "        elif label == \"LBB\" and sym == \"L\":\n",
        "            center = idx\n",
        "        elif label == \"RBB\" and sym == \"R\":\n",
        "            center = idx\n",
        "        elif label == \"PVC\" and sym == \"V\":\n",
        "            center = idx\n",
        "        elif label == \"APC\" and sym in [\"A\", \"a\"]:  # APC / atrial premature\n",
        "            center = idx\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        # Extract 10-second window around beat\n",
        "        start = max(center - win_samples//2, 0)\n",
        "        end = start + win_samples\n",
        "        if end <= len(sig):\n",
        "            out.append(sig[start:end])\n",
        "    return out\n",
        "\n",
        "# Build pools per class\n",
        "pool = {cls: [] for cls in RECORDS}\n",
        "for cls, recs in RECORDS.items():\n",
        "    for r in recs:\n",
        "        pool[cls].extend(extract_segments(r, cls))\n",
        "    print(cls, \"segments extracted:\", len(pool[cls]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dw1ejL_663h9",
        "outputId": "d0e9039a-80ce-4ce7-bc8c-3ddb651d415f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (2100, 3600) {'NOR': 450, 'LBB': 450, 'RBB': 450, 'PVC': 300, 'APC': 450}\n",
            "Test : (420, 3600) {'NOR': 90, 'LBB': 90, 'RBB': 90, 'PVC': 60, 'APC': 90}\n"
          ]
        }
      ],
      "source": [
        "rng = np.random.default_rng(SEED)\n",
        "\n",
        "def take_n(lst, n):\n",
        "    idx = rng.choice(len(lst), size=min(n, len(lst)), replace=False)\n",
        "    return [lst[i] for i in idx]\n",
        "\n",
        "train_X_1d, train_y = [], []\n",
        "test_X_1d,  test_y  = [], []\n",
        "\n",
        "for cls in [\"NOR\",\"LBB\",\"RBB\",\"APC\",\"PVC\"]:\n",
        "    tr_n, te_n = TARGET_TRAIN[cls], TARGET_TEST[cls]\n",
        "    cls_pool = pool[cls]\n",
        "\n",
        "    # Select train\n",
        "    train_segs = take_n(cls_pool, tr_n)\n",
        "    chosen = set(id(x) for x in train_segs)\n",
        "\n",
        "    # Remaining for test\n",
        "    remaining = [x for x in cls_pool if id(x) not in chosen]\n",
        "    test_segs = take_n(remaining, te_n)\n",
        "\n",
        "    train_X_1d += train_segs\n",
        "    train_y    += [class_to_idx[cls]] * len(train_segs)\n",
        "    test_X_1d  += test_segs\n",
        "    test_y     += [class_to_idx[cls]] * len(test_segs)\n",
        "\n",
        "# Convert to arrays\n",
        "train_X_1d = np.stack(train_X_1d)  # [N, 3600]\n",
        "test_X_1d  = np.stack(test_X_1d)\n",
        "train_y    = np.array(train_y, dtype=np.int64)\n",
        "test_y     = np.array(test_y, dtype=np.int64)\n",
        "\n",
        "print(\"Train:\", train_X_1d.shape, {k:int((train_y==v).sum()) for k,v in class_to_idx.items()})\n",
        "print(\"Test :\", test_X_1d.shape,  {k:int((test_y==v).sum()) for k,v in class_to_idx.items()})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "MD61C1VQRoPy",
        "outputId": "ff59ae8a-aa55-4810-c36f-c9d9ba53da81"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "             Train  Test  Total\n",
              "NOR            450    90    540\n",
              "LBB            450    90    540\n",
              "RBB            450    90    540\n",
              "APC            450    90    540\n",
              "PVC            300    60    360\n",
              "Grand total   2100   420   2520"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d4ca88e3-b609-47e6-b622-3219f41317ea\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train</th>\n",
              "      <th>Test</th>\n",
              "      <th>Total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>NOR</th>\n",
              "      <td>450</td>\n",
              "      <td>90</td>\n",
              "      <td>540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LBB</th>\n",
              "      <td>450</td>\n",
              "      <td>90</td>\n",
              "      <td>540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RBB</th>\n",
              "      <td>450</td>\n",
              "      <td>90</td>\n",
              "      <td>540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>APC</th>\n",
              "      <td>450</td>\n",
              "      <td>90</td>\n",
              "      <td>540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PVC</th>\n",
              "      <td>300</td>\n",
              "      <td>60</td>\n",
              "      <td>360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Grand total</th>\n",
              "      <td>2100</td>\n",
              "      <td>420</td>\n",
              "      <td>2520</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d4ca88e3-b609-47e6-b622-3219f41317ea')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d4ca88e3-b609-47e6-b622-3219f41317ea button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d4ca88e3-b609-47e6-b622-3219f41317ea');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c8921dbe-61dc-4112-b080-04c25b346884\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c8921dbe-61dc-4112-b080-04c25b346884')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c8921dbe-61dc-4112-b080-04c25b346884 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    pass\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"Train\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 688,\n        \"min\": 300,\n        \"max\": 2100,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          450,\n          300,\n          2100\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 137,\n        \"min\": 60,\n        \"max\": 420,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          90,\n          60,\n          420\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 826,\n        \"min\": 360,\n        \"max\": 2520,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          540,\n          360,\n          2520\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matches paper counts (2100 train, 420 test)\n"
          ]
        }
      ],
      "source": [
        "# === Dataset counts table (standalone cell) ===\n",
        "# Expects: train_y, test_y, class_to_idx already defined somewhere above.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Try pandas for a tidy table; fall back to plain text if not available\n",
        "try:\n",
        "    import pandas as pd\n",
        "    from IPython.display import display\n",
        "except Exception:\n",
        "    pd = None\n",
        "    display = print\n",
        "\n",
        "def to_int_labels(y):\n",
        "    y = np.asarray(y)\n",
        "    return y.argmax(axis=1) if y.ndim == 2 else y.astype(int)\n",
        "\n",
        "labels = [\"NOR\",\"LBB\",\"RBB\",\"APC\",\"PVC\"]\n",
        "ytr = to_int_labels(train_y)\n",
        "yte = to_int_labels(test_y)\n",
        "\n",
        "train_counts = {c: int(np.sum(ytr == class_to_idx[c])) for c in labels}\n",
        "test_counts  = {c: int(np.sum(yte == class_to_idx[c])) for c in labels}\n",
        "total_counts = {c: train_counts[c] + test_counts[c] for c in labels}\n",
        "\n",
        "if pd is not None:\n",
        "    df = pd.DataFrame({\n",
        "        \"Train\": [train_counts[c] for c in labels],\n",
        "        \"Test\":  [test_counts[c]  for c in labels],\n",
        "        \"Total\": [total_counts[c] for c in labels],\n",
        "    }, index=labels)\n",
        "    # Grand totals row\n",
        "    df.loc[\"Grand total\"] = df.sum(numeric_only=True)\n",
        "    display(df.astype(\"int64\"))\n",
        "else:\n",
        "    print(f\"{'Class':>6} | {'Train':>5} | {'Test':>5} | {'Total':>5}\")\n",
        "    print(\"-\"*32)\n",
        "    for c in labels:\n",
        "        print(f\"{c:>6} | {train_counts[c]:5d} | {test_counts[c]:5d} | {total_counts[c]:5d}\")\n",
        "    print(\"-\"*32)\n",
        "    print(f\"{'TOTAL':>6} | {sum(train_counts.values()):5d} | {sum(test_counts.values()):5d} | {sum(total_counts.values()):5d}\")\n",
        "\n",
        "# Optional: quick check against the paper's fixed counts if TARGET_* are defined\n",
        "try:\n",
        "    ok = all(train_counts[c]==TARGET_TRAIN[c] and test_counts[c]==TARGET_TEST[c] for c in labels)\n",
        "    print(\"Matches paper counts (2100 train, 420 test)\" if ok else \"Counts differ from paper setup.\")\n",
        "except NameError:\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9PpcdVP_AOx",
        "outputId": "e2995585-503a-4d3b-9c3e-d5e20b90c53e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train 2D: (2100, 256, 256, 1) Test 2D: (420, 256, 256, 1)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "from scipy import signal\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "STFT_NPERSEG  = 512   # paper\n",
        "STFT_NOVERLAP = 256   # reasonable 50% overlap (paper doesn’t state; this is standard)\n",
        "SPEC_SIZE      = 256   # paper: 256x256 image\n",
        "\n",
        "def stft_to_image(seg, fs=FS):\n",
        "    # Symmetric Hann per paper formula (M-1 in the denominator)\n",
        "    hann_sym = signal.windows.hann(STFT_NPERSEG, sym=True)\n",
        "\n",
        "    f, t, Z = signal.stft(\n",
        "        seg, fs=fs,\n",
        "        window=hann_sym,           # exact Hanning window\n",
        "        nperseg=STFT_NPERSEG,      # 512\n",
        "        noverlap=STFT_NOVERLAP,    # 50% overlap (paper doesn’t specify; 256 is standard)\n",
        "        nfft=STFT_NPERSEG,         # 512-point FFT\n",
        "        boundary=None,             # no zero-padding at the ends\n",
        "        padded=False               # avoid internal padding\n",
        "    )\n",
        "\n",
        "    # magnitude → dB → [0,255] grayscale\n",
        "    S = np.abs(Z) + 1e-12\n",
        "    S_db = 20 * np.log10(S / S.max())\n",
        "    S01 = (S_db - S_db.min()) / (S_db.max() - S_db.min())\n",
        "    img = Image.fromarray((S01 * 255).astype(np.uint8)).resize((SPEC_SIZE, SPEC_SIZE), Image.BICUBIC)\n",
        "    return np.array(img, np.uint8)\n",
        "\n",
        "def make_spec_set(X_1d, y):\n",
        "    imgs = [stft_to_image(seg, FS) for seg in X_1d]\n",
        "    X = np.expand_dims(np.array(imgs, np.float32) / 255.0, axis=-1)\n",
        "    Y = to_categorical(y, num_classes=5)\n",
        "    return X, Y\n",
        "\n",
        "train_X_2d, train_y_oh = make_spec_set(train_X_1d, train_y)\n",
        "test_X_2d,  test_y_oh  = make_spec_set(test_X_1d,  test_y)\n",
        "print(\"Train 2D:\", train_X_2d.shape, \"Test 2D:\", test_X_2d.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "Ei2Z5hB6NEjb",
        "outputId": "debf6102-715c-4790-fdc5-ef0b7a4ced40"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"ECG_2D_CNN\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"ECG_2D_CNN\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │           \u001b[38;5;34m136\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m13\u001b[0m)   │           \u001b[38;5;34m429\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m13\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m13\u001b[0m)     │           \u001b[38;5;34m689\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m13\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13312\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m852,032\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m325\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">429</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">689</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13312</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">852,032</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m853,611\u001b[0m (3.26 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">853,611</span> (3.26 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m853,611\u001b[0m (3.26 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">853,611</span> (3.26 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def make_2d_cnn(input_shape=(SPEC_SIZE, SPEC_SIZE, 1), num_classes=5):\n",
        "    x = inp = keras.Input(shape=input_shape)\n",
        "    x = layers.Conv2D(8, (4,4), activation='relu', padding='same')(x)\n",
        "    x = layers.MaxPooling2D((2,2))(x)\n",
        "    x = layers.Conv2D(13, (2,2), activation='relu', padding='same')(x)\n",
        "    x = layers.MaxPooling2D((2,2))(x)\n",
        "    x = layers.Conv2D(13, (2,2), activation='relu', padding='same')(x)\n",
        "    x = layers.MaxPooling2D((2,2))(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(64, activation='relu')(x)  # width not fixed in paper; 64 keeps it small and stable\n",
        "    out = layers.Dense(num_classes, activation='softmax')(x)\n",
        "    return keras.Model(inp, out, name=\"ECG_2D_CNN\")\n",
        "\n",
        "model_2d = make_2d_cnn()\n",
        "model_2d.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yO7FJ01OMO0",
        "outputId": "87f89668-57e2-41b6-c785-128e0e1f1986"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.8630 - loss: 0.6687 - val_accuracy: 0.8310 - val_loss: 0.6357\n",
            "Epoch 2/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 225ms/step - accuracy: 0.9102 - loss: 0.2533 - val_accuracy: 0.8952 - val_loss: 0.3231\n",
            "Epoch 3/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 225ms/step - accuracy: 0.9320 - loss: 0.1881 - val_accuracy: 0.9214 - val_loss: 0.2301\n",
            "Epoch 4/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 223ms/step - accuracy: 0.9542 - loss: 0.1227 - val_accuracy: 0.9643 - val_loss: 0.1229\n",
            "Epoch 5/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 228ms/step - accuracy: 0.9846 - loss: 0.0659 - val_accuracy: 0.9690 - val_loss: 0.1368\n",
            "Epoch 6/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 225ms/step - accuracy: 0.9806 - loss: 0.0729 - val_accuracy: 0.9714 - val_loss: 0.1108\n",
            "Epoch 7/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 226ms/step - accuracy: 0.9884 - loss: 0.0500 - val_accuracy: 0.9643 - val_loss: 0.1138\n",
            "Epoch 8/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 238ms/step - accuracy: 0.9928 - loss: 0.0388 - val_accuracy: 0.9762 - val_loss: 0.0939\n",
            "Epoch 9/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 244ms/step - accuracy: 0.9954 - loss: 0.0302 - val_accuracy: 0.9762 - val_loss: 0.0803\n",
            "Epoch 10/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 225ms/step - accuracy: 0.9977 - loss: 0.0262 - val_accuracy: 0.9762 - val_loss: 0.0826\n",
            "Epoch 11/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 226ms/step - accuracy: 0.9980 - loss: 0.0247 - val_accuracy: 0.9738 - val_loss: 0.0798\n",
            "Epoch 12/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 227ms/step - accuracy: 0.9981 - loss: 0.0208 - val_accuracy: 0.9738 - val_loss: 0.0816\n",
            "Epoch 13/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 232ms/step - accuracy: 0.9989 - loss: 0.0191 - val_accuracy: 0.9738 - val_loss: 0.0797\n",
            "Epoch 14/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 226ms/step - accuracy: 0.9992 - loss: 0.0176 - val_accuracy: 0.9738 - val_loss: 0.0766\n",
            "Epoch 15/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 228ms/step - accuracy: 1.0000 - loss: 0.0167 - val_accuracy: 0.9786 - val_loss: 0.0745\n",
            "Epoch 16/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 225ms/step - accuracy: 1.0000 - loss: 0.0158 - val_accuracy: 0.9786 - val_loss: 0.0750\n",
            "Epoch 17/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 229ms/step - accuracy: 1.0000 - loss: 0.0147 - val_accuracy: 0.9786 - val_loss: 0.0725\n",
            "Epoch 18/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 225ms/step - accuracy: 1.0000 - loss: 0.0137 - val_accuracy: 0.9786 - val_loss: 0.0703\n",
            "Epoch 19/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 225ms/step - accuracy: 1.0000 - loss: 0.0129 - val_accuracy: 0.9786 - val_loss: 0.0691\n",
            "Epoch 20/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 226ms/step - accuracy: 1.0000 - loss: 0.0121 - val_accuracy: 0.9786 - val_loss: 0.0696\n",
            "Epoch 21/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 225ms/step - accuracy: 1.0000 - loss: 0.0113 - val_accuracy: 0.9810 - val_loss: 0.0674\n",
            "Epoch 22/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 0.0107 - val_accuracy: 0.9786 - val_loss: 0.0681\n",
            "Epoch 23/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 225ms/step - accuracy: 1.0000 - loss: 0.0102 - val_accuracy: 0.9810 - val_loss: 0.0667\n",
            "Epoch 24/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 225ms/step - accuracy: 1.0000 - loss: 0.0096 - val_accuracy: 0.9810 - val_loss: 0.0657\n",
            "Epoch 25/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 237ms/step - accuracy: 1.0000 - loss: 0.0092 - val_accuracy: 0.9810 - val_loss: 0.0661\n",
            "Epoch 26/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 276ms/step - accuracy: 1.0000 - loss: 0.0088 - val_accuracy: 0.9810 - val_loss: 0.0653\n",
            "Epoch 27/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 296ms/step - accuracy: 1.0000 - loss: 0.0084 - val_accuracy: 0.9810 - val_loss: 0.0641\n",
            "Epoch 28/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 223ms/step - accuracy: 1.0000 - loss: 0.0081 - val_accuracy: 0.9810 - val_loss: 0.0641\n",
            "Epoch 29/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 223ms/step - accuracy: 1.0000 - loss: 0.0077 - val_accuracy: 0.9810 - val_loss: 0.0640\n",
            "Epoch 30/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 223ms/step - accuracy: 1.0000 - loss: 0.0074 - val_accuracy: 0.9810 - val_loss: 0.0634\n",
            "Epoch 31/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.9810 - val_loss: 0.0629\n",
            "Epoch 32/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 222ms/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 0.9810 - val_loss: 0.0624\n",
            "Epoch 33/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 231ms/step - accuracy: 1.0000 - loss: 0.0066 - val_accuracy: 0.9810 - val_loss: 0.0620\n",
            "Epoch 34/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 274ms/step - accuracy: 1.0000 - loss: 0.0064 - val_accuracy: 0.9810 - val_loss: 0.0616\n",
            "Epoch 35/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.9810 - val_loss: 0.0610\n",
            "Epoch 36/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 237ms/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 0.9810 - val_loss: 0.0606\n",
            "Epoch 37/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 223ms/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 0.9810 - val_loss: 0.0604\n",
            "Epoch 38/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 222ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.9810 - val_loss: 0.0603\n",
            "Epoch 39/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 223ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.9810 - val_loss: 0.0602\n",
            "Epoch 40/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.9810 - val_loss: 0.0600\n",
            "Epoch 41/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 221ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.9833 - val_loss: 0.0598\n",
            "Epoch 42/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 235ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.9833 - val_loss: 0.0596\n",
            "Epoch 43/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 227ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.9833 - val_loss: 0.0594\n",
            "Epoch 44/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 222ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.9833 - val_loss: 0.0594\n",
            "Epoch 45/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 223ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.9833 - val_loss: 0.0593\n",
            "Epoch 46/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 223ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.9833 - val_loss: 0.0593\n",
            "Epoch 47/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 223ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.9833 - val_loss: 0.0592\n",
            "Epoch 48/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.9833 - val_loss: 0.0592\n",
            "Epoch 49/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 223ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.9833 - val_loss: 0.0590\n",
            "Epoch 50/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 223ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.9833 - val_loss: 0.0589\n",
            "Epoch 51/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 233ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.9833 - val_loss: 0.0588\n",
            "Epoch 52/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 243ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.9810 - val_loss: 0.0588\n",
            "Epoch 53/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 221ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.9810 - val_loss: 0.0588\n",
            "Epoch 54/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 223ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.9810 - val_loss: 0.0588\n",
            "Epoch 55/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.9810 - val_loss: 0.0588\n",
            "Epoch 56/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.9810 - val_loss: 0.0588\n",
            "Epoch 57/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 225ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.9810 - val_loss: 0.0588\n",
            "Epoch 58/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 222ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9810 - val_loss: 0.0587\n",
            "Epoch 59/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 258ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.9810 - val_loss: 0.0586\n",
            "Epoch 60/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 237ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.9810 - val_loss: 0.0586\n",
            "Epoch 61/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 244ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.9810 - val_loss: 0.0586\n",
            "Epoch 62/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 225ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9810 - val_loss: 0.0585\n",
            "Epoch 63/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 225ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9810 - val_loss: 0.0585\n",
            "Epoch 64/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.9810 - val_loss: 0.0585\n",
            "Epoch 65/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.9810 - val_loss: 0.0585\n",
            "Epoch 66/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 227ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.9810 - val_loss: 0.0585\n",
            "Epoch 67/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9810 - val_loss: 0.0585\n",
            "Epoch 68/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 236ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9810 - val_loss: 0.0584\n",
            "Epoch 69/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 277ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9810 - val_loss: 0.0584\n",
            "Epoch 70/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9810 - val_loss: 0.0584\n",
            "Epoch 71/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 225ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9810 - val_loss: 0.0584\n",
            "Epoch 72/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 227ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9810 - val_loss: 0.0584\n",
            "Epoch 73/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9810 - val_loss: 0.0584\n",
            "Epoch 74/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9810 - val_loss: 0.0583\n",
            "Epoch 75/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 226ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9810 - val_loss: 0.0583\n",
            "Epoch 76/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 266ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9810 - val_loss: 0.0583\n",
            "Epoch 77/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 276ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9833 - val_loss: 0.0583\n",
            "Epoch 78/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9833 - val_loss: 0.0583\n",
            "Epoch 79/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9833 - val_loss: 0.0583\n",
            "Epoch 80/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9833 - val_loss: 0.0582\n",
            "Epoch 81/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9833 - val_loss: 0.0583\n",
            "Epoch 82/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9833 - val_loss: 0.0583\n",
            "Epoch 83/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 225ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9833 - val_loss: 0.0583\n",
            "Epoch 84/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 272ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9833 - val_loss: 0.0583\n",
            "Epoch 85/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 229ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9833 - val_loss: 0.0583\n",
            "Epoch 86/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9833 - val_loss: 0.0583\n",
            "Epoch 87/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 223ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9833 - val_loss: 0.0582\n",
            "Epoch 88/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 225ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9833 - val_loss: 0.0583\n",
            "Epoch 89/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 225ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9833 - val_loss: 0.0583\n",
            "Epoch 90/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 223ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9833 - val_loss: 0.0584\n",
            "Epoch 91/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 223ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9833 - val_loss: 0.0584\n",
            "Epoch 92/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 223ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9833 - val_loss: 0.0586\n",
            "Epoch 93/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 274ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9833 - val_loss: 0.0588\n",
            "Epoch 94/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 227ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9810 - val_loss: 0.0592\n",
            "Epoch 95/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 223ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9810 - val_loss: 0.0596\n",
            "Epoch 96/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 223ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9810 - val_loss: 0.0607\n",
            "Epoch 97/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 225ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9810 - val_loss: 0.0620\n",
            "Epoch 98/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 223ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9762 - val_loss: 0.0643\n",
            "Epoch 99/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 230ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9762 - val_loss: 0.0675\n",
            "Epoch 100/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9762 - val_loss: 0.0715\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "LR = 0.001\n",
        "BATCH = 500\n",
        "EPOCHS = 100\n",
        "\n",
        "model_2d.compile(optimizer=keras.optimizers.Adam(learning_rate=LR),\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "hist_2d = model_2d.fit(\n",
        "    train_X_2d, train_y_oh,\n",
        "    validation_data=(test_X_2d, test_y_oh),\n",
        "    epochs=EPOCHS, batch_size=BATCH, verbose=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "GhrEGx6T226e",
        "outputId": "0181211e-2ef3-495a-8873-1c7f4b01e928"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'hist_2d' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2376610974.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist_2d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mvl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist_2d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'hist_2d' is not defined"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "tr = np.array(hist_2d.history['accuracy'])\n",
        "vl = np.array(hist_2d.history.get('val_accuracy', []))\n",
        "\n",
        "print(f\"Final train acc     : {tr[-1]*100:.2f}%\")\n",
        "if vl.size:\n",
        "    print(f\"Final val acc       : {vl[-1]*100:.2f}%\")\n",
        "    print(f\"Average train acc   : {tr.mean()*100:.2f}%\")\n",
        "    print(f\"Average val acc     : {vl.mean()*100:.2f}%\")\n",
        "    print(f\"Best val acc        : {vl.max()*100:.2f}%  (epoch {vl.argmax()+1})\")\n",
        "else:\n",
        "    print(f\"Average train acc   : {tr.mean()*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UpzA2Sp4ydl"
      },
      "source": [
        "## FULL CODE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "f2misHgR4yFp",
        "outputId": "46a3f92c-26cb-4f46-d360-759e3129be4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Config ready.\n",
            "NOR: segments extracted = 7936\n",
            "LBB: segments extracted = 6600\n",
            "RBB: segments extracted = 5513\n",
            "PVC: segments extracted = 1347\n",
            "APC: segments extracted = 1860\n",
            "Train: (2100, 3600) {'NOR': 450, 'LBB': 450, 'RBB': 450, 'PVC': 300, 'APC': 450}\n",
            "Test : (420, 3600) {'NOR': 90, 'LBB': 90, 'RBB': 90, 'PVC': 60, 'APC': 90}\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Train\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 67,\n        \"min\": 300,\n        \"max\": 450,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          300,\n          450\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13,\n        \"min\": 60,\n        \"max\": 90,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          60,\n          90\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 80,\n        \"min\": 360,\n        \"max\": 540,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          360,\n          540\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-e2d395fa-7a83-4154-bbae-6fc3a6354952\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train</th>\n",
              "      <th>Test</th>\n",
              "      <th>Total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>NOR</th>\n",
              "      <td>450</td>\n",
              "      <td>90</td>\n",
              "      <td>540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LBB</th>\n",
              "      <td>450</td>\n",
              "      <td>90</td>\n",
              "      <td>540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RBB</th>\n",
              "      <td>450</td>\n",
              "      <td>90</td>\n",
              "      <td>540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PVC</th>\n",
              "      <td>300</td>\n",
              "      <td>60</td>\n",
              "      <td>360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>APC</th>\n",
              "      <td>450</td>\n",
              "      <td>90</td>\n",
              "      <td>540</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e2d395fa-7a83-4154-bbae-6fc3a6354952')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e2d395fa-7a83-4154-bbae-6fc3a6354952 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e2d395fa-7a83-4154-bbae-6fc3a6354952');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-df210290-9ad2-4a4f-a555-0d2e09307d27\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-df210290-9ad2-4a4f-a555-0d2e09307d27')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-df210290-9ad2-4a4f-a555-0d2e09307d27 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_aa078736-ced4-4e8d-8663-d5284d054334\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_aa078736-ced4-4e8d-8663-d5284d054334 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     Train  Test  Total\n",
              "NOR    450    90    540\n",
              "LBB    450    90    540\n",
              "RBB    450    90    540\n",
              "PVC    300    60    360\n",
              "APC    450    90    540"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train 2D: (2100, 256, 256, 1) Test 2D: (420, 256, 256, 1)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"ECG_2D_CNN\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"ECG_2D_CNN\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">429</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">689</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13312</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">852,032</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │           \u001b[38;5;34m136\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_9 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m13\u001b[0m)   │           \u001b[38;5;34m429\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_10 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m13\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m13\u001b[0m)     │           \u001b[38;5;34m689\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_11 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m13\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13312\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m852,032\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m325\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">853,611</span> (3.26 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m853,611\u001b[0m (3.26 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">853,611</span> (3.26 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m853,611\u001b[0m (3.26 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 114ms/step - accuracy: 0.2017 - loss: 1.6367 - val_accuracy: 0.2143 - val_loss: 1.5947 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.2739 - loss: 1.5865 - val_accuracy: 0.2786 - val_loss: 1.5664 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.3497 - loss: 1.5447 - val_accuracy: 0.3714 - val_loss: 1.4855 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.4620 - loss: 1.4104 - val_accuracy: 0.5571 - val_loss: 1.2169 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.5746 - loss: 1.1659 - val_accuracy: 0.5714 - val_loss: 1.0646 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.6633 - loss: 0.9518 - val_accuracy: 0.7071 - val_loss: 0.8861 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.7259 - loss: 0.7989 - val_accuracy: 0.7929 - val_loss: 0.7355 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.7885 - loss: 0.6735 - val_accuracy: 0.7952 - val_loss: 0.6394 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.8354 - loss: 0.5338 - val_accuracy: 0.8595 - val_loss: 0.5298 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.8514 - loss: 0.4800 - val_accuracy: 0.8619 - val_loss: 0.4868 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8681 - loss: 0.4201 - val_accuracy: 0.8619 - val_loss: 0.4569 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8816 - loss: 0.3705 - val_accuracy: 0.8524 - val_loss: 0.4340 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8960 - loss: 0.3342 - val_accuracy: 0.8762 - val_loss: 0.3923 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9152 - loss: 0.2938 - val_accuracy: 0.8976 - val_loss: 0.3451 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9211 - loss: 0.2647 - val_accuracy: 0.9095 - val_loss: 0.3215 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9322 - loss: 0.2465 - val_accuracy: 0.9000 - val_loss: 0.3626 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9321 - loss: 0.2411 - val_accuracy: 0.9214 - val_loss: 0.3084 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9568 - loss: 0.1914 - val_accuracy: 0.9262 - val_loss: 0.2650 - learning_rate: 0.0010\n",
            "Epoch 19/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9577 - loss: 0.1678 - val_accuracy: 0.9238 - val_loss: 0.2744 - learning_rate: 0.0010\n",
            "Epoch 20/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9563 - loss: 0.1682 - val_accuracy: 0.9190 - val_loss: 0.2827 - learning_rate: 0.0010\n",
            "Epoch 21/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9577 - loss: 0.1602 - val_accuracy: 0.9310 - val_loss: 0.2496 - learning_rate: 0.0010\n",
            "Epoch 22/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9684 - loss: 0.1366 - val_accuracy: 0.9500 - val_loss: 0.1915 - learning_rate: 0.0010\n",
            "Epoch 23/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9746 - loss: 0.1140 - val_accuracy: 0.9452 - val_loss: 0.1842 - learning_rate: 0.0010\n",
            "Epoch 24/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9788 - loss: 0.1002 - val_accuracy: 0.9429 - val_loss: 0.1779 - learning_rate: 0.0010\n",
            "Epoch 25/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9787 - loss: 0.0942 - val_accuracy: 0.9381 - val_loss: 0.1753 - learning_rate: 0.0010\n",
            "Epoch 26/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9760 - loss: 0.1018 - val_accuracy: 0.9524 - val_loss: 0.1669 - learning_rate: 0.0010\n",
            "Epoch 27/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.9739 - loss: 0.0943 - val_accuracy: 0.9429 - val_loss: 0.1924 - learning_rate: 0.0010\n",
            "Epoch 28/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9759 - loss: 0.0903 - val_accuracy: 0.9405 - val_loss: 0.1950 - learning_rate: 0.0010\n",
            "Epoch 29/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9800 - loss: 0.0742 - val_accuracy: 0.9381 - val_loss: 0.2101 - learning_rate: 0.0010\n",
            "Epoch 30/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9787 - loss: 0.0775 - val_accuracy: 0.9452 - val_loss: 0.1705 - learning_rate: 0.0010\n",
            "Epoch 31/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9797 - loss: 0.0758 - val_accuracy: 0.9429 - val_loss: 0.1693 - learning_rate: 0.0010\n",
            "Epoch 32/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9868 - loss: 0.0549 - val_accuracy: 0.9548 - val_loss: 0.1407 - learning_rate: 5.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9895 - loss: 0.0460 - val_accuracy: 0.9619 - val_loss: 0.1320 - learning_rate: 5.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9905 - loss: 0.0397 - val_accuracy: 0.9595 - val_loss: 0.1322 - learning_rate: 5.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9927 - loss: 0.0374 - val_accuracy: 0.9595 - val_loss: 0.1326 - learning_rate: 5.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9954 - loss: 0.0360 - val_accuracy: 0.9619 - val_loss: 0.1302 - learning_rate: 5.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9953 - loss: 0.0343 - val_accuracy: 0.9619 - val_loss: 0.1294 - learning_rate: 5.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9960 - loss: 0.0327 - val_accuracy: 0.9619 - val_loss: 0.1287 - learning_rate: 5.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9970 - loss: 0.0311 - val_accuracy: 0.9619 - val_loss: 0.1285 - learning_rate: 5.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9970 - loss: 0.0292 - val_accuracy: 0.9619 - val_loss: 0.1281 - learning_rate: 5.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9971 - loss: 0.0274 - val_accuracy: 0.9619 - val_loss: 0.1286 - learning_rate: 5.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9972 - loss: 0.0258 - val_accuracy: 0.9619 - val_loss: 0.1286 - learning_rate: 5.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9972 - loss: 0.0243 - val_accuracy: 0.9619 - val_loss: 0.1280 - learning_rate: 5.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9972 - loss: 0.0231 - val_accuracy: 0.9619 - val_loss: 0.1274 - learning_rate: 5.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9974 - loss: 0.0221 - val_accuracy: 0.9619 - val_loss: 0.1268 - learning_rate: 5.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9974 - loss: 0.0210 - val_accuracy: 0.9619 - val_loss: 0.1260 - learning_rate: 5.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9974 - loss: 0.0201 - val_accuracy: 0.9619 - val_loss: 0.1249 - learning_rate: 5.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9977 - loss: 0.0192 - val_accuracy: 0.9619 - val_loss: 0.1235 - learning_rate: 5.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9988 - loss: 0.0183 - val_accuracy: 0.9619 - val_loss: 0.1228 - learning_rate: 5.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9990 - loss: 0.0175 - val_accuracy: 0.9643 - val_loss: 0.1226 - learning_rate: 5.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9990 - loss: 0.0167 - val_accuracy: 0.9643 - val_loss: 0.1219 - learning_rate: 5.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9990 - loss: 0.0161 - val_accuracy: 0.9643 - val_loss: 0.1208 - learning_rate: 5.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9990 - loss: 0.0154 - val_accuracy: 0.9643 - val_loss: 0.1200 - learning_rate: 5.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.0148 - val_accuracy: 0.9643 - val_loss: 0.1191 - learning_rate: 5.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0143 - val_accuracy: 0.9643 - val_loss: 0.1181 - learning_rate: 5.0000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.0137 - val_accuracy: 0.9690 - val_loss: 0.1175 - learning_rate: 5.0000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0132 - val_accuracy: 0.9690 - val_loss: 0.1172 - learning_rate: 5.0000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0128 - val_accuracy: 0.9690 - val_loss: 0.1168 - learning_rate: 5.0000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0123 - val_accuracy: 0.9690 - val_loss: 0.1162 - learning_rate: 5.0000e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0119 - val_accuracy: 0.9690 - val_loss: 0.1159 - learning_rate: 5.0000e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0115 - val_accuracy: 0.9690 - val_loss: 0.1148 - learning_rate: 5.0000e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.0111 - val_accuracy: 0.9690 - val_loss: 0.1147 - learning_rate: 5.0000e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.0108 - val_accuracy: 0.9690 - val_loss: 0.1143 - learning_rate: 5.0000e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0104 - val_accuracy: 0.9690 - val_loss: 0.1142 - learning_rate: 5.0000e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.0101 - val_accuracy: 0.9690 - val_loss: 0.1137 - learning_rate: 5.0000e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0098 - val_accuracy: 0.9690 - val_loss: 0.1122 - learning_rate: 5.0000e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0095 - val_accuracy: 0.9690 - val_loss: 0.1119 - learning_rate: 5.0000e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0093 - val_accuracy: 0.9690 - val_loss: 0.1110 - learning_rate: 5.0000e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9997 - loss: 0.0090 - val_accuracy: 0.9667 - val_loss: 0.1096 - learning_rate: 5.0000e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9997 - loss: 0.0088 - val_accuracy: 0.9667 - val_loss: 0.1084 - learning_rate: 5.0000e-04\n",
            "Epoch 71/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9997 - loss: 0.0086 - val_accuracy: 0.9667 - val_loss: 0.1077 - learning_rate: 5.0000e-04\n",
            "Epoch 72/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.9997 - loss: 0.0085 - val_accuracy: 0.9667 - val_loss: 0.1077 - learning_rate: 5.0000e-04\n",
            "Epoch 73/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9997 - loss: 0.0084 - val_accuracy: 0.9643 - val_loss: 0.1090 - learning_rate: 5.0000e-04\n",
            "Epoch 74/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9997 - loss: 0.0083 - val_accuracy: 0.9619 - val_loss: 0.1114 - learning_rate: 5.0000e-04\n",
            "Epoch 75/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9997 - loss: 0.0083 - val_accuracy: 0.9619 - val_loss: 0.1147 - learning_rate: 5.0000e-04\n",
            "Epoch 76/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9997 - loss: 0.0083 - val_accuracy: 0.9619 - val_loss: 0.1172 - learning_rate: 5.0000e-04\n",
            "Epoch 77/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9993 - loss: 0.0078 - val_accuracy: 0.9667 - val_loss: 0.0965 - learning_rate: 2.5000e-04\n",
            "Epoch 78/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9983 - loss: 0.0085 - val_accuracy: 0.9690 - val_loss: 0.1069 - learning_rate: 2.5000e-04\n",
            "Epoch 79/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9996 - loss: 0.0082 - val_accuracy: 0.9690 - val_loss: 0.1102 - learning_rate: 2.5000e-04\n",
            "Epoch 80/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9983 - loss: 0.0095 - val_accuracy: 0.9643 - val_loss: 0.1080 - learning_rate: 2.5000e-04\n",
            "Epoch 81/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9983 - loss: 0.0092 - val_accuracy: 0.9690 - val_loss: 0.1105 - learning_rate: 2.5000e-04\n",
            "Epoch 82/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9996 - loss: 0.0083 - val_accuracy: 0.9667 - val_loss: 0.1129 - learning_rate: 2.5000e-04\n",
            "Epoch 83/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.9997 - loss: 0.0078 - val_accuracy: 0.9738 - val_loss: 0.0961 - learning_rate: 1.2500e-04\n",
            "Epoch 84/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0084 - val_accuracy: 0.9738 - val_loss: 0.0819 - learning_rate: 1.2500e-04\n",
            "Epoch 85/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9999 - loss: 0.0056 - val_accuracy: 0.9786 - val_loss: 0.0830 - learning_rate: 1.2500e-04\n",
            "Epoch 86/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.9762 - val_loss: 0.0849 - learning_rate: 1.2500e-04\n",
            "Epoch 87/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.9762 - val_loss: 0.0838 - learning_rate: 1.2500e-04\n",
            "Epoch 88/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.9762 - val_loss: 0.0836 - learning_rate: 1.2500e-04\n",
            "Epoch 89/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.9762 - val_loss: 0.0833 - learning_rate: 1.2500e-04\n",
            "Epoch 90/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.9714 - val_loss: 0.0845 - learning_rate: 6.2500e-05\n",
            "Epoch 91/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.9738 - val_loss: 0.0831 - learning_rate: 6.2500e-05\n",
            "Epoch 92/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.9738 - val_loss: 0.0836 - learning_rate: 6.2500e-05\n",
            "Epoch 93/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.9738 - val_loss: 0.0834 - learning_rate: 6.2500e-05\n",
            "Epoch 94/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.9738 - val_loss: 0.0834 - learning_rate: 6.2500e-05\n",
            "Epoch 95/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.9738 - val_loss: 0.0838 - learning_rate: 3.1250e-05\n",
            "Epoch 96/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.9738 - val_loss: 0.0837 - learning_rate: 3.1250e-05\n",
            "Epoch 97/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.9738 - val_loss: 0.0837 - learning_rate: 3.1250e-05\n",
            "Epoch 98/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.9738 - val_loss: 0.0837 - learning_rate: 3.1250e-05\n",
            "Epoch 99/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.9738 - val_loss: 0.0837 - learning_rate: 3.1250e-05\n",
            "Epoch 100/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.9738 - val_loss: 0.0838 - learning_rate: 1.5625e-05\n",
            "\n",
            "Final train acc: 100.00% | Final val acc: 97.38%\n",
            "Avg  train acc : 94.73% | Avg  val acc : 92.11%\n",
            "Best val acc   : 97.86% (epoch 85)\n",
            "Final loss     : train 0.0035 | val 0.0838\n",
            "\n",
            "[Paper metrics] Test accuracy: 97.38% | Cross-entropy: 0.083791\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         NOR     0.9890    1.0000    0.9945        90\n",
            "         LBB     0.9886    0.9667    0.9775        90\n",
            "         RBB     0.9674    0.9889    0.9780        90\n",
            "         PVC     0.9333    0.9333    0.9333        60\n",
            "         APC     0.9775    0.9667    0.9721        90\n",
            "\n",
            "    accuracy                         0.9738       420\n",
            "   macro avg     0.9712    0.9711    0.9711       420\n",
            "weighted avg     0.9739    0.9738    0.9738       420\n",
            "\n",
            "Confusion matrix:\n",
            " [[90  0  0  0  0]\n",
            " [ 0 87  1  2  0]\n",
            " [ 0  0 89  0  1]\n",
            " [ 1  0  2 56  1]\n",
            " [ 0  1  0  2 87]]\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# ECG Arrhythmia Classification (Paper-faithful full pipeline)\n",
        "# MIT-BIH: STFT (512 Hann) -> 256x256 spectrogram -> 2D-CNN\n",
        "# ============================================================\n",
        "\n",
        "# -------------------------\n",
        "# 0) Config & dependencies\n",
        "# -------------------------\n",
        "import os, random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import wfdb\n",
        "from wfdb import processing\n",
        "\n",
        "# Reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\n",
        "\n",
        "# Records per class (from the paper)\n",
        "RECORDS = {\n",
        "    \"NOR\": [100, 105, 215],\n",
        "    \"LBB\": [109, 111, 214],\n",
        "    \"RBB\": [118, 124, 212],\n",
        "    \"PVC\": [106, 233],\n",
        "    \"APC\": [207, 209, 232]\n",
        "}\n",
        "\n",
        "# Target split (paper): NOR/LBB/RBB/APC (450 train, 90 test), PVC (300 train, 60 test)\n",
        "TARGET_TRAIN = {\"NOR\":450, \"LBB\":450, \"RBB\":450, \"APC\":450, \"PVC\":300}\n",
        "TARGET_TEST  = {\"NOR\": 90, \"LBB\": 90, \"RBB\": 90, \"APC\": 90, \"PVC\": 60}\n",
        "\n",
        "# Sampling\n",
        "FS = 360           # Hz\n",
        "WIN_SEC = 10       # seconds\n",
        "WIN_SAMPLES = FS * WIN_SEC\n",
        "\n",
        "# STFT / Spectrogram (paper/stable choices)\n",
        "STFT_NPERSEG  = 512   # paper window size\n",
        "STFT_NOVERLAP = 256   # 50% overlap (paper not explicit; standard)\n",
        "SPEC_SIZE     = 256   # spectrogram image size (HxW)\n",
        "\n",
        "# Class mapping\n",
        "class_to_idx = {\"NOR\":0, \"LBB\":1, \"RBB\":2, \"PVC\":3, \"APC\":4}\n",
        "idx_to_class = {v:k for k,v in class_to_idx.items()}\n",
        "\n",
        "print(\"Config ready.\")\n",
        "\n",
        "# ------------------------------------------\n",
        "# 1) Read signals & extract labeled segments\n",
        "# ------------------------------------------\n",
        "def read_signal(record_num, fs_target=FS):\n",
        "    \"\"\"Read one MIT-BIH record and resample to fs_target.\"\"\"\n",
        "    rec = wfdb.rdrecord(str(record_num), pn_dir=\"mitdb\")\n",
        "    names = [n.lower() for n in rec.sig_name]\n",
        "    if \"v5\" in names:\n",
        "        ch = names.index(\"v5\")\n",
        "    elif \"mlii\" in names:\n",
        "        ch = names.index(\"mlii\")\n",
        "    else:\n",
        "        ch = 0\n",
        "    sig = rec.p_signal[:, ch].astype(np.float32)\n",
        "    fs = int(rec.fs)\n",
        "    if fs != fs_target:\n",
        "        sig = processing.resample_sig(sig, fs, fs_target)[0]\n",
        "        fs = fs_target\n",
        "    return sig, fs\n",
        "\n",
        "def extract_segments(record_num, label, win_samples=WIN_SAMPLES):\n",
        "    \"\"\"\n",
        "    Extract 10s windows centered on annotated beats of a given label.\n",
        "\n",
        "    Label mapping (MIT-BIH symbols):\n",
        "      NOR: 'N'\n",
        "      LBB: 'L'\n",
        "      RBB: 'R'\n",
        "      PVC: 'V'\n",
        "      APC: 'A' or 'a'\n",
        "    \"\"\"\n",
        "    sig, fs = read_signal(record_num)\n",
        "    ann = wfdb.rdann(str(record_num), \"atr\", pn_dir=\"mitdb\")\n",
        "\n",
        "    out = []\n",
        "    for idx, sym in zip(ann.sample, ann.symbol):\n",
        "        if   label == \"NOR\" and sym == \"N\": center = idx\n",
        "        elif label == \"LBB\" and sym == \"L\": center = idx\n",
        "        elif label == \"RBB\" and sym == \"R\": center = idx\n",
        "        elif label == \"PVC\" and sym == \"V\": center = idx\n",
        "        elif label == \"APC\" and sym in (\"A\",\"a\"): center = idx\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        # 10s window centered on the beat\n",
        "        start = max(center - win_samples//2, 0)\n",
        "        end   = start + win_samples\n",
        "        if end <= len(sig):\n",
        "            out.append(sig[start:end])\n",
        "    return out\n",
        "\n",
        "# Build pools per class\n",
        "pool = {cls: [] for cls in RECORDS}\n",
        "for cls, recs in RECORDS.items():\n",
        "    for r in recs:\n",
        "        pool[cls].extend(extract_segments(r, cls))\n",
        "    print(f\"{cls}: segments extracted = {len(pool[cls])}\")\n",
        "\n",
        "# ---------------------------------------\n",
        "# 2) Paper's fixed train/test split (1D)\n",
        "# ---------------------------------------\n",
        "rng = np.random.default_rng(SEED)\n",
        "\n",
        "def take_n(lst, n):\n",
        "    idx = rng.choice(len(lst), size=min(n, len(lst)), replace=False)\n",
        "    return [lst[i] for i in idx]\n",
        "\n",
        "train_X_1d, train_y = [], []\n",
        "test_X_1d,  test_y  = [], []\n",
        "\n",
        "for cls in [\"NOR\",\"LBB\",\"RBB\",\"APC\",\"PVC\"]:\n",
        "    tr_n, te_n = TARGET_TRAIN[cls], TARGET_TEST[cls]\n",
        "    cls_pool = pool[cls]\n",
        "\n",
        "    train_segs = take_n(cls_pool, tr_n)\n",
        "    chosen = set(id(x) for x in train_segs)\n",
        "\n",
        "    remaining = [x for x in cls_pool if id(x) not in chosen]\n",
        "    test_segs = take_n(remaining, te_n)\n",
        "\n",
        "    train_X_1d += train_segs\n",
        "    train_y    += [class_to_idx[cls]] * len(train_segs)\n",
        "    test_X_1d  += test_segs\n",
        "    test_y     += [class_to_idx[cls]] * len(test_segs)\n",
        "\n",
        "# Arrays\n",
        "train_X_1d = np.stack(train_X_1d)  # [N, 3600]\n",
        "test_X_1d  = np.stack(test_X_1d)\n",
        "train_y    = np.array(train_y, dtype=np.int64)\n",
        "test_y     = np.array(test_y, dtype=np.int64)\n",
        "\n",
        "print(\"Train:\", train_X_1d.shape, {k:int((train_y==v).sum()) for k,v in class_to_idx.items()})\n",
        "print(\"Test :\", test_X_1d.shape,  {k:int((test_y==v).sum()) for k,v in class_to_idx.items()})\n",
        "\n",
        "# Optional: small counts table\n",
        "try:\n",
        "    import pandas as pd\n",
        "    df = pd.DataFrame({\n",
        "        \"Train\":[int((train_y==class_to_idx[c]).sum()) for c in class_to_idx],\n",
        "        \"Test\":[int((test_y==class_to_idx[c]).sum()) for c in class_to_idx]\n",
        "    }, index=list(class_to_idx.keys()))\n",
        "    df[\"Total\"] = df[\"Train\"]+df[\"Test\"]\n",
        "    display(df)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# ------------------------------------------\n",
        "# 3) STFT -> 256x256 grayscale spectrograms\n",
        "# ------------------------------------------\n",
        "from PIL import Image\n",
        "from scipy import signal\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "def stft_to_image(seg, fs=FS):\n",
        "    \"\"\"\n",
        "    STFT with symmetric Hann (Hanning) window of 512 (paper),\n",
        "    50% overlap, magnitude -> dB -> [0,255], resized to 256x256.\n",
        "    \"\"\"\n",
        "    hann_sym = signal.windows.hann(STFT_NPERSEG, sym=True)\n",
        "    f, t, Z = signal.stft(\n",
        "        seg, fs=fs,\n",
        "        window=hann_sym,\n",
        "        nperseg=STFT_NPERSEG,\n",
        "        noverlap=STFT_NOVERLAP,\n",
        "        nfft=STFT_NPERSEG,\n",
        "        boundary=None,\n",
        "        padded=False\n",
        "    )\n",
        "    S = np.abs(Z) + 1e-12\n",
        "    S_db = 20*np.log10(S / S.max())\n",
        "    S01 = (S_db - S_db.min()) / (S_db.max() - S_db.min() + 1e-12)\n",
        "    img = Image.fromarray((S01*255).astype(np.uint8)).resize((SPEC_SIZE, SPEC_SIZE), Image.BICUBIC)\n",
        "    return np.array(img, np.uint8)\n",
        "\n",
        "def make_spec_set(X_1d, y):\n",
        "    imgs = [stft_to_image(seg, FS) for seg in X_1d]\n",
        "    X = np.expand_dims(np.array(imgs, np.float32)/255.0, axis=-1)  # [N,H,W,1]\n",
        "    Y = to_categorical(y, num_classes=5)\n",
        "    return X, Y\n",
        "\n",
        "train_X_2d, train_y_oh = make_spec_set(train_X_1d, train_y)\n",
        "test_X_2d,  test_y_oh  = make_spec_set(test_X_1d,  test_y)\n",
        "print(\"Train 2D:\", train_X_2d.shape, \"Test 2D:\", test_X_2d.shape)\n",
        "\n",
        "# Optional: free 1D arrays to save RAM\n",
        "import gc\n",
        "del train_X_1d, test_X_1d\n",
        "gc.collect()\n",
        "\n",
        "# (Optional) Save spectrogram tensors so restarts don't hurt\n",
        "# np.savez_compressed(\"ecg_spectros.npz\",\n",
        "#     train_X_2d=train_X_2d, train_y_oh=train_y_oh,\n",
        "#     test_X_2d=test_X_2d,   test_y_oh=test_y_oh\n",
        "# )\n",
        "\n",
        "# ---------------------------\n",
        "# 4) 2D-CNN (paper structure)\n",
        "# ---------------------------\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def make_2d_cnn(input_shape=(SPEC_SIZE, SPEC_SIZE, 1), num_classes=5):\n",
        "    x = inp = keras.Input(shape=input_shape)\n",
        "    x = layers.Conv2D(8, (4,4), activation='relu', padding='same')(x)\n",
        "    x = layers.MaxPooling2D((2,2))(x)\n",
        "    x = layers.Conv2D(13, (2,2), activation='relu', padding='same')(x)\n",
        "    x = layers.MaxPooling2D((2,2))(x)\n",
        "    x = layers.Conv2D(13, (2,2), activation='relu', padding='same')(x)\n",
        "    x = layers.MaxPooling2D((2,2))(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(64, activation='relu')(x)  # dense width not fixed by paper; 64 is a sensible choice\n",
        "    out = layers.Dense(num_classes, activation='softmax')(x)\n",
        "    return keras.Model(inp, out, name=\"ECG_2D_CNN\")\n",
        "\n",
        "model_2d = make_2d_cnn()\n",
        "model_2d.summary()\n",
        "\n",
        "# ------------------------------------\n",
        "# 5) Train (paper LR/epochs; safe Bsz)\n",
        "# ------------------------------------\n",
        "LR = 0.001       # paper\n",
        "EPOCHS = 100     # paper \"iterations\"\n",
        "BATCH = 100      # practical; paper used 2500 (too big for most GPUs)\n",
        "\n",
        "# (Optional) Mixed precision if VRAM is tight (uncomment next 3 lines)\n",
        "# from tensorflow.keras import mixed_precision\n",
        "# mixed_precision.set_global_policy('mixed_float16')\n",
        "# train_X_2d, test_X_2d = train_X_2d.astype('float16'), test_X_2d.astype('float16')\n",
        "\n",
        "# Safety: ensure tensors exist if the runtime was restarted\n",
        "try:\n",
        "    _ = train_X_2d.shape; _ = test_X_2d.shape; _ = train_y_oh.shape; _ = test_y_oh.shape\n",
        "except NameError:\n",
        "    # Uncomment this if you saved earlier:\n",
        "    # data = np.load(\"ecg_spectros.npz\")\n",
        "    # train_X_2d, train_y_oh = data[\"train_X_2d\"], data[\"train_y_oh\"]\n",
        "    # test_X_2d,  test_y_oh  = data[\"test_X_2d\"],  data[\"test_y_oh\"]\n",
        "    # Or rebuild:\n",
        "    train_X_2d, train_y_oh = make_spec_set(train_X_1d, train_y)\n",
        "    test_X_2d,  test_y_oh  = make_spec_set(test_X_1d,  test_y)\n",
        "\n",
        "# Helpful callbacks (optional but recommended)\n",
        "cbs = [\n",
        "    #keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True),\n",
        "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
        "]\n",
        "\n",
        "model_2d.compile(optimizer=keras.optimizers.Adam(learning_rate=LR),\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "hist_2d = model_2d.fit(\n",
        "    train_X_2d, train_y_oh,\n",
        "    validation_data=(test_X_2d, test_y_oh),\n",
        "    epochs=EPOCHS, batch_size=BATCH, verbose=1,\n",
        "    callbacks=cbs\n",
        ")\n",
        "\n",
        "# -------------------------\n",
        "# 6) Report & quick plots\n",
        "# -------------------------\n",
        "# Averages / best epoch\n",
        "tr_acc = np.array(hist_2d.history['accuracy'])\n",
        "vl_acc = np.array(hist_2d.history['val_accuracy'])\n",
        "tr_loss = np.array(hist_2d.history['loss'])\n",
        "vl_loss = np.array(hist_2d.history['val_loss'])\n",
        "\n",
        "print(f\"\\nFinal train acc: {tr_acc[-1]*100:.2f}% | Final val acc: {vl_acc[-1]*100:.2f}%\")\n",
        "print(f\"Avg  train acc : {tr_acc.mean()*100:.2f}% | Avg  val acc : {vl_acc.mean()*100:.2f}%\")\n",
        "print(f\"Best val acc   : {vl_acc.max()*100:.2f}% (epoch {vl_acc.argmax()+1})\")\n",
        "print(f\"Final loss     : train {tr_loss[-1]:.4f} | val {vl_loss[-1]:.4f}\")\n",
        "\n",
        "# Optional: exact paper metrics on TEST set\n",
        "y_prob = model_2d.predict(test_X_2d, verbose=0)\n",
        "y_pred = y_prob.argmax(axis=1)\n",
        "y_true = test_y_oh.argmax(axis=1)\n",
        "\n",
        "acc_pct = (y_pred == y_true).mean()*100.0\n",
        "eps = 1e-7\n",
        "ce = -np.sum(test_y_oh * np.log(np.clip(y_prob, eps, 1-eps)), axis=1).mean()\n",
        "\n",
        "print(f\"\\n[Paper metrics] Test accuracy: {acc_pct:.2f}% | Cross-entropy: {ce:.6f}\")\n",
        "\n",
        "# Confusion matrix (uses sklearn if available)\n",
        "try:\n",
        "    from sklearn.metrics import confusion_matrix, classification_report\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[0,1,2,3,4])\n",
        "    print(\"\\nClassification report:\\n\",\n",
        "          classification_report(y_true, y_pred, target_names=[idx_to_class[i] for i in range(5)], digits=4))\n",
        "    # Basic text CM (no seaborn)\n",
        "    print(\"Confusion matrix:\\n\", cm)\n",
        "except Exception:\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QCK9LvtHl7ei",
        "outputId": "3cc84e49-8774-4cb7-9258-0bca04a5c09b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Config ready.\n",
            "NOR: segments extracted = 7936\n",
            "LBB: segments extracted = 6600\n",
            "RBB: segments extracted = 5513\n",
            "PVC: segments extracted = 1347\n",
            "APC: segments extracted = 1860\n",
            "Train: (2100, 3600) {'NOR': 450, 'LBB': 450, 'RBB': 450, 'PVC': 300, 'APC': 450}\n",
            "Test : (420, 3600) {'NOR': 90, 'LBB': 90, 'RBB': 90, 'PVC': 60, 'APC': 90}\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Train\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 67,\n        \"min\": 300,\n        \"max\": 450,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          300,\n          450\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13,\n        \"min\": 60,\n        \"max\": 90,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          60,\n          90\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 80,\n        \"min\": 360,\n        \"max\": 540,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          360,\n          540\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-1700c18c-2e5d-4716-8a03-77e805d87214\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train</th>\n",
              "      <th>Test</th>\n",
              "      <th>Total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>NOR</th>\n",
              "      <td>450</td>\n",
              "      <td>90</td>\n",
              "      <td>540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LBB</th>\n",
              "      <td>450</td>\n",
              "      <td>90</td>\n",
              "      <td>540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RBB</th>\n",
              "      <td>450</td>\n",
              "      <td>90</td>\n",
              "      <td>540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PVC</th>\n",
              "      <td>300</td>\n",
              "      <td>60</td>\n",
              "      <td>360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>APC</th>\n",
              "      <td>450</td>\n",
              "      <td>90</td>\n",
              "      <td>540</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1700c18c-2e5d-4716-8a03-77e805d87214')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1700c18c-2e5d-4716-8a03-77e805d87214 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1700c18c-2e5d-4716-8a03-77e805d87214');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-35b72c35-cd72-4a7d-bbba-d665b5d37d3e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-35b72c35-cd72-4a7d-bbba-d665b5d37d3e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-35b72c35-cd72-4a7d-bbba-d665b5d37d3e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_972640a9-ed89-41e1-b393-8612781cf3d9\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_972640a9-ed89-41e1-b393-8612781cf3d9 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     Train  Test  Total\n",
              "NOR    450    90    540\n",
              "LBB    450    90    540\n",
              "RBB    450    90    540\n",
              "PVC    300    60    360\n",
              "APC    450    90    540"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train 2D: (2100, 256, 256, 1) Test 2D: (420, 256, 256, 1)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"ECG_2D_CNN\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"ECG_2D_CNN\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">429</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">689</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13312</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">852,032</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │           \u001b[38;5;34m136\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m13\u001b[0m)   │           \u001b[38;5;34m429\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m13\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m13\u001b[0m)     │           \u001b[38;5;34m689\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m13\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13312\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m852,032\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m325\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">853,611</span> (3.26 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m853,611\u001b[0m (3.26 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">853,611</span> (3.26 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m853,611\u001b[0m (3.26 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 437ms/step - accuracy: 0.2107 - loss: 1.6340 - val_accuracy: 0.2190 - val_loss: 1.5951 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - accuracy: 0.2123 - loss: 1.5925 - val_accuracy: 0.3714 - val_loss: 1.5853 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - accuracy: 0.4351 - loss: 1.5759 - val_accuracy: 0.3476 - val_loss: 1.5610 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.4029 - loss: 1.5433 - val_accuracy: 0.4690 - val_loss: 1.5025 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.5259 - loss: 1.4641 - val_accuracy: 0.5738 - val_loss: 1.3737 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - accuracy: 0.5939 - loss: 1.3104 - val_accuracy: 0.6429 - val_loss: 1.1945 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.6219 - loss: 1.1218 - val_accuracy: 0.6405 - val_loss: 1.0737 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - accuracy: 0.6511 - loss: 0.9749 - val_accuracy: 0.6833 - val_loss: 0.9488 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 124ms/step - accuracy: 0.6929 - loss: 0.8696 - val_accuracy: 0.7238 - val_loss: 0.8736 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.7223 - loss: 0.8021 - val_accuracy: 0.7071 - val_loss: 0.8709 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - accuracy: 0.7310 - loss: 0.7496 - val_accuracy: 0.6810 - val_loss: 0.8048 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.7480 - loss: 0.6877 - val_accuracy: 0.7643 - val_loss: 0.7264 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.8082 - loss: 0.5970 - val_accuracy: 0.8000 - val_loss: 0.6472 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.8338 - loss: 0.5445 - val_accuracy: 0.8119 - val_loss: 0.6232 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.8384 - loss: 0.5343 - val_accuracy: 0.8024 - val_loss: 0.6272 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - accuracy: 0.8318 - loss: 0.5126 - val_accuracy: 0.8262 - val_loss: 0.5636 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - accuracy: 0.8626 - loss: 0.4626 - val_accuracy: 0.8595 - val_loss: 0.4958 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - accuracy: 0.8905 - loss: 0.4054 - val_accuracy: 0.8643 - val_loss: 0.4818 - learning_rate: 0.0010\n",
            "Epoch 19/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.8939 - loss: 0.3829 - val_accuracy: 0.8595 - val_loss: 0.4673 - learning_rate: 0.0010\n",
            "Epoch 20/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.8978 - loss: 0.3718 - val_accuracy: 0.8619 - val_loss: 0.4667 - learning_rate: 0.0010\n",
            "Epoch 21/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.8975 - loss: 0.3596 - val_accuracy: 0.8738 - val_loss: 0.4348 - learning_rate: 0.0010\n",
            "Epoch 22/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.9034 - loss: 0.3336 - val_accuracy: 0.8881 - val_loss: 0.3991 - learning_rate: 0.0010\n",
            "Epoch 23/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.9190 - loss: 0.3043 - val_accuracy: 0.8929 - val_loss: 0.3684 - learning_rate: 0.0010\n",
            "Epoch 24/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.9265 - loss: 0.2754 - val_accuracy: 0.9024 - val_loss: 0.3454 - learning_rate: 0.0010\n",
            "Epoch 25/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - accuracy: 0.9362 - loss: 0.2581 - val_accuracy: 0.8952 - val_loss: 0.3447 - learning_rate: 0.0010\n",
            "Epoch 26/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - accuracy: 0.9365 - loss: 0.2523 - val_accuracy: 0.8905 - val_loss: 0.3487 - learning_rate: 0.0010\n",
            "Epoch 27/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 161ms/step - accuracy: 0.9341 - loss: 0.2502 - val_accuracy: 0.8857 - val_loss: 0.3491 - learning_rate: 0.0010\n",
            "Epoch 28/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - accuracy: 0.9338 - loss: 0.2500 - val_accuracy: 0.9024 - val_loss: 0.3269 - learning_rate: 0.0010\n",
            "Epoch 29/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.9367 - loss: 0.2424 - val_accuracy: 0.9381 - val_loss: 0.2705 - learning_rate: 0.0010\n",
            "Epoch 30/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.9508 - loss: 0.2134 - val_accuracy: 0.9286 - val_loss: 0.2798 - learning_rate: 0.0010\n",
            "Epoch 31/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.9684 - loss: 0.1877 - val_accuracy: 0.9357 - val_loss: 0.2443 - learning_rate: 0.0010\n",
            "Epoch 32/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.9666 - loss: 0.1758 - val_accuracy: 0.9452 - val_loss: 0.2372 - learning_rate: 0.0010\n",
            "Epoch 33/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.9707 - loss: 0.1711 - val_accuracy: 0.9357 - val_loss: 0.2383 - learning_rate: 0.0010\n",
            "Epoch 34/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.9722 - loss: 0.1605 - val_accuracy: 0.9452 - val_loss: 0.2152 - learning_rate: 0.0010\n",
            "Epoch 35/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.9710 - loss: 0.1539 - val_accuracy: 0.9452 - val_loss: 0.2118 - learning_rate: 0.0010\n",
            "Epoch 36/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 153ms/step - accuracy: 0.9716 - loss: 0.1499 - val_accuracy: 0.9429 - val_loss: 0.2138 - learning_rate: 0.0010\n",
            "Epoch 37/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - accuracy: 0.9730 - loss: 0.1437 - val_accuracy: 0.9452 - val_loss: 0.2045 - learning_rate: 0.0010\n",
            "Epoch 38/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 124ms/step - accuracy: 0.9737 - loss: 0.1363 - val_accuracy: 0.9452 - val_loss: 0.1968 - learning_rate: 0.0010\n",
            "Epoch 39/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.9737 - loss: 0.1314 - val_accuracy: 0.9452 - val_loss: 0.1950 - learning_rate: 0.0010\n",
            "Epoch 40/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.9745 - loss: 0.1263 - val_accuracy: 0.9476 - val_loss: 0.1900 - learning_rate: 0.0010\n",
            "Epoch 41/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.9750 - loss: 0.1211 - val_accuracy: 0.9476 - val_loss: 0.1856 - learning_rate: 0.0010\n",
            "Epoch 42/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.9749 - loss: 0.1159 - val_accuracy: 0.9500 - val_loss: 0.1800 - learning_rate: 0.0010\n",
            "Epoch 43/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.9751 - loss: 0.1106 - val_accuracy: 0.9476 - val_loss: 0.1800 - learning_rate: 0.0010\n",
            "Epoch 44/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.9747 - loss: 0.1062 - val_accuracy: 0.9524 - val_loss: 0.1737 - learning_rate: 0.0010\n",
            "Epoch 45/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - accuracy: 0.9764 - loss: 0.1010 - val_accuracy: 0.9500 - val_loss: 0.1734 - learning_rate: 0.0010\n",
            "Epoch 46/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - accuracy: 0.9783 - loss: 0.0956 - val_accuracy: 0.9500 - val_loss: 0.1720 - learning_rate: 0.0010\n",
            "Epoch 47/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.9811 - loss: 0.0909 - val_accuracy: 0.9500 - val_loss: 0.1709 - learning_rate: 0.0010\n",
            "Epoch 48/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.9819 - loss: 0.0859 - val_accuracy: 0.9524 - val_loss: 0.1681 - learning_rate: 0.0010\n",
            "Epoch 49/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.9828 - loss: 0.0816 - val_accuracy: 0.9524 - val_loss: 0.1676 - learning_rate: 0.0010\n",
            "Epoch 50/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.9836 - loss: 0.0774 - val_accuracy: 0.9524 - val_loss: 0.1684 - learning_rate: 0.0010\n",
            "Epoch 51/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.9844 - loss: 0.0736 - val_accuracy: 0.9500 - val_loss: 0.1683 - learning_rate: 0.0010\n",
            "Epoch 52/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.9844 - loss: 0.0697 - val_accuracy: 0.9500 - val_loss: 0.1681 - learning_rate: 0.0010\n",
            "Epoch 53/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.9853 - loss: 0.0663 - val_accuracy: 0.9476 - val_loss: 0.1719 - learning_rate: 0.0010\n",
            "Epoch 54/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.9872 - loss: 0.0631 - val_accuracy: 0.9476 - val_loss: 0.1732 - learning_rate: 0.0010\n",
            "Epoch 55/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 159ms/step - accuracy: 0.9860 - loss: 0.0615 - val_accuracy: 0.9476 - val_loss: 0.1795 - learning_rate: 5.0000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 125ms/step - accuracy: 0.9740 - loss: 0.0838 - val_accuracy: 0.9357 - val_loss: 0.2270 - learning_rate: 5.0000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - accuracy: 0.9694 - loss: 0.1062 - val_accuracy: 0.9333 - val_loss: 0.2569 - learning_rate: 5.0000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.9633 - loss: 0.1216 - val_accuracy: 0.9357 - val_loss: 0.2248 - learning_rate: 5.0000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.9612 - loss: 0.1243 - val_accuracy: 0.9571 - val_loss: 0.1594 - learning_rate: 5.0000e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.9611 - loss: 0.1133 - val_accuracy: 0.9667 - val_loss: 0.1325 - learning_rate: 5.0000e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - accuracy: 0.9757 - loss: 0.0872 - val_accuracy: 0.9452 - val_loss: 0.1775 - learning_rate: 5.0000e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.9809 - loss: 0.0812 - val_accuracy: 0.9619 - val_loss: 0.1437 - learning_rate: 5.0000e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - accuracy: 0.9809 - loss: 0.0702 - val_accuracy: 0.9595 - val_loss: 0.1378 - learning_rate: 5.0000e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - accuracy: 0.9809 - loss: 0.0695 - val_accuracy: 0.9690 - val_loss: 0.1321 - learning_rate: 5.0000e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.9840 - loss: 0.0604 - val_accuracy: 0.9690 - val_loss: 0.1250 - learning_rate: 5.0000e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.9873 - loss: 0.0523 - val_accuracy: 0.9714 - val_loss: 0.1304 - learning_rate: 5.0000e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - accuracy: 0.9888 - loss: 0.0524 - val_accuracy: 0.9690 - val_loss: 0.1292 - learning_rate: 5.0000e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.9881 - loss: 0.0513 - val_accuracy: 0.9690 - val_loss: 0.1316 - learning_rate: 5.0000e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.9885 - loss: 0.0522 - val_accuracy: 0.9690 - val_loss: 0.1293 - learning_rate: 5.0000e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - accuracy: 0.9885 - loss: 0.0509 - val_accuracy: 0.9690 - val_loss: 0.1282 - learning_rate: 5.0000e-04\n",
            "Epoch 71/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.9901 - loss: 0.0493 - val_accuracy: 0.9690 - val_loss: 0.1036 - learning_rate: 2.5000e-04\n",
            "Epoch 72/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - accuracy: 0.9917 - loss: 0.0402 - val_accuracy: 0.9643 - val_loss: 0.1105 - learning_rate: 2.5000e-04\n",
            "Epoch 73/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 156ms/step - accuracy: 0.9920 - loss: 0.0430 - val_accuracy: 0.9714 - val_loss: 0.1002 - learning_rate: 2.5000e-04\n",
            "Epoch 74/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 126ms/step - accuracy: 0.9935 - loss: 0.0390 - val_accuracy: 0.9714 - val_loss: 0.0982 - learning_rate: 2.5000e-04\n",
            "Epoch 75/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - accuracy: 0.9945 - loss: 0.0348 - val_accuracy: 0.9690 - val_loss: 0.0983 - learning_rate: 2.5000e-04\n",
            "Epoch 76/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - accuracy: 0.9946 - loss: 0.0343 - val_accuracy: 0.9690 - val_loss: 0.0972 - learning_rate: 2.5000e-04\n",
            "Epoch 77/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.9959 - loss: 0.0342 - val_accuracy: 0.9690 - val_loss: 0.0975 - learning_rate: 2.5000e-04\n",
            "Epoch 78/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - accuracy: 0.9957 - loss: 0.0343 - val_accuracy: 0.9690 - val_loss: 0.0965 - learning_rate: 2.5000e-04\n",
            "Epoch 79/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.9959 - loss: 0.0335 - val_accuracy: 0.9690 - val_loss: 0.0959 - learning_rate: 2.5000e-04\n",
            "Epoch 80/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 156ms/step - accuracy: 0.9959 - loss: 0.0329 - val_accuracy: 0.9690 - val_loss: 0.0956 - learning_rate: 2.5000e-04\n",
            "Epoch 81/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - accuracy: 0.9959 - loss: 0.0325 - val_accuracy: 0.9690 - val_loss: 0.0951 - learning_rate: 2.5000e-04\n",
            "Epoch 82/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - accuracy: 0.9959 - loss: 0.0321 - val_accuracy: 0.9714 - val_loss: 0.0949 - learning_rate: 2.5000e-04\n",
            "Epoch 83/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 126ms/step - accuracy: 0.9965 - loss: 0.0318 - val_accuracy: 0.9714 - val_loss: 0.0943 - learning_rate: 2.5000e-04\n",
            "Epoch 84/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - accuracy: 0.9965 - loss: 0.0313 - val_accuracy: 0.9714 - val_loss: 0.0938 - learning_rate: 2.5000e-04\n",
            "Epoch 85/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.9965 - loss: 0.0309 - val_accuracy: 0.9714 - val_loss: 0.0936 - learning_rate: 2.5000e-04\n",
            "Epoch 86/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - accuracy: 0.9967 - loss: 0.0305 - val_accuracy: 0.9714 - val_loss: 0.0930 - learning_rate: 2.5000e-04\n",
            "Epoch 87/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - accuracy: 0.9969 - loss: 0.0300 - val_accuracy: 0.9714 - val_loss: 0.0927 - learning_rate: 2.5000e-04\n",
            "Epoch 88/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.9967 - loss: 0.0297 - val_accuracy: 0.9714 - val_loss: 0.0923 - learning_rate: 2.5000e-04\n",
            "Epoch 89/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.9969 - loss: 0.0293 - val_accuracy: 0.9714 - val_loss: 0.0918 - learning_rate: 2.5000e-04\n",
            "Epoch 90/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - accuracy: 0.9973 - loss: 0.0289 - val_accuracy: 0.9714 - val_loss: 0.0916 - learning_rate: 2.5000e-04\n",
            "Epoch 91/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - accuracy: 0.9973 - loss: 0.0286 - val_accuracy: 0.9714 - val_loss: 0.0911 - learning_rate: 2.5000e-04\n",
            "Epoch 92/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - accuracy: 0.9973 - loss: 0.0281 - val_accuracy: 0.9714 - val_loss: 0.0906 - learning_rate: 2.5000e-04\n",
            "Epoch 93/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.9973 - loss: 0.0278 - val_accuracy: 0.9738 - val_loss: 0.0903 - learning_rate: 2.5000e-04\n",
            "Epoch 94/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - accuracy: 0.9976 - loss: 0.0274 - val_accuracy: 0.9738 - val_loss: 0.0899 - learning_rate: 2.5000e-04\n",
            "Epoch 95/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - accuracy: 0.9976 - loss: 0.0270 - val_accuracy: 0.9738 - val_loss: 0.0896 - learning_rate: 2.5000e-04\n",
            "Epoch 96/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - accuracy: 0.9976 - loss: 0.0267 - val_accuracy: 0.9738 - val_loss: 0.0892 - learning_rate: 2.5000e-04\n",
            "Epoch 97/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - accuracy: 0.9976 - loss: 0.0263 - val_accuracy: 0.9738 - val_loss: 0.0889 - learning_rate: 2.5000e-04\n",
            "Epoch 98/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.9976 - loss: 0.0260 - val_accuracy: 0.9738 - val_loss: 0.0885 - learning_rate: 2.5000e-04\n",
            "Epoch 99/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.9976 - loss: 0.0256 - val_accuracy: 0.9738 - val_loss: 0.0881 - learning_rate: 2.5000e-04\n",
            "Epoch 100/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 159ms/step - accuracy: 0.9976 - loss: 0.0253 - val_accuracy: 0.9738 - val_loss: 0.0877 - learning_rate: 2.5000e-04\n",
            "\n",
            "Final train acc: 99.71% | Final val acc: 97.38%\n",
            "Avg  train acc : 91.76% | Avg  val acc : 89.70%\n",
            "Best val acc   : 97.38% (epoch 93)\n",
            "Final loss     : train 0.0259 | val 0.0877\n",
            "\n",
            "[Paper metrics] Test accuracy: 97.38% | Cross-entropy: 0.087746\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         NOR     0.9889    0.9889    0.9889        90\n",
            "         LBB     0.9775    0.9667    0.9721        90\n",
            "         RBB     0.9890    1.0000    0.9945        90\n",
            "         PVC     0.9180    0.9333    0.9256        60\n",
            "         APC     0.9775    0.9667    0.9721        90\n",
            "\n",
            "    accuracy                         0.9738       420\n",
            "   macro avg     0.9702    0.9711    0.9706       420\n",
            "weighted avg     0.9739    0.9738    0.9738       420\n",
            "\n",
            "Confusion matrix:\n",
            " [[89  0  0  1  0]\n",
            " [ 0 87  1  2  0]\n",
            " [ 0  0 90  0  0]\n",
            " [ 1  1  0 56  2]\n",
            " [ 0  1  0  2 87]]\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# ECG Arrhythmia Classification (Paper full pipeline)\n",
        "# MIT-BIH: STFT (512 Hann) -> 256x256 spectrogram -> 2D-CNN\n",
        "# ============================================================\n",
        "\n",
        "# -------------------------\n",
        "# 0) Config & dependencies\n",
        "# -------------------------\n",
        "import os, random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import wfdb\n",
        "from wfdb import processing\n",
        "\n",
        "# Reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\n",
        "\n",
        "# Records per class (from the paper)\n",
        "RECORDS = {\n",
        "    \"NOR\": [100, 105, 215],\n",
        "    \"LBB\": [109, 111, 214],\n",
        "    \"RBB\": [118, 124, 212],\n",
        "    \"PVC\": [106, 233],\n",
        "    \"APC\": [207, 209, 232]\n",
        "}\n",
        "\n",
        "# Target split (paper): NOR/LBB/RBB/APC (450 train, 90 test), PVC (300 train, 60 test)\n",
        "TARGET_TRAIN = {\"NOR\":450, \"LBB\":450, \"RBB\":450, \"APC\":450, \"PVC\":300}\n",
        "TARGET_TEST  = {\"NOR\": 90, \"LBB\": 90, \"RBB\": 90, \"APC\": 90, \"PVC\": 60}\n",
        "\n",
        "# Sampling\n",
        "FS = 360           # Hz\n",
        "WIN_SEC = 10       # seconds\n",
        "WIN_SAMPLES = FS * WIN_SEC\n",
        "\n",
        "# STFT / Spectrogram (paper/stable choices)\n",
        "STFT_NPERSEG  = 512   # paper window size\n",
        "STFT_NOVERLAP = 256   # 50% overlap (paper not explicit; standard)\n",
        "SPEC_SIZE     = 256   # spectrogram image size (HxW)\n",
        "\n",
        "# Class mapping\n",
        "class_to_idx = {\"NOR\":0, \"LBB\":1, \"RBB\":2, \"PVC\":3, \"APC\":4}\n",
        "idx_to_class = {v:k for k,v in class_to_idx.items()}\n",
        "\n",
        "print(\"Config ready.\")\n",
        "\n",
        "# ------------------------------------------\n",
        "# 1) Read signals & extract labeled segments\n",
        "# ------------------------------------------\n",
        "def read_signal(record_num, fs_target=FS):\n",
        "    \"\"\"Read one MIT-BIH record and resample to fs_target.\"\"\"\n",
        "    rec = wfdb.rdrecord(str(record_num), pn_dir=\"mitdb\")\n",
        "    names = [n.lower() for n in rec.sig_name]\n",
        "    if \"v5\" in names:\n",
        "        ch = names.index(\"v5\")\n",
        "    elif \"mlii\" in names:\n",
        "        ch = names.index(\"mlii\")\n",
        "    else:\n",
        "        ch = 0\n",
        "    sig = rec.p_signal[:, ch].astype(np.float32)\n",
        "    fs = int(rec.fs)\n",
        "    if fs != fs_target:\n",
        "        sig = processing.resample_sig(sig, fs, fs_target)[0]\n",
        "        fs = fs_target\n",
        "    return sig, fs\n",
        "\n",
        "def extract_segments(record_num, label, win_samples=WIN_SAMPLES):\n",
        "    \"\"\"\n",
        "    Extract 10s windows centered on annotated beats of a given label.\n",
        "\n",
        "    Label mapping (MIT-BIH symbols):\n",
        "      NOR: 'N'\n",
        "      LBB: 'L'\n",
        "      RBB: 'R'\n",
        "      PVC: 'V'\n",
        "      APC: 'A' or 'a'\n",
        "    \"\"\"\n",
        "    sig, fs = read_signal(record_num)\n",
        "    ann = wfdb.rdann(str(record_num), \"atr\", pn_dir=\"mitdb\")\n",
        "\n",
        "    out = []\n",
        "    for idx, sym in zip(ann.sample, ann.symbol):\n",
        "        if   label == \"NOR\" and sym == \"N\": center = idx\n",
        "        elif label == \"LBB\" and sym == \"L\": center = idx\n",
        "        elif label == \"RBB\" and sym == \"R\": center = idx\n",
        "        elif label == \"PVC\" and sym == \"V\": center = idx\n",
        "        elif label == \"APC\" and sym in (\"A\",\"a\"): center = idx\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        # 10s window centered on the beat\n",
        "        start = max(center - win_samples//2, 0)\n",
        "        end   = start + win_samples\n",
        "        if end <= len(sig):\n",
        "            out.append(sig[start:end])\n",
        "    return out\n",
        "\n",
        "# Build pools per class\n",
        "pool = {cls: [] for cls in RECORDS}\n",
        "for cls, recs in RECORDS.items():\n",
        "    for r in recs:\n",
        "        pool[cls].extend(extract_segments(r, cls))\n",
        "    print(f\"{cls}: segments extracted = {len(pool[cls])}\")\n",
        "\n",
        "# ---------------------------------------\n",
        "# 2) Paper's fixed train/test split (1D)\n",
        "# ---------------------------------------\n",
        "rng = np.random.default_rng(SEED)\n",
        "\n",
        "def take_n(lst, n):\n",
        "    idx = rng.choice(len(lst), size=min(n, len(lst)), replace=False)\n",
        "    return [lst[i] for i in idx]\n",
        "\n",
        "train_X_1d, train_y = [], []\n",
        "test_X_1d,  test_y  = [], []\n",
        "\n",
        "for cls in [\"NOR\",\"LBB\",\"RBB\",\"APC\",\"PVC\"]:\n",
        "    tr_n, te_n = TARGET_TRAIN[cls], TARGET_TEST[cls]\n",
        "    cls_pool = pool[cls]\n",
        "\n",
        "    train_segs = take_n(cls_pool, tr_n)\n",
        "    chosen = set(id(x) for x in train_segs)\n",
        "\n",
        "    remaining = [x for x in cls_pool if id(x) not in chosen]\n",
        "    test_segs = take_n(remaining, te_n)\n",
        "\n",
        "    train_X_1d += train_segs\n",
        "    train_y    += [class_to_idx[cls]] * len(train_segs)\n",
        "    test_X_1d  += test_segs\n",
        "    test_y     += [class_to_idx[cls]] * len(test_segs)\n",
        "\n",
        "# Arrays\n",
        "train_X_1d = np.stack(train_X_1d)  # [N, 3600]\n",
        "test_X_1d  = np.stack(test_X_1d)\n",
        "train_y    = np.array(train_y, dtype=np.int64)\n",
        "test_y     = np.array(test_y, dtype=np.int64)\n",
        "\n",
        "print(\"Train:\", train_X_1d.shape, {k:int((train_y==v).sum()) for k,v in class_to_idx.items()})\n",
        "print(\"Test :\", test_X_1d.shape,  {k:int((test_y==v).sum()) for k,v in class_to_idx.items()})\n",
        "\n",
        "# Optional: small counts table\n",
        "try:\n",
        "    import pandas as pd\n",
        "    df = pd.DataFrame({\n",
        "        \"Train\":[int((train_y==class_to_idx[c]).sum()) for c in class_to_idx],\n",
        "        \"Test\":[int((test_y==class_to_idx[c]).sum()) for c in class_to_idx]\n",
        "    }, index=list(class_to_idx.keys()))\n",
        "    df[\"Total\"] = df[\"Train\"]+df[\"Test\"]\n",
        "    display(df)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# ------------------------------------------\n",
        "# 3) STFT -> 256x256 grayscale spectrograms\n",
        "# ------------------------------------------\n",
        "from PIL import Image\n",
        "from scipy import signal\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "def stft_to_image(seg, fs=FS):\n",
        "    \"\"\"\n",
        "    STFT with symmetric Hann (Hanning) window of 512 (paper),\n",
        "    50% overlap, magnitude -> dB -> [0,255], resized to 256x256.\n",
        "    \"\"\"\n",
        "    hann_sym = signal.windows.hann(STFT_NPERSEG, sym=True)\n",
        "    f, t, Z = signal.stft(\n",
        "        seg, fs=fs,\n",
        "        window=hann_sym,\n",
        "        nperseg=STFT_NPERSEG,\n",
        "        noverlap=STFT_NOVERLAP,\n",
        "        nfft=STFT_NPERSEG,\n",
        "        boundary=None,\n",
        "        padded=False\n",
        "    )\n",
        "    S = np.abs(Z) + 1e-12\n",
        "    S_db = 20*np.log10(S / S.max())\n",
        "    S01 = (S_db - S_db.min()) / (S_db.max() - S_db.min() + 1e-12)\n",
        "    img = Image.fromarray((S01*255).astype(np.uint8)).resize((SPEC_SIZE, SPEC_SIZE), Image.BICUBIC)\n",
        "    return np.array(img, np.uint8)\n",
        "\n",
        "def make_spec_set(X_1d, y):\n",
        "    imgs = [stft_to_image(seg, FS) for seg in X_1d]\n",
        "    X = np.expand_dims(np.array(imgs, np.float32)/255.0, axis=-1)  # [N,H,W,1]\n",
        "    Y = to_categorical(y, num_classes=5)\n",
        "    return X, Y\n",
        "\n",
        "train_X_2d, train_y_oh = make_spec_set(train_X_1d, train_y)\n",
        "test_X_2d,  test_y_oh  = make_spec_set(test_X_1d,  test_y)\n",
        "print(\"Train 2D:\", train_X_2d.shape, \"Test 2D:\", test_X_2d.shape)\n",
        "\n",
        "# Optional: free 1D arrays to save RAM\n",
        "import gc\n",
        "del train_X_1d, test_X_1d\n",
        "gc.collect()\n",
        "\n",
        "# (Optional) Save spectrogram tensors so restarts don't hurt\n",
        "# np.savez_compressed(\"ecg_spectros.npz\",\n",
        "#     train_X_2d=train_X_2d, train_y_oh=train_y_oh,\n",
        "#     test_X_2d=test_X_2d,   test_y_oh=test_y_oh\n",
        "# )\n",
        "\n",
        "# ---------------------------\n",
        "# 4) 2D-CNN (paper structure)\n",
        "# ---------------------------\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def make_2d_cnn(input_shape=(SPEC_SIZE, SPEC_SIZE, 1), num_classes=5):\n",
        "    x = inp = keras.Input(shape=input_shape)\n",
        "    x = layers.Conv2D(8, (4,4), activation='relu', padding='same')(x)\n",
        "    x = layers.MaxPooling2D((2,2))(x)\n",
        "    x = layers.Conv2D(13, (2,2), activation='relu', padding='same')(x)\n",
        "    x = layers.MaxPooling2D((2,2))(x)\n",
        "    x = layers.Conv2D(13, (2,2), activation='relu', padding='same')(x)\n",
        "    x = layers.MaxPooling2D((2,2))(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(64, activation='relu')(x)  # dense width not fixed by paper; 64 is a sensible choice\n",
        "    out = layers.Dense(num_classes, activation='softmax')(x)\n",
        "    return keras.Model(inp, out, name=\"ECG_2D_CNN\")\n",
        "\n",
        "model_2d = make_2d_cnn()\n",
        "model_2d.summary()\n",
        "\n",
        "# ------------------------------------\n",
        "# 5) Train (paper LR/epochs; safe Bsz)\n",
        "# ------------------------------------\n",
        "LR = 0.001       # paper\n",
        "EPOCHS = 100     # paper \"iterations\"\n",
        "BATCH = 250    # practical; paper used 2500 (too big for most GPUs)\n",
        "\n",
        "# (Optional) Mixed precision if VRAM is tight (uncomment next 3 lines)\n",
        "# from tensorflow.keras import mixed_precision\n",
        "# mixed_precision.set_global_policy('mixed_float16')\n",
        "# train_X_2d, test_X_2d = train_X_2d.astype('float16'), test_X_2d.astype('float16')\n",
        "\n",
        "# Safety: ensure tensors exist if the runtime was restarted\n",
        "try:\n",
        "    _ = train_X_2d.shape; _ = test_X_2d.shape; _ = train_y_oh.shape; _ = test_y_oh.shape\n",
        "except NameError:\n",
        "    # Uncomment this if you saved earlier:\n",
        "    # data = np.load(\"ecg_spectros.npz\")\n",
        "    # train_X_2d, train_y_oh = data[\"train_X_2d\"], data[\"train_y_oh\"]\n",
        "    # test_X_2d,  test_y_oh  = data[\"test_X_2d\"],  data[\"test_y_oh\"]\n",
        "    # Or rebuild:\n",
        "    train_X_2d, train_y_oh = make_spec_set(train_X_1d, train_y)\n",
        "    test_X_2d,  test_y_oh  = make_spec_set(test_X_1d,  test_y)\n",
        "\n",
        "# Helpful callbacks (optional but recommended)\n",
        "cbs = [\n",
        "    #keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True),\n",
        "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
        "]\n",
        "\n",
        "model_2d.compile(optimizer=keras.optimizers.Adam(learning_rate=LR),\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "hist_2d = model_2d.fit(\n",
        "    train_X_2d, train_y_oh,\n",
        "    validation_data=(test_X_2d, test_y_oh),\n",
        "    epochs=EPOCHS, batch_size=BATCH, verbose=1,\n",
        "    callbacks=cbs\n",
        ")\n",
        "\n",
        "# -------------------------\n",
        "# 6) Report & quick plots\n",
        "# -------------------------\n",
        "# Averages / best epoch\n",
        "tr_acc = np.array(hist_2d.history['accuracy'])\n",
        "vl_acc = np.array(hist_2d.history['val_accuracy'])\n",
        "tr_loss = np.array(hist_2d.history['loss'])\n",
        "vl_loss = np.array(hist_2d.history['val_loss'])\n",
        "\n",
        "print(f\"\\nFinal train acc: {tr_acc[-1]*100:.2f}% | Final val acc: {vl_acc[-1]*100:.2f}%\")\n",
        "print(f\"Avg  train acc : {tr_acc.mean()*100:.2f}% | Avg  val acc : {vl_acc.mean()*100:.2f}%\")\n",
        "print(f\"Best val acc   : {vl_acc.max()*100:.2f}% (epoch {vl_acc.argmax()+1})\")\n",
        "print(f\"Final loss     : train {tr_loss[-1]:.4f} | val {vl_loss[-1]:.4f}\")\n",
        "\n",
        "# Optional: exact paper metrics on TEST set\n",
        "y_prob = model_2d.predict(test_X_2d, verbose=0)\n",
        "y_pred = y_prob.argmax(axis=1)\n",
        "y_true = test_y_oh.argmax(axis=1)\n",
        "\n",
        "acc_pct = (y_pred == y_true).mean()*100.0\n",
        "eps = 1e-7\n",
        "ce = -np.sum(test_y_oh * np.log(np.clip(y_prob, eps, 1-eps)), axis=1).mean()\n",
        "\n",
        "print(f\"\\n[Paper metrics] Test accuracy: {acc_pct:.2f}% | Cross-entropy: {ce:.6f}\")\n",
        "\n",
        "# Confusion matrix (uses sklearn if available)\n",
        "try:\n",
        "    from sklearn.metrics import confusion_matrix, classification_report\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[0,1,2,3,4])\n",
        "    print(\"\\nClassification report:\\n\",\n",
        "          classification_report(y_true, y_pred, target_names=[idx_to_class[i] for i in range(5)], digits=4))\n",
        "    # Basic text CM (no seaborn)\n",
        "    print(\"Confusion matrix:\\n\", cm)\n",
        "except Exception:\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# adaptive filter"
      ],
      "metadata": {
        "id": "8CPTb48NpGJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# ECG Arrhythmia Classification (Paper-faithful full pipeline)\n",
        "# MIT-BIH: Adaptive STFT (128/256/512 Hann) -> 256x256x3 spectrogram -> 2D-CNN\n",
        "# ============================================================\n",
        "\n",
        "# -------------------------\n",
        "# 0) Config & dependencies\n",
        "# -------------------------\n",
        "import os, random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import wfdb\n",
        "from wfdb import processing\n",
        "\n",
        "# Reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\n",
        "\n",
        "# Records per class (from the paper)\n",
        "RECORDS = {\n",
        "    \"NOR\": [100, 105, 215],\n",
        "    \"LBB\": [109, 111, 214],\n",
        "    \"RBB\": [118, 124, 212],\n",
        "    \"PVC\": [106, 233],\n",
        "    \"APC\": [207, 209, 232]\n",
        "}\n",
        "\n",
        "# Target split (paper): NOR/LBB/RBB/APC (450 train, 90 test), PVC (300 train, 60 test)\n",
        "TARGET_TRAIN = {\"NOR\":450, \"LBB\":450, \"RBB\":450, \"APC\":450, \"PVC\":300}\n",
        "TARGET_TEST  = {\"NOR\": 90, \"LBB\": 90, \"RBB\": 90, \"APC\": 90, \"PVC\": 60}\n",
        "\n",
        "# Sampling\n",
        "FS = 360           # Hz\n",
        "WIN_SEC = 10       # seconds\n",
        "WIN_SAMPLES = FS * WIN_SEC\n",
        "\n",
        "# Adaptive STFT / Spectrogram (multi-window front-end)\n",
        "# We use 3 window sizes: 128, 256, 512 (Hann), each with 50% overlap\n",
        "STFT_WINDOW_SIZES = [128, 256, 512]\n",
        "SPEC_SIZE         = 256   # spectrogram image size (HxW)\n",
        "\n",
        "# Class mapping\n",
        "class_to_idx = {\"NOR\":0, \"LBB\":1, \"RBB\":2, \"PVC\":3, \"APC\":4}\n",
        "idx_to_class = {v:k for k,v in class_to_idx.items()}\n",
        "\n",
        "print(\"Config ready.\")\n",
        "\n",
        "# ------------------------------------------\n",
        "# 1) Read signals & extract labeled segments\n",
        "# ------------------------------------------\n",
        "def read_signal(record_num, fs_target=FS):\n",
        "    \"\"\"Read one MIT-BIH record and resample to fs_target.\"\"\"\n",
        "    rec = wfdb.rdrecord(str(record_num), pn_dir=\"mitdb\")\n",
        "    names = [n.lower() for n in rec.sig_name]\n",
        "    if \"v5\" in names:\n",
        "        ch = names.index(\"v5\")\n",
        "    elif \"mlii\" in names:\n",
        "        ch = names.index(\"mlii\")\n",
        "    else:\n",
        "        ch = 0\n",
        "    sig = rec.p_signal[:, ch].astype(np.float32)\n",
        "    fs = int(rec.fs)\n",
        "    if fs != fs_target:\n",
        "        sig = processing.resample_sig(sig, fs, fs_target)[0]\n",
        "        fs = fs_target\n",
        "    return sig, fs\n",
        "\n",
        "def extract_segments(record_num, label, win_samples=WIN_SAMPLES):\n",
        "    \"\"\"\n",
        "    Extract 10s windows centered on annotated beats of a given label.\n",
        "\n",
        "    Label mapping (MIT-BIH symbols):\n",
        "      NOR: 'N'\n",
        "      LBB: 'L'\n",
        "      RBB: 'R'\n",
        "      PVC: 'V'\n",
        "      APC: 'A' or 'a'\n",
        "    \"\"\"\n",
        "    sig, fs = read_signal(record_num)\n",
        "    ann = wfdb.rdann(str(record_num), \"atr\", pn_dir=\"mitdb\")\n",
        "\n",
        "    out = []\n",
        "    for idx, sym in zip(ann.sample, ann.symbol):\n",
        "        if   label == \"NOR\" and sym == \"N\": center = idx\n",
        "        elif label == \"LBB\" and sym == \"L\": center = idx\n",
        "        elif label == \"RBB\" and sym == \"R\": center = idx\n",
        "        elif label == \"PVC\" and sym == \"V\": center = idx\n",
        "        elif label == \"APC\" and sym in (\"A\",\"a\"): center = idx\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        # 10s window centered on the beat\n",
        "        start = max(center - win_samples//2, 0)\n",
        "        end   = start + win_samples\n",
        "        if end <= len(sig):\n",
        "            out.append(sig[start:end])\n",
        "    return out\n",
        "\n",
        "# Build pools per class\n",
        "pool = {cls: [] for cls in RECORDS}\n",
        "for cls, recs in RECORDS.items():\n",
        "    for r in recs:\n",
        "        pool[cls].extend(extract_segments(r, cls))\n",
        "    print(f\"{cls}: segments extracted = {len(pool[cls])}\")\n",
        "\n",
        "# ---------------------------------------\n",
        "# 2) Paper's fixed train/test split (1D)\n",
        "# ---------------------------------------\n",
        "rng = np.random.default_rng(SEED)\n",
        "\n",
        "def take_n(lst, n):\n",
        "    idx = rng.choice(len(lst), size=min(n, len(lst)), replace=False)\n",
        "    return [lst[i] for i in idx]\n",
        "\n",
        "train_X_1d, train_y = [], []\n",
        "test_X_1d,  test_y  = [], []\n",
        "\n",
        "for cls in [\"NOR\",\"LBB\",\"RBB\",\"APC\",\"PVC\"]:\n",
        "    tr_n, te_n = TARGET_TRAIN[cls], TARGET_TEST[cls]\n",
        "    cls_pool = pool[cls]\n",
        "\n",
        "    train_segs = take_n(cls_pool, tr_n)\n",
        "    chosen = set(id(x) for x in train_segs)\n",
        "\n",
        "    remaining = [x for x in cls_pool if id(x) not in chosen]\n",
        "    test_segs = take_n(remaining, te_n)\n",
        "\n",
        "    train_X_1d += train_segs\n",
        "    train_y    += [class_to_idx[cls]] * len(train_segs)\n",
        "    test_X_1d  += test_segs\n",
        "    test_y     += [class_to_idx[cls]] * len(test_segs)\n",
        "\n",
        "# Arrays\n",
        "train_X_1d = np.stack(train_X_1d)  # [N, 3600]\n",
        "test_X_1d  = np.stack(test_X_1d)\n",
        "train_y    = np.array(train_y, dtype=np.int64)\n",
        "test_y     = np.array(test_y, dtype=np.int64)\n",
        "\n",
        "print(\"Train:\", train_X_1d.shape, {k:int((train_y==v).sum()) for k,v in class_to_idx.items()})\n",
        "print(\"Test :\", test_X_1d.shape,  {k:int((test_y==v).sum()) for k,v in class_to_idx.items()})\n",
        "\n",
        "# Optional: small counts table\n",
        "try:\n",
        "    import pandas as pd\n",
        "    df = pd.DataFrame({\n",
        "        \"Train\":[int((train_y==class_to_idx[c]).sum()) for c in class_to_idx],\n",
        "        \"Test\":[int((test_y==class_to_idx[c]).sum()) for c in class_to_idx]\n",
        "    }, index=list(class_to_idx.keys()))\n",
        "    df[\"Total\"] = df[\"Train\"]+df[\"Test\"]\n",
        "    display(df)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 3) Adaptive STFT -> 256x256x3 spectrogram images\n",
        "# -------------------------------------------------\n",
        "from PIL import Image\n",
        "from scipy import signal\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "def stft_single_window_to_image(seg, fs, nperseg, noverlap):\n",
        "    \"\"\"\n",
        "    STFT with symmetric Hann window of size nperseg,\n",
        "    'noverlap' overlap, magnitude -> dB -> [0,255], resized to 256x256.\n",
        "    Returns a 2D uint8 image.\n",
        "    \"\"\"\n",
        "    hann_sym = signal.windows.hann(nperseg, sym=True)\n",
        "    f, t, Z = signal.stft(\n",
        "        seg, fs=fs,\n",
        "        window=hann_sym,\n",
        "        nperseg=nperseg,\n",
        "        noverlap=noverlap,\n",
        "        nfft=nperseg,\n",
        "        boundary=None,\n",
        "        padded=False\n",
        "    )\n",
        "    S = np.abs(Z) + 1e-12\n",
        "    S_db = 20*np.log10(S / S.max())\n",
        "    S01 = (S_db - S_db.min()) / (S_db.max() - S_db.min() + 1e-12)\n",
        "    img = Image.fromarray((S01*255).astype(np.uint8)).resize((SPEC_SIZE, SPEC_SIZE), Image.BICUBIC)\n",
        "    return np.array(img, np.uint8)  # [H,W]\n",
        "\n",
        "def stft_multi_to_image(seg, fs=FS):\n",
        "    \"\"\"\n",
        "    Adaptive front-end:\n",
        "      - Compute STFT spectrograms with 3 different Hann windows\n",
        "        (128, 256, 512 samples; each 50% overlap).\n",
        "      - Convert each to a 256x256 grayscale image.\n",
        "      - Stack as 3 channels -> 256x256x3.\n",
        "    \"\"\"\n",
        "    chans = []\n",
        "    for nperseg in STFT_WINDOW_SIZES:\n",
        "        noverlap = nperseg // 2   # 50% overlap\n",
        "        img2d = stft_single_window_to_image(seg, fs, nperseg, noverlap)  # [H,W]\n",
        "        chans.append(img2d)\n",
        "    img3 = np.stack(chans, axis=-1)  # [H,W,3], uint8\n",
        "    return img3\n",
        "\n",
        "def make_spec_set(X_1d, y):\n",
        "    # Each segment -> 3-channel spectrogram image\n",
        "    imgs = [stft_multi_to_image(seg, FS) for seg in X_1d]\n",
        "    X = np.array(imgs, np.float32) / 255.0  # [N,H,W,3]\n",
        "    Y = to_categorical(y, num_classes=5)\n",
        "    return X, Y\n",
        "\n",
        "train_X_2d, train_y_oh = make_spec_set(train_X_1d, train_y)\n",
        "test_X_2d,  test_y_oh  = make_spec_set(test_X_1d,  test_y)\n",
        "print(\"Train 2D:\", train_X_2d.shape, \"Test 2D:\", test_X_2d.shape)\n",
        "# Expect: (N, 256, 256, 3)\n",
        "\n",
        "# Optional: free 1D arrays to save RAM\n",
        "import gc\n",
        "del train_X_1d, test_X_1d\n",
        "gc.collect()\n",
        "\n",
        "# (Optional) Save spectrogram tensors so restarts don't hurt\n",
        "# np.savez_compressed(\"ecg_spectros_multiwin.npz\",\n",
        "#     train_X_2d=train_X_2d, train_y_oh=train_y_oh,\n",
        "#     test_X_2d=test_X_2d,   test_y_oh=test_y_oh\n",
        "# )\n",
        "\n",
        "# ---------------------------\n",
        "# 4) 2D-CNN (paper structure)\n",
        "#     Now with 3-channel input\n",
        "# ---------------------------\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def make_2d_cnn(input_shape=(SPEC_SIZE, SPEC_SIZE, 3), num_classes=5):\n",
        "    x = inp = keras.Input(shape=input_shape)\n",
        "    x = layers.Conv2D(8, (4,4), activation='relu', padding='same')(x)\n",
        "    x = layers.MaxPooling2D((2,2))(x)\n",
        "    x = layers.Conv2D(13, (2,2), activation='relu', padding='same')(x)\n",
        "    x = layers.MaxPooling2D((2,2))(x)\n",
        "    x = layers.Conv2D(13, (2,2), activation='relu', padding='same')(x)\n",
        "    x = layers.MaxPooling2D((2,2))(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(64, activation='relu')(x)  # dense width not fixed by paper; 64 is a sensible choice\n",
        "    out = layers.Dense(num_classes, activation='softmax')(x)\n",
        "    return keras.Model(inp, out, name=\"ECG_2D_CNN_MultiWindowSTFT\")\n",
        "\n",
        "model_2d = make_2d_cnn()\n",
        "model_2d.summary()\n",
        "\n",
        "# ------------------------------------\n",
        "# 5) Train (paper LR/epochs; safe Bsz)\n",
        "# ------------------------------------\n",
        "LR = 0.001       # paper\n",
        "EPOCHS = 100     # paper \"iterations\"\n",
        "BATCH = 250      # practical; paper used 2500 (too big for most GPUs)\n",
        "\n",
        "# (Optional) Mixed precision if VRAM is tight (uncomment next 3 lines)\n",
        "# from tensorflow.keras import mixed_precision\n",
        "# mixed_precision.set_global_policy('mixed_float16')\n",
        "# train_X_2d, test_X_2d = train_X_2d.astype('float16'), test_X_2d.astype('float16')\n",
        "\n",
        "# Safety: ensure tensors exist if the runtime was restarted\n",
        "try:\n",
        "    _ = train_X_2d.shape; _ = test_X_2d.shape; _ = train_y_oh.shape; _ = test_y_oh.shape\n",
        "except NameError:\n",
        "    # Uncomment this if you saved earlier:\n",
        "    # data = np.load(\"ecg_spectros_multiwin.npz\")\n",
        "    # train_X_2d, train_y_oh = data[\"train_X_2d\"], data[\"train_y_oh\"]\n",
        "    # test_X_2d,  test_y_oh  = data[\"test_X_2d\"],  data[\"test_y_oh\"]\n",
        "    # Or rebuild:\n",
        "    train_X_2d, train_y_oh = make_spec_set(train_X_1d, train_y)\n",
        "    test_X_2d,  test_y_oh  = make_spec_set(test_X_1d,  test_y)\n",
        "\n",
        "# Helpful callbacks (optional but recommended)\n",
        "cbs = [\n",
        "    # keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True),\n",
        "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
        "]\n",
        "\n",
        "model_2d.compile(optimizer=keras.optimizers.Adam(learning_rate=LR),\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "hist_2d = model_2d.fit(\n",
        "    train_X_2d, train_y_oh,\n",
        "    validation_data=(test_X_2d, test_y_oh),\n",
        "    epochs=EPOCHS, batch_size=BATCH, verbose=1,\n",
        "    callbacks=cbs\n",
        ")\n",
        "\n",
        "# -------------------------\n",
        "# 6) Report & quick plots\n",
        "# -------------------------\n",
        "# Averages / best epoch\n",
        "tr_acc = np.array(hist_2d.history['accuracy'])\n",
        "vl_acc = np.array(hist_2d.history['val_accuracy'])\n",
        "tr_loss = np.array(hist_2d.history['loss'])\n",
        "vl_loss = np.array(hist_2d.history['val_loss'])\n",
        "\n",
        "print(f\"\\nFinal train acc: {tr_acc[-1]*100:.2f}% | Final val acc: {vl_acc[-1]*100:.2f}%\")\n",
        "print(f\"Avg  train acc : {tr_acc.mean()*100:.2f}% | Avg  val acc : {vl_acc.mean()*100:.2f}%\")\n",
        "print(f\"Best val acc   : {vl_acc.max()*100:.2f}% (epoch {vl_acc.argmax()+1})\")\n",
        "print(f\"Final loss     : train {tr_loss[-1]:.4f} | val {vl_loss[-1]:.4f}\")\n",
        "\n",
        "# Optional: exact paper metrics on TEST set\n",
        "y_prob = model_2d.predict(test_X_2d, verbose=0)\n",
        "y_pred = y_prob.argmax(axis=1)\n",
        "y_true = test_y_oh.argmax(axis=1)\n",
        "\n",
        "acc_pct = (y_pred == y_true).mean()*100.0\n",
        "eps = 1e-7\n",
        "ce = -np.sum(test_y_oh * np.log(np.clip(y_prob, eps, 1-eps)), axis=1).mean()\n",
        "\n",
        "print(f\"\\n[Paper metrics] Test accuracy: {acc_pct:.2f}% | Cross-entropy: {ce:.6f}\")\n",
        "\n",
        "# Confusion matrix (uses sklearn if available)\n",
        "try:\n",
        "    from sklearn.metrics import confusion_matrix, classification_report\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[0,1,2,3,4])\n",
        "    print(\"\\nClassification report:\\n\",\n",
        "          classification_report(y_true, y_pred, target_names=[idx_to_class[i] for i in range(5)], digits=4))\n",
        "    # Basic text CM (no seaborn)\n",
        "    print(\"Confusion matrix:\\n\", cm)\n",
        "except Exception:\n",
        "    pass\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xwPOwTGPpJYp",
        "outputId": "5ed74a4d-bd5a-4ef7-d9b0-e4d49a37eabf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config ready.\n",
            "NOR: segments extracted = 7936\n",
            "LBB: segments extracted = 6600\n",
            "RBB: segments extracted = 5513\n",
            "PVC: segments extracted = 1347\n",
            "APC: segments extracted = 1860\n",
            "Train: (2100, 3600) {'NOR': 450, 'LBB': 450, 'RBB': 450, 'PVC': 300, 'APC': 450}\n",
            "Test : (420, 3600) {'NOR': 90, 'LBB': 90, 'RBB': 90, 'PVC': 60, 'APC': 90}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     Train  Test  Total\n",
              "NOR    450    90    540\n",
              "LBB    450    90    540\n",
              "RBB    450    90    540\n",
              "PVC    300    60    360\n",
              "APC    450    90    540"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c3629ca7-9756-4ccb-81d9-73540fd23c8d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train</th>\n",
              "      <th>Test</th>\n",
              "      <th>Total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>NOR</th>\n",
              "      <td>450</td>\n",
              "      <td>90</td>\n",
              "      <td>540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LBB</th>\n",
              "      <td>450</td>\n",
              "      <td>90</td>\n",
              "      <td>540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RBB</th>\n",
              "      <td>450</td>\n",
              "      <td>90</td>\n",
              "      <td>540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PVC</th>\n",
              "      <td>300</td>\n",
              "      <td>60</td>\n",
              "      <td>360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>APC</th>\n",
              "      <td>450</td>\n",
              "      <td>90</td>\n",
              "      <td>540</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c3629ca7-9756-4ccb-81d9-73540fd23c8d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c3629ca7-9756-4ccb-81d9-73540fd23c8d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c3629ca7-9756-4ccb-81d9-73540fd23c8d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3c87d85f-3ae7-4a69-850e-e31e054657b7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3c87d85f-3ae7-4a69-850e-e31e054657b7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3c87d85f-3ae7-4a69-850e-e31e054657b7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_68c554e7-a15c-46c7-bc4f-d0077485771a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_68c554e7-a15c-46c7-bc4f-d0077485771a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Train\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 67,\n        \"min\": 300,\n        \"max\": 450,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          300,\n          450\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13,\n        \"min\": 60,\n        \"max\": 90,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          60,\n          90\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 80,\n        \"min\": 360,\n        \"max\": 540,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          360,\n          540\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train 2D: (2100, 256, 256, 3) Test 2D: (420, 256, 256, 3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"ECG_2D_CNN_MultiWindowSTFT\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"ECG_2D_CNN_MultiWindowSTFT\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │           \u001b[38;5;34m392\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m13\u001b[0m)   │           \u001b[38;5;34m429\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m13\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m13\u001b[0m)     │           \u001b[38;5;34m689\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m13\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13312\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m852,032\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m325\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">392</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">429</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">689</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13312</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">852,032</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m853,867\u001b[0m (3.26 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">853,867</span> (3.26 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m853,867\u001b[0m (3.26 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">853,867</span> (3.26 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 561ms/step - accuracy: 0.2258 - loss: 1.6137 - val_accuracy: 0.4476 - val_loss: 1.5612 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 232ms/step - accuracy: 0.4495 - loss: 1.5302 - val_accuracy: 0.5762 - val_loss: 1.4422 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - accuracy: 0.6351 - loss: 1.3699 - val_accuracy: 0.6381 - val_loss: 1.1956 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - accuracy: 0.7536 - loss: 1.0837 - val_accuracy: 0.8190 - val_loss: 0.8147 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - accuracy: 0.8615 - loss: 0.7244 - val_accuracy: 0.8405 - val_loss: 0.5410 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - accuracy: 0.8803 - loss: 0.4735 - val_accuracy: 0.9048 - val_loss: 0.3847 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - accuracy: 0.9150 - loss: 0.3155 - val_accuracy: 0.9405 - val_loss: 0.2770 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 239ms/step - accuracy: 0.9487 - loss: 0.2138 - val_accuracy: 0.9476 - val_loss: 0.1955 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - accuracy: 0.9603 - loss: 0.1549 - val_accuracy: 0.9476 - val_loss: 0.1626 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - accuracy: 0.9726 - loss: 0.1209 - val_accuracy: 0.9548 - val_loss: 0.1382 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - accuracy: 0.9799 - loss: 0.0966 - val_accuracy: 0.9690 - val_loss: 0.1154 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - accuracy: 0.9880 - loss: 0.0755 - val_accuracy: 0.9690 - val_loss: 0.1007 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 252ms/step - accuracy: 0.9892 - loss: 0.0632 - val_accuracy: 0.9667 - val_loss: 0.1139 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 223ms/step - accuracy: 0.9879 - loss: 0.0628 - val_accuracy: 0.9429 - val_loss: 0.1534 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - accuracy: 0.9842 - loss: 0.0744 - val_accuracy: 0.9643 - val_loss: 0.1122 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - accuracy: 0.9824 - loss: 0.0597 - val_accuracy: 0.9667 - val_loss: 0.1185 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - accuracy: 0.9927 - loss: 0.0476 - val_accuracy: 0.9690 - val_loss: 0.1031 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - accuracy: 0.9915 - loss: 0.0367 - val_accuracy: 0.9833 - val_loss: 0.0650 - learning_rate: 5.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 253ms/step - accuracy: 0.9980 - loss: 0.0274 - val_accuracy: 0.9810 - val_loss: 0.0695 - learning_rate: 5.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 215ms/step - accuracy: 0.9977 - loss: 0.0257 - val_accuracy: 0.9857 - val_loss: 0.0654 - learning_rate: 5.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - accuracy: 0.9992 - loss: 0.0237 - val_accuracy: 0.9857 - val_loss: 0.0605 - learning_rate: 5.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - accuracy: 0.9994 - loss: 0.0217 - val_accuracy: 0.9857 - val_loss: 0.0561 - learning_rate: 5.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - accuracy: 0.9993 - loss: 0.0190 - val_accuracy: 0.9833 - val_loss: 0.0570 - learning_rate: 5.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - accuracy: 0.9998 - loss: 0.0176 - val_accuracy: 0.9857 - val_loss: 0.0528 - learning_rate: 5.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 269ms/step - accuracy: 1.0000 - loss: 0.0160 - val_accuracy: 0.9857 - val_loss: 0.0544 - learning_rate: 5.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - accuracy: 1.0000 - loss: 0.0152 - val_accuracy: 0.9857 - val_loss: 0.0515 - learning_rate: 5.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - accuracy: 1.0000 - loss: 0.0141 - val_accuracy: 0.9857 - val_loss: 0.0510 - learning_rate: 5.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - accuracy: 1.0000 - loss: 0.0132 - val_accuracy: 0.9857 - val_loss: 0.0497 - learning_rate: 5.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - accuracy: 1.0000 - loss: 0.0123 - val_accuracy: 0.9857 - val_loss: 0.0489 - learning_rate: 5.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - accuracy: 1.0000 - loss: 0.0115 - val_accuracy: 0.9857 - val_loss: 0.0480 - learning_rate: 5.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 232ms/step - accuracy: 1.0000 - loss: 0.0107 - val_accuracy: 0.9857 - val_loss: 0.0473 - learning_rate: 5.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - accuracy: 1.0000 - loss: 0.0100 - val_accuracy: 0.9857 - val_loss: 0.0465 - learning_rate: 5.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - accuracy: 1.0000 - loss: 0.0094 - val_accuracy: 0.9857 - val_loss: 0.0459 - learning_rate: 5.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 204ms/step - accuracy: 1.0000 - loss: 0.0088 - val_accuracy: 0.9857 - val_loss: 0.0453 - learning_rate: 5.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - accuracy: 1.0000 - loss: 0.0083 - val_accuracy: 0.9857 - val_loss: 0.0447 - learning_rate: 5.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 217ms/step - accuracy: 1.0000 - loss: 0.0078 - val_accuracy: 0.9857 - val_loss: 0.0442 - learning_rate: 5.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - accuracy: 1.0000 - loss: 0.0074 - val_accuracy: 0.9857 - val_loss: 0.0438 - learning_rate: 5.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.9857 - val_loss: 0.0434 - learning_rate: 5.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - accuracy: 1.0000 - loss: 0.0066 - val_accuracy: 0.9857 - val_loss: 0.0429 - learning_rate: 5.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 0.9857 - val_loss: 0.0426 - learning_rate: 5.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 0.9857 - val_loss: 0.0422 - learning_rate: 5.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 262ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.9857 - val_loss: 0.0419 - learning_rate: 5.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.9857 - val_loss: 0.0416 - learning_rate: 5.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.9857 - val_loss: 0.0413 - learning_rate: 5.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.9857 - val_loss: 0.0411 - learning_rate: 5.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.9857 - val_loss: 0.0408 - learning_rate: 5.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.9857 - val_loss: 0.0406 - learning_rate: 5.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 227ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.9857 - val_loss: 0.0404 - learning_rate: 5.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.9857 - val_loss: 0.0402 - learning_rate: 5.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.9857 - val_loss: 0.0400 - learning_rate: 5.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.9857 - val_loss: 0.0398 - learning_rate: 5.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.9857 - val_loss: 0.0397 - learning_rate: 5.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.9857 - val_loss: 0.0395 - learning_rate: 5.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 229ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.9857 - val_loss: 0.0394 - learning_rate: 5.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9857 - val_loss: 0.0392 - learning_rate: 5.0000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.9857 - val_loss: 0.0391 - learning_rate: 5.0000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9857 - val_loss: 0.0389 - learning_rate: 5.0000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.9857 - val_loss: 0.0389 - learning_rate: 5.0000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.9857 - val_loss: 0.0387 - learning_rate: 5.0000e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 229ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9857 - val_loss: 0.0387 - learning_rate: 5.0000e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9857 - val_loss: 0.0385 - learning_rate: 5.0000e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9857 - val_loss: 0.0385 - learning_rate: 5.0000e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9857 - val_loss: 0.0384 - learning_rate: 5.0000e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9857 - val_loss: 0.0383 - learning_rate: 5.0000e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 250ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9857 - val_loss: 0.0383 - learning_rate: 5.0000e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9857 - val_loss: 0.0382 - learning_rate: 5.0000e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9857 - val_loss: 0.0381 - learning_rate: 5.0000e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.9857 - val_loss: 0.0380 - learning_rate: 5.0000e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9857 - val_loss: 0.0381 - learning_rate: 5.0000e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9857 - val_loss: 0.0380 - learning_rate: 5.0000e-04\n",
            "Epoch 71/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 264ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9857 - val_loss: 0.0379 - learning_rate: 5.0000e-04\n",
            "Epoch 72/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9857 - val_loss: 0.0379 - learning_rate: 5.0000e-04\n",
            "Epoch 73/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9857 - val_loss: 0.0379 - learning_rate: 5.0000e-04\n",
            "Epoch 74/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9857 - val_loss: 0.0378 - learning_rate: 5.0000e-04\n",
            "Epoch 75/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9857 - val_loss: 0.0378 - learning_rate: 5.0000e-04\n",
            "Epoch 76/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9857 - val_loss: 0.0378 - learning_rate: 5.0000e-04\n",
            "Epoch 77/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 240ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9857 - val_loss: 0.0377 - learning_rate: 5.0000e-04\n",
            "Epoch 78/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9857 - val_loss: 0.0377 - learning_rate: 5.0000e-04\n",
            "Epoch 79/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9857 - val_loss: 0.0377 - learning_rate: 5.0000e-04\n",
            "Epoch 80/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9857 - val_loss: 0.0377 - learning_rate: 5.0000e-04\n",
            "Epoch 81/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9857 - val_loss: 0.0377 - learning_rate: 5.0000e-04\n",
            "Epoch 82/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9857 - val_loss: 0.0377 - learning_rate: 5.0000e-04\n",
            "Epoch 83/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 228ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9857 - val_loss: 0.0376 - learning_rate: 5.0000e-04\n",
            "Epoch 84/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9857 - val_loss: 0.0376 - learning_rate: 5.0000e-04\n",
            "Epoch 85/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9857 - val_loss: 0.0376 - learning_rate: 2.5000e-04\n",
            "Epoch 86/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9857 - val_loss: 0.0376 - learning_rate: 2.5000e-04\n",
            "Epoch 87/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9857 - val_loss: 0.0376 - learning_rate: 2.5000e-04\n",
            "Epoch 88/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 258ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9857 - val_loss: 0.0376 - learning_rate: 2.5000e-04\n",
            "Epoch 89/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9857 - val_loss: 0.0376 - learning_rate: 2.5000e-04\n",
            "Epoch 90/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9857 - val_loss: 0.0376 - learning_rate: 2.5000e-04\n",
            "Epoch 91/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9857 - val_loss: 0.0376 - learning_rate: 1.2500e-04\n",
            "Epoch 92/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9857 - val_loss: 0.0376 - learning_rate: 1.2500e-04\n",
            "Epoch 93/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 202ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9857 - val_loss: 0.0376 - learning_rate: 1.2500e-04\n",
            "Epoch 94/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 260ms/step - accuracy: 1.0000 - loss: 9.9750e-04 - val_accuracy: 0.9857 - val_loss: 0.0376 - learning_rate: 1.2500e-04\n",
            "Epoch 95/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - accuracy: 1.0000 - loss: 9.9062e-04 - val_accuracy: 0.9857 - val_loss: 0.0376 - learning_rate: 1.2500e-04\n",
            "Epoch 96/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - accuracy: 1.0000 - loss: 9.8393e-04 - val_accuracy: 0.9857 - val_loss: 0.0376 - learning_rate: 6.2500e-05\n",
            "Epoch 97/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - accuracy: 1.0000 - loss: 9.8052e-04 - val_accuracy: 0.9857 - val_loss: 0.0376 - learning_rate: 6.2500e-05\n",
            "Epoch 98/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 201ms/step - accuracy: 1.0000 - loss: 9.7709e-04 - val_accuracy: 0.9857 - val_loss: 0.0376 - learning_rate: 6.2500e-05\n",
            "Epoch 99/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 253ms/step - accuracy: 1.0000 - loss: 9.7368e-04 - val_accuracy: 0.9857 - val_loss: 0.0376 - learning_rate: 6.2500e-05\n",
            "Epoch 100/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - accuracy: 1.0000 - loss: 9.7026e-04 - val_accuracy: 0.9857 - val_loss: 0.0376 - learning_rate: 6.2500e-05\n",
            "\n",
            "Final train acc: 100.00% | Final val acc: 98.57%\n",
            "Avg  train acc : 97.56% | Avg  val acc : 96.57%\n",
            "Best val acc   : 98.57% (epoch 20)\n",
            "Final loss     : train 0.0010 | val 0.0376\n",
            "\n",
            "[Paper metrics] Test accuracy: 98.57% | Cross-entropy: 0.037615\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         NOR     0.9780    0.9889    0.9834        90\n",
            "         LBB     1.0000    0.9889    0.9944        90\n",
            "         RBB     0.9888    0.9778    0.9832        90\n",
            "         PVC     1.0000    0.9667    0.9831        60\n",
            "         APC     0.9677    1.0000    0.9836        90\n",
            "\n",
            "    accuracy                         0.9857       420\n",
            "   macro avg     0.9869    0.9844    0.9855       420\n",
            "weighted avg     0.9860    0.9857    0.9857       420\n",
            "\n",
            "Confusion matrix:\n",
            " [[89  0  0  0  1]\n",
            " [ 1 89  0  0  0]\n",
            " [ 0  0 88  0  2]\n",
            " [ 1  0  1 58  0]\n",
            " [ 0  0  0  0 90]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1000 batch size"
      ],
      "metadata": {
        "id": "bLNj3obVrVbb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# ECG Arrhythmia Classification (Paper-faithful full pipeline)\n",
        "# MIT-BIH: STFT (512 Hann) -> 256x256 spectrogram -> 2D-CNN\n",
        "# ============================================================\n",
        "\n",
        "# -------------------------\n",
        "# 0) Config & dependencies\n",
        "# -------------------------\n",
        "import os, random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import wfdb\n",
        "from wfdb import processing\n",
        "\n",
        "# Reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\n",
        "\n",
        "# Records per class (from the paper)\n",
        "RECORDS = {\n",
        "    \"NOR\": [100, 105, 215],\n",
        "    \"LBB\": [109, 111, 214],\n",
        "    \"RBB\": [118, 124, 212],\n",
        "    \"PVC\": [106, 233],\n",
        "    \"APC\": [207, 209, 232]\n",
        "}\n",
        "\n",
        "# Target split (paper): NOR/LBB/RBB/APC (450 train, 90 test), PVC (300 train, 60 test)\n",
        "TARGET_TRAIN = {\"NOR\":450, \"LBB\":450, \"RBB\":450, \"APC\":450, \"PVC\":300}\n",
        "TARGET_TEST  = {\"NOR\": 90, \"LBB\": 90, \"RBB\": 90, \"APC\": 90, \"PVC\": 60}\n",
        "\n",
        "# Sampling\n",
        "FS = 360           # Hz\n",
        "WIN_SEC = 10       # seconds\n",
        "WIN_SAMPLES = FS * WIN_SEC\n",
        "\n",
        "# STFT / Spectrogram (paper/stable choices)\n",
        "STFT_NPERSEG  = 512   # paper window size\n",
        "STFT_NOVERLAP = 256   # 50% overlap (paper not explicit; standard)\n",
        "SPEC_SIZE     = 256   # spectrogram image size (HxW)\n",
        "\n",
        "# Class mapping\n",
        "class_to_idx = {\"NOR\":0, \"LBB\":1, \"RBB\":2, \"PVC\":3, \"APC\":4}\n",
        "idx_to_class = {v:k for k,v in class_to_idx.items()}\n",
        "\n",
        "print(\"Config ready.\")\n",
        "\n",
        "# ------------------------------------------\n",
        "# 1) Read signals & extract labeled segments\n",
        "# ------------------------------------------\n",
        "def read_signal(record_num, fs_target=FS):\n",
        "    \"\"\"Read one MIT-BIH record and resample to fs_target.\"\"\"\n",
        "    rec = wfdb.rdrecord(str(record_num), pn_dir=\"mitdb\")\n",
        "    names = [n.lower() for n in rec.sig_name]\n",
        "    if \"v5\" in names:\n",
        "        ch = names.index(\"v5\")\n",
        "    elif \"mlii\" in names:\n",
        "        ch = names.index(\"mlii\")\n",
        "    else:\n",
        "        ch = 0\n",
        "    sig = rec.p_signal[:, ch].astype(np.float32)\n",
        "    fs = int(rec.fs)\n",
        "    if fs != fs_target:\n",
        "        sig = processing.resample_sig(sig, fs, fs_target)[0]\n",
        "        fs = fs_target\n",
        "    return sig, fs\n",
        "\n",
        "def extract_segments(record_num, label, win_samples=WIN_SAMPLES):\n",
        "    \"\"\"\n",
        "    Extract 10s windows centered on annotated beats of a given label.\n",
        "\n",
        "    Label mapping (MIT-BIH symbols):\n",
        "      NOR: 'N'\n",
        "      LBB: 'L'\n",
        "      RBB: 'R'\n",
        "      PVC: 'V'\n",
        "      APC: 'A' or 'a'\n",
        "    \"\"\"\n",
        "    sig, fs = read_signal(record_num)\n",
        "    ann = wfdb.rdann(str(record_num), \"atr\", pn_dir=\"mitdb\")\n",
        "\n",
        "    out = []\n",
        "    for idx, sym in zip(ann.sample, ann.symbol):\n",
        "        if   label == \"NOR\" and sym == \"N\": center = idx\n",
        "        elif label == \"LBB\" and sym == \"L\": center = idx\n",
        "        elif label == \"RBB\" and sym == \"R\": center = idx\n",
        "        elif label == \"PVC\" and sym == \"V\": center = idx\n",
        "        elif label == \"APC\" and sym in (\"A\",\"a\"): center = idx\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        # 10s window centered on the beat\n",
        "        start = max(center - win_samples//2, 0)\n",
        "        end   = start + win_samples\n",
        "        if end <= len(sig):\n",
        "            out.append(sig[start:end])\n",
        "    return out\n",
        "\n",
        "# Build pools per class\n",
        "pool = {cls: [] for cls in RECORDS}\n",
        "for cls, recs in RECORDS.items():\n",
        "    for r in recs:\n",
        "        pool[cls].extend(extract_segments(r, cls))\n",
        "    print(f\"{cls}: segments extracted = {len(pool[cls])}\")\n",
        "\n",
        "# ---------------------------------------\n",
        "# 2) Paper's fixed train/test split (1D)\n",
        "# ---------------------------------------\n",
        "rng = np.random.default_rng(SEED)\n",
        "\n",
        "def take_n(lst, n):\n",
        "    idx = rng.choice(len(lst), size=min(n, len(lst)), replace=False)\n",
        "    return [lst[i] for i in idx]\n",
        "\n",
        "train_X_1d, train_y = [], []\n",
        "test_X_1d,  test_y  = [], []\n",
        "\n",
        "for cls in [\"NOR\",\"LBB\",\"RBB\",\"APC\",\"PVC\"]:\n",
        "    tr_n, te_n = TARGET_TRAIN[cls], TARGET_TEST[cls]\n",
        "    cls_pool = pool[cls]\n",
        "\n",
        "    train_segs = take_n(cls_pool, tr_n)\n",
        "    chosen = set(id(x) for x in train_segs)\n",
        "\n",
        "    remaining = [x for x in cls_pool if id(x) not in chosen]\n",
        "    test_segs = take_n(remaining, te_n)\n",
        "\n",
        "    train_X_1d += train_segs\n",
        "    train_y    += [class_to_idx[cls]] * len(train_segs)\n",
        "    test_X_1d  += test_segs\n",
        "    test_y     += [class_to_idx[cls]] * len(test_segs)\n",
        "\n",
        "# Arrays\n",
        "train_X_1d = np.stack(train_X_1d)  # [N, 3600]\n",
        "test_X_1d  = np.stack(test_X_1d)\n",
        "train_y    = np.array(train_y, dtype=np.int64)\n",
        "test_y     = np.array(test_y, dtype=np.int64)\n",
        "\n",
        "print(\"Train:\", train_X_1d.shape, {k:int((train_y==v).sum()) for k,v in class_to_idx.items()})\n",
        "print(\"Test :\", test_X_1d.shape,  {k:int((test_y==v).sum()) for k,v in class_to_idx.items()})\n",
        "\n",
        "# Optional: small counts table\n",
        "try:\n",
        "    import pandas as pd\n",
        "    df = pd.DataFrame({\n",
        "        \"Train\":[int((train_y==class_to_idx[c]).sum()) for c in class_to_idx],\n",
        "        \"Test\":[int((test_y==class_to_idx[c]).sum()) for c in class_to_idx]\n",
        "    }, index=list(class_to_idx.keys()))\n",
        "    df[\"Total\"] = df[\"Train\"]+df[\"Test\"]\n",
        "    display(df)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# ------------------------------------------\n",
        "# 3) STFT -> 256x256 grayscale spectrograms\n",
        "# ------------------------------------------\n",
        "from PIL import Image\n",
        "from scipy import signal\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "def stft_to_image(seg, fs=FS):\n",
        "    \"\"\"\n",
        "    STFT with symmetric Hann (Hanning) window of 512 (paper),\n",
        "    50% overlap, magnitude -> dB -> [0,255], resized to 256x256.\n",
        "    \"\"\"\n",
        "    hann_sym = signal.windows.hann(STFT_NPERSEG, sym=True)\n",
        "    f, t, Z = signal.stft(\n",
        "        seg, fs=fs,\n",
        "        window=hann_sym,\n",
        "        nperseg=STFT_NPERSEG,\n",
        "        noverlap=STFT_NOVERLAP,\n",
        "        nfft=STFT_NPERSEG,\n",
        "        boundary=None,\n",
        "        padded=False\n",
        "    )\n",
        "    S = np.abs(Z) + 1e-12\n",
        "    S_db = 20*np.log10(S / S.max())\n",
        "    S01 = (S_db - S_db.min()) / (S_db.max() - S_db.min() + 1e-12)\n",
        "    img = Image.fromarray((S01*255).astype(np.uint8)).resize((SPEC_SIZE, SPEC_SIZE), Image.BICUBIC)\n",
        "    return np.array(img, np.uint8)\n",
        "\n",
        "def make_spec_set(X_1d, y):\n",
        "    imgs = [stft_to_image(seg, FS) for seg in X_1d]\n",
        "    X = np.expand_dims(np.array(imgs, np.float32)/255.0, axis=-1)  # [N,H,W,1]\n",
        "    Y = to_categorical(y, num_classes=5)\n",
        "    return X, Y\n",
        "\n",
        "train_X_2d, train_y_oh = make_spec_set(train_X_1d, train_y)\n",
        "test_X_2d,  test_y_oh  = make_spec_set(test_X_1d,  test_y)\n",
        "print(\"Train 2D:\", train_X_2d.shape, \"Test 2D:\", test_X_2d.shape)\n",
        "\n",
        "# Optional: free 1D arrays to save RAM\n",
        "import gc\n",
        "del train_X_1d, test_X_1d\n",
        "gc.collect()\n",
        "\n",
        "# (Optional) Save spectrogram tensors so restarts don't hurt\n",
        "# np.savez_compressed(\"ecg_spectros.npz\",\n",
        "#     train_X_2d=train_X_2d, train_y_oh=train_y_oh,\n",
        "#     test_X_2d=test_X_2d,   test_y_oh=test_y_oh\n",
        "# )\n",
        "\n",
        "# ---------------------------\n",
        "# 4) 2D-CNN (paper structure)\n",
        "# ---------------------------\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def make_2d_cnn(input_shape=(SPEC_SIZE, SPEC_SIZE, 1), num_classes=5):\n",
        "    x = inp = keras.Input(shape=input_shape)\n",
        "    x = layers.Conv2D(8, (4,4), activation='relu', padding='same')(x)\n",
        "    x = layers.MaxPooling2D((2,2))(x)\n",
        "    x = layers.Conv2D(13, (2,2), activation='relu', padding='same')(x)\n",
        "    x = layers.MaxPooling2D((2,2))(x)\n",
        "    x = layers.Conv2D(13, (2,2), activation='relu', padding='same')(x)\n",
        "    x = layers.MaxPooling2D((2,2))(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(64, activation='relu')(x)  # dense width not fixed by paper; 64 is a sensible choice\n",
        "    out = layers.Dense(num_classes, activation='softmax')(x)\n",
        "    return keras.Model(inp, out, name=\"ECG_2D_CNN\")\n",
        "\n",
        "model_2d = make_2d_cnn()\n",
        "model_2d.summary()\n",
        "\n",
        "# ------------------------------------\n",
        "# 5) Train (paper LR/epochs; safe Bsz)\n",
        "# ------------------------------------\n",
        "LR = 0.001       # paper\n",
        "EPOCHS = 100     # paper \"iterations\"\n",
        "BATCH = 1000   # practical; paper used 2500 (too big for most GPUs)\n",
        "\n",
        "# (Optional) Mixed precision if VRAM is tight (uncomment next 3 lines)\n",
        "# from tensorflow.keras import mixed_precision\n",
        "# mixed_precision.set_global_policy('mixed_float16')\n",
        "# train_X_2d, test_X_2d = train_X_2d.astype('float16'), test_X_2d.astype('float16')\n",
        "\n",
        "# Safety: ensure tensors exist if the runtime was restarted\n",
        "try:\n",
        "    _ = train_X_2d.shape; _ = test_X_2d.shape; _ = train_y_oh.shape; _ = test_y_oh.shape\n",
        "except NameError:\n",
        "    # Uncomment this if you saved earlier:\n",
        "    # data = np.load(\"ecg_spectros.npz\")\n",
        "    # train_X_2d, train_y_oh = data[\"train_X_2d\"], data[\"train_y_oh\"]\n",
        "    # test_X_2d,  test_y_oh  = data[\"test_X_2d\"],  data[\"test_y_oh\"]\n",
        "    # Or rebuild:\n",
        "    train_X_2d, train_y_oh = make_spec_set(train_X_1d, train_y)\n",
        "    test_X_2d,  test_y_oh  = make_spec_set(test_X_1d,  test_y)\n",
        "\n",
        "# Helpful callbacks (optional but recommended)\n",
        "cbs = [\n",
        "    #keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True),\n",
        "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
        "]\n",
        "\n",
        "model_2d.compile(optimizer=keras.optimizers.Adam(learning_rate=LR),\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "hist_2d = model_2d.fit(\n",
        "    train_X_2d, train_y_oh,\n",
        "    validation_data=(test_X_2d, test_y_oh),\n",
        "    epochs=EPOCHS, batch_size=BATCH, verbose=1,\n",
        "    callbacks=cbs\n",
        ")\n",
        "\n",
        "# -------------------------\n",
        "# 6) Report & quick plots\n",
        "# -------------------------\n",
        "# Averages / best epoch\n",
        "tr_acc = np.array(hist_2d.history['accuracy'])\n",
        "vl_acc = np.array(hist_2d.history['val_accuracy'])\n",
        "tr_loss = np.array(hist_2d.history['loss'])\n",
        "vl_loss = np.array(hist_2d.history['val_loss'])\n",
        "\n",
        "print(f\"\\nFinal train acc: {tr_acc[-1]*100:.2f}% | Final val acc: {vl_acc[-1]*100:.2f}%\")\n",
        "print(f\"Avg  train acc : {tr_acc.mean()*100:.2f}% | Avg  val acc : {vl_acc.mean()*100:.2f}%\")\n",
        "print(f\"Best val acc   : {vl_acc.max()*100:.2f}% (epoch {vl_acc.argmax()+1})\")\n",
        "print(f\"Final loss     : train {tr_loss[-1]:.4f} | val {vl_loss[-1]:.4f}\")\n",
        "\n",
        "# Optional: exact paper metrics on TEST set\n",
        "y_prob = model_2d.predict(test_X_2d, verbose=0)\n",
        "y_pred = y_prob.argmax(axis=1)\n",
        "y_true = test_y_oh.argmax(axis=1)\n",
        "\n",
        "acc_pct = (y_pred == y_true).mean()*100.0\n",
        "eps = 1e-7\n",
        "ce = -np.sum(test_y_oh * np.log(np.clip(y_prob, eps, 1-eps)), axis=1).mean()\n",
        "\n",
        "print(f\"\\n[Paper metrics] Test accuracy: {acc_pct:.2f}% | Cross-entropy: {ce:.6f}\")\n",
        "\n",
        "# Confusion matrix (uses sklearn if available)\n",
        "try:\n",
        "    from sklearn.metrics import confusion_matrix, classification_report\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[0,1,2,3,4])\n",
        "    print(\"\\nClassification report:\\n\",\n",
        "          classification_report(y_true, y_pred, target_names=[idx_to_class[i] for i in range(5)], digits=4))\n",
        "    # Basic text CM (no seaborn)\n",
        "    print(\"Confusion matrix:\\n\", cm)\n",
        "except Exception:\n",
        "    pass\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Sa0ntvL1rZd3",
        "outputId": "fccb4e94-c586-4bda-cc79-af999e2298c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config ready.\n",
            "NOR: segments extracted = 7936\n",
            "LBB: segments extracted = 6600\n",
            "RBB: segments extracted = 5513\n",
            "PVC: segments extracted = 1347\n",
            "APC: segments extracted = 1860\n",
            "Train: (2100, 3600) {'NOR': 450, 'LBB': 450, 'RBB': 450, 'PVC': 300, 'APC': 450}\n",
            "Test : (420, 3600) {'NOR': 90, 'LBB': 90, 'RBB': 90, 'PVC': 60, 'APC': 90}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     Train  Test  Total\n",
              "NOR    450    90    540\n",
              "LBB    450    90    540\n",
              "RBB    450    90    540\n",
              "PVC    300    60    360\n",
              "APC    450    90    540"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-547ef0b5-595f-4a5a-bc8b-d393feaae548\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train</th>\n",
              "      <th>Test</th>\n",
              "      <th>Total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>NOR</th>\n",
              "      <td>450</td>\n",
              "      <td>90</td>\n",
              "      <td>540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LBB</th>\n",
              "      <td>450</td>\n",
              "      <td>90</td>\n",
              "      <td>540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RBB</th>\n",
              "      <td>450</td>\n",
              "      <td>90</td>\n",
              "      <td>540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PVC</th>\n",
              "      <td>300</td>\n",
              "      <td>60</td>\n",
              "      <td>360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>APC</th>\n",
              "      <td>450</td>\n",
              "      <td>90</td>\n",
              "      <td>540</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-547ef0b5-595f-4a5a-bc8b-d393feaae548')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-547ef0b5-595f-4a5a-bc8b-d393feaae548 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-547ef0b5-595f-4a5a-bc8b-d393feaae548');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-564b764c-2e16-4766-99bc-6677fbadc877\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-564b764c-2e16-4766-99bc-6677fbadc877')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-564b764c-2e16-4766-99bc-6677fbadc877 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_67fea1a5-b8ba-4789-83d6-c37b5b1adbe4\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_67fea1a5-b8ba-4789-83d6-c37b5b1adbe4 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Train\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 67,\n        \"min\": 300,\n        \"max\": 450,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          300,\n          450\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13,\n        \"min\": 60,\n        \"max\": 90,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          60,\n          90\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 80,\n        \"min\": 360,\n        \"max\": 540,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          360,\n          540\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train 2D: (2100, 256, 256, 1) Test 2D: (420, 256, 256, 1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"ECG_2D_CNN\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"ECG_2D_CNN\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │           \u001b[38;5;34m136\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_15 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m13\u001b[0m)   │           \u001b[38;5;34m429\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_16 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m13\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m13\u001b[0m)     │           \u001b[38;5;34m689\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_17 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m13\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_5 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13312\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m852,032\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m325\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">429</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">689</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13312</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">852,032</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m853,611\u001b[0m (3.26 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">853,611</span> (3.26 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m853,611\u001b[0m (3.26 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">853,611</span> (3.26 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5s/step - accuracy: 0.2186 - loss: 1.6148 - val_accuracy: 0.2143 - val_loss: 1.6012 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 327ms/step - accuracy: 0.2141 - loss: 1.6010 - val_accuracy: 0.2143 - val_loss: 1.5984 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 325ms/step - accuracy: 0.2141 - loss: 1.5963 - val_accuracy: 0.2143 - val_loss: 1.5933 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 327ms/step - accuracy: 0.2186 - loss: 1.5909 - val_accuracy: 0.4143 - val_loss: 1.5870 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 325ms/step - accuracy: 0.4079 - loss: 1.5837 - val_accuracy: 0.3167 - val_loss: 1.5791 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 423ms/step - accuracy: 0.2808 - loss: 1.5743 - val_accuracy: 0.2738 - val_loss: 1.5688 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 356ms/step - accuracy: 0.2856 - loss: 1.5625 - val_accuracy: 0.4048 - val_loss: 1.5533 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 326ms/step - accuracy: 0.4191 - loss: 1.5427 - val_accuracy: 0.4476 - val_loss: 1.5290 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 329ms/step - accuracy: 0.4379 - loss: 1.5151 - val_accuracy: 0.4190 - val_loss: 1.4959 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 325ms/step - accuracy: 0.4362 - loss: 1.4762 - val_accuracy: 0.5357 - val_loss: 1.4516 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 324ms/step - accuracy: 0.5813 - loss: 1.4241 - val_accuracy: 0.6286 - val_loss: 1.4089 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 324ms/step - accuracy: 0.6352 - loss: 1.3736 - val_accuracy: 0.5833 - val_loss: 1.3449 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 327ms/step - accuracy: 0.5964 - loss: 1.3215 - val_accuracy: 0.5738 - val_loss: 1.2999 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 324ms/step - accuracy: 0.6081 - loss: 1.2606 - val_accuracy: 0.6595 - val_loss: 1.2423 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 347ms/step - accuracy: 0.6451 - loss: 1.1995 - val_accuracy: 0.6429 - val_loss: 1.2408 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 430ms/step - accuracy: 0.6090 - loss: 1.1713 - val_accuracy: 0.6643 - val_loss: 1.2466 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 326ms/step - accuracy: 0.6777 - loss: 1.1527 - val_accuracy: 0.6857 - val_loss: 1.1215 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 324ms/step - accuracy: 0.6950 - loss: 1.1068 - val_accuracy: 0.6071 - val_loss: 1.1014 - learning_rate: 0.0010\n",
            "Epoch 19/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 328ms/step - accuracy: 0.6171 - loss: 1.0409 - val_accuracy: 0.6810 - val_loss: 1.1155 - learning_rate: 0.0010\n",
            "Epoch 20/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 327ms/step - accuracy: 0.7062 - loss: 1.0240 - val_accuracy: 0.7071 - val_loss: 0.9902 - learning_rate: 0.0010\n",
            "Epoch 21/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 327ms/step - accuracy: 0.7332 - loss: 0.9580 - val_accuracy: 0.7048 - val_loss: 0.9554 - learning_rate: 0.0010\n",
            "Epoch 22/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 322ms/step - accuracy: 0.7283 - loss: 0.9041 - val_accuracy: 0.7214 - val_loss: 0.9981 - learning_rate: 0.0010\n",
            "Epoch 23/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 329ms/step - accuracy: 0.7418 - loss: 0.9012 - val_accuracy: 0.7452 - val_loss: 0.8898 - learning_rate: 0.0010\n",
            "Epoch 24/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 356ms/step - accuracy: 0.7688 - loss: 0.8427 - val_accuracy: 0.7381 - val_loss: 0.8580 - learning_rate: 0.0010\n",
            "Epoch 25/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 344ms/step - accuracy: 0.7639 - loss: 0.7909 - val_accuracy: 0.7452 - val_loss: 0.8940 - learning_rate: 0.0010\n",
            "Epoch 26/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 327ms/step - accuracy: 0.7695 - loss: 0.8012 - val_accuracy: 0.7786 - val_loss: 0.8200 - learning_rate: 0.0010\n",
            "Epoch 27/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 327ms/step - accuracy: 0.7866 - loss: 0.7521 - val_accuracy: 0.7905 - val_loss: 0.7668 - learning_rate: 0.0010\n",
            "Epoch 28/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 326ms/step - accuracy: 0.8006 - loss: 0.6997 - val_accuracy: 0.7524 - val_loss: 0.7826 - learning_rate: 0.0010\n",
            "Epoch 29/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 330ms/step - accuracy: 0.7675 - loss: 0.7203 - val_accuracy: 0.6619 - val_loss: 1.0991 - learning_rate: 0.0010\n",
            "Epoch 30/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 325ms/step - accuracy: 0.6858 - loss: 0.9488 - val_accuracy: 0.7452 - val_loss: 0.8189 - learning_rate: 0.0010\n",
            "Epoch 31/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 324ms/step - accuracy: 0.7661 - loss: 0.7689 - val_accuracy: 0.7881 - val_loss: 0.7502 - learning_rate: 0.0010\n",
            "Epoch 32/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 326ms/step - accuracy: 0.7684 - loss: 0.7338 - val_accuracy: 0.8167 - val_loss: 0.7507 - learning_rate: 0.0010\n",
            "Epoch 33/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 418ms/step - accuracy: 0.7746 - loss: 0.6958 - val_accuracy: 0.7095 - val_loss: 0.7785 - learning_rate: 0.0010\n",
            "Epoch 34/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 330ms/step - accuracy: 0.7539 - loss: 0.6802 - val_accuracy: 0.7548 - val_loss: 0.7839 - learning_rate: 0.0010\n",
            "Epoch 35/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 324ms/step - accuracy: 0.8039 - loss: 0.6672 - val_accuracy: 0.8143 - val_loss: 0.6619 - learning_rate: 0.0010\n",
            "Epoch 36/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 330ms/step - accuracy: 0.8219 - loss: 0.6154 - val_accuracy: 0.7833 - val_loss: 0.6805 - learning_rate: 0.0010\n",
            "Epoch 37/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 328ms/step - accuracy: 0.8048 - loss: 0.6115 - val_accuracy: 0.7881 - val_loss: 0.6664 - learning_rate: 0.0010\n",
            "Epoch 38/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 326ms/step - accuracy: 0.8211 - loss: 0.5971 - val_accuracy: 0.8048 - val_loss: 0.6329 - learning_rate: 0.0010\n",
            "Epoch 39/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 327ms/step - accuracy: 0.8331 - loss: 0.5631 - val_accuracy: 0.8190 - val_loss: 0.6570 - learning_rate: 0.0010\n",
            "Epoch 40/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 331ms/step - accuracy: 0.8402 - loss: 0.5691 - val_accuracy: 0.8143 - val_loss: 0.6324 - learning_rate: 0.0010\n",
            "Epoch 41/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 327ms/step - accuracy: 0.8418 - loss: 0.5490 - val_accuracy: 0.8167 - val_loss: 0.6202 - learning_rate: 0.0010\n",
            "Epoch 42/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 353ms/step - accuracy: 0.8437 - loss: 0.5448 - val_accuracy: 0.8286 - val_loss: 0.5976 - learning_rate: 0.0010\n",
            "Epoch 43/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 330ms/step - accuracy: 0.8525 - loss: 0.5280 - val_accuracy: 0.8238 - val_loss: 0.5895 - learning_rate: 0.0010\n",
            "Epoch 44/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 326ms/step - accuracy: 0.8512 - loss: 0.5293 - val_accuracy: 0.8286 - val_loss: 0.5785 - learning_rate: 0.0010\n",
            "Epoch 45/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 327ms/step - accuracy: 0.8479 - loss: 0.5199 - val_accuracy: 0.8214 - val_loss: 0.5800 - learning_rate: 0.0010\n",
            "Epoch 46/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 324ms/step - accuracy: 0.8497 - loss: 0.5213 - val_accuracy: 0.8238 - val_loss: 0.5666 - learning_rate: 0.0010\n",
            "Epoch 47/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 327ms/step - accuracy: 0.8483 - loss: 0.5173 - val_accuracy: 0.8286 - val_loss: 0.5637 - learning_rate: 0.0010\n",
            "Epoch 48/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 329ms/step - accuracy: 0.8455 - loss: 0.5163 - val_accuracy: 0.8238 - val_loss: 0.5776 - learning_rate: 0.0010\n",
            "Epoch 49/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 326ms/step - accuracy: 0.8317 - loss: 0.5359 - val_accuracy: 0.8071 - val_loss: 0.5945 - learning_rate: 0.0010\n",
            "Epoch 50/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 334ms/step - accuracy: 0.8046 - loss: 0.5651 - val_accuracy: 0.7333 - val_loss: 0.6619 - learning_rate: 0.0010\n",
            "Epoch 51/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 427ms/step - accuracy: 0.7685 - loss: 0.6229 - val_accuracy: 0.6952 - val_loss: 0.6944 - learning_rate: 0.0010\n",
            "Epoch 52/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 332ms/step - accuracy: 0.7825 - loss: 0.6050 - val_accuracy: 0.8048 - val_loss: 0.5866 - learning_rate: 0.0010\n",
            "Epoch 53/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 336ms/step - accuracy: 0.8278 - loss: 0.5126 - val_accuracy: 0.8143 - val_loss: 0.5877 - learning_rate: 5.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 329ms/step - accuracy: 0.8626 - loss: 0.4813 - val_accuracy: 0.8286 - val_loss: 0.5546 - learning_rate: 5.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 327ms/step - accuracy: 0.8471 - loss: 0.4816 - val_accuracy: 0.8381 - val_loss: 0.5585 - learning_rate: 5.0000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 328ms/step - accuracy: 0.8718 - loss: 0.4557 - val_accuracy: 0.8452 - val_loss: 0.5159 - learning_rate: 5.0000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 326ms/step - accuracy: 0.8638 - loss: 0.4541 - val_accuracy: 0.8524 - val_loss: 0.5313 - learning_rate: 5.0000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 327ms/step - accuracy: 0.8838 - loss: 0.4411 - val_accuracy: 0.8548 - val_loss: 0.4959 - learning_rate: 5.0000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 326ms/step - accuracy: 0.8814 - loss: 0.4371 - val_accuracy: 0.8571 - val_loss: 0.5088 - learning_rate: 5.0000e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 425ms/step - accuracy: 0.8859 - loss: 0.4301 - val_accuracy: 0.8548 - val_loss: 0.4850 - learning_rate: 5.0000e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 327ms/step - accuracy: 0.8874 - loss: 0.4247 - val_accuracy: 0.8643 - val_loss: 0.4931 - learning_rate: 5.0000e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 326ms/step - accuracy: 0.8859 - loss: 0.4221 - val_accuracy: 0.8571 - val_loss: 0.4826 - learning_rate: 5.0000e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 331ms/step - accuracy: 0.8896 - loss: 0.4168 - val_accuracy: 0.8548 - val_loss: 0.4837 - learning_rate: 5.0000e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 328ms/step - accuracy: 0.8846 - loss: 0.4159 - val_accuracy: 0.8619 - val_loss: 0.4804 - learning_rate: 5.0000e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 326ms/step - accuracy: 0.8904 - loss: 0.4102 - val_accuracy: 0.8571 - val_loss: 0.4757 - learning_rate: 5.0000e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 328ms/step - accuracy: 0.8857 - loss: 0.4094 - val_accuracy: 0.8643 - val_loss: 0.4750 - learning_rate: 5.0000e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 334ms/step - accuracy: 0.8909 - loss: 0.4039 - val_accuracy: 0.8643 - val_loss: 0.4686 - learning_rate: 5.0000e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 326ms/step - accuracy: 0.8891 - loss: 0.4031 - val_accuracy: 0.8643 - val_loss: 0.4670 - learning_rate: 5.0000e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 353ms/step - accuracy: 0.8947 - loss: 0.3980 - val_accuracy: 0.8643 - val_loss: 0.4624 - learning_rate: 5.0000e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 332ms/step - accuracy: 0.8929 - loss: 0.3964 - val_accuracy: 0.8643 - val_loss: 0.4591 - learning_rate: 5.0000e-04\n",
            "Epoch 71/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 326ms/step - accuracy: 0.8946 - loss: 0.3925 - val_accuracy: 0.8690 - val_loss: 0.4562 - learning_rate: 5.0000e-04\n",
            "Epoch 72/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 327ms/step - accuracy: 0.8958 - loss: 0.3895 - val_accuracy: 0.8714 - val_loss: 0.4506 - learning_rate: 5.0000e-04\n",
            "Epoch 73/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 327ms/step - accuracy: 0.8958 - loss: 0.3853 - val_accuracy: 0.8786 - val_loss: 0.4479 - learning_rate: 5.0000e-04\n",
            "Epoch 74/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 325ms/step - accuracy: 0.8968 - loss: 0.3815 - val_accuracy: 0.8714 - val_loss: 0.4475 - learning_rate: 5.0000e-04\n",
            "Epoch 75/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 329ms/step - accuracy: 0.8971 - loss: 0.3799 - val_accuracy: 0.8738 - val_loss: 0.4398 - learning_rate: 5.0000e-04\n",
            "Epoch 76/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 328ms/step - accuracy: 0.8988 - loss: 0.3753 - val_accuracy: 0.8738 - val_loss: 0.4401 - learning_rate: 5.0000e-04\n",
            "Epoch 77/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 331ms/step - accuracy: 0.8990 - loss: 0.3734 - val_accuracy: 0.8810 - val_loss: 0.4337 - learning_rate: 5.0000e-04\n",
            "Epoch 78/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 424ms/step - accuracy: 0.9000 - loss: 0.3698 - val_accuracy: 0.8833 - val_loss: 0.4351 - learning_rate: 5.0000e-04\n",
            "Epoch 79/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 327ms/step - accuracy: 0.8990 - loss: 0.3679 - val_accuracy: 0.8833 - val_loss: 0.4289 - learning_rate: 5.0000e-04\n",
            "Epoch 80/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 331ms/step - accuracy: 0.8996 - loss: 0.3644 - val_accuracy: 0.8833 - val_loss: 0.4277 - learning_rate: 5.0000e-04\n",
            "Epoch 81/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 327ms/step - accuracy: 0.9002 - loss: 0.3620 - val_accuracy: 0.8857 - val_loss: 0.4231 - learning_rate: 5.0000e-04\n",
            "Epoch 82/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 327ms/step - accuracy: 0.9019 - loss: 0.3588 - val_accuracy: 0.8833 - val_loss: 0.4219 - learning_rate: 5.0000e-04\n",
            "Epoch 83/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 327ms/step - accuracy: 0.9025 - loss: 0.3566 - val_accuracy: 0.8833 - val_loss: 0.4185 - learning_rate: 5.0000e-04\n",
            "Epoch 84/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 325ms/step - accuracy: 0.9047 - loss: 0.3540 - val_accuracy: 0.8881 - val_loss: 0.4168 - learning_rate: 5.0000e-04\n",
            "Epoch 85/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 327ms/step - accuracy: 0.9032 - loss: 0.3513 - val_accuracy: 0.8833 - val_loss: 0.4124 - learning_rate: 5.0000e-04\n",
            "Epoch 86/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 330ms/step - accuracy: 0.9063 - loss: 0.3488 - val_accuracy: 0.8857 - val_loss: 0.4109 - learning_rate: 5.0000e-04\n",
            "Epoch 87/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 354ms/step - accuracy: 0.9054 - loss: 0.3460 - val_accuracy: 0.8857 - val_loss: 0.4077 - learning_rate: 5.0000e-04\n",
            "Epoch 88/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 328ms/step - accuracy: 0.9071 - loss: 0.3437 - val_accuracy: 0.8857 - val_loss: 0.4054 - learning_rate: 5.0000e-04\n",
            "Epoch 89/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 327ms/step - accuracy: 0.9058 - loss: 0.3410 - val_accuracy: 0.8857 - val_loss: 0.4029 - learning_rate: 5.0000e-04\n",
            "Epoch 90/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 328ms/step - accuracy: 0.9078 - loss: 0.3387 - val_accuracy: 0.8905 - val_loss: 0.4000 - learning_rate: 5.0000e-04\n",
            "Epoch 91/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 325ms/step - accuracy: 0.9066 - loss: 0.3360 - val_accuracy: 0.8881 - val_loss: 0.3975 - learning_rate: 5.0000e-04\n",
            "Epoch 92/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 328ms/step - accuracy: 0.9077 - loss: 0.3337 - val_accuracy: 0.8929 - val_loss: 0.3946 - learning_rate: 5.0000e-04\n",
            "Epoch 93/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 328ms/step - accuracy: 0.9067 - loss: 0.3310 - val_accuracy: 0.8905 - val_loss: 0.3931 - learning_rate: 5.0000e-04\n",
            "Epoch 94/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 331ms/step - accuracy: 0.9093 - loss: 0.3291 - val_accuracy: 0.8905 - val_loss: 0.3896 - learning_rate: 5.0000e-04\n",
            "Epoch 95/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 326ms/step - accuracy: 0.9102 - loss: 0.3262 - val_accuracy: 0.8929 - val_loss: 0.3872 - learning_rate: 5.0000e-04\n",
            "Epoch 96/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 350ms/step - accuracy: 0.9102 - loss: 0.3237 - val_accuracy: 0.8905 - val_loss: 0.3846 - learning_rate: 5.0000e-04\n",
            "Epoch 97/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 334ms/step - accuracy: 0.9110 - loss: 0.3215 - val_accuracy: 0.8929 - val_loss: 0.3824 - learning_rate: 5.0000e-04\n",
            "Epoch 98/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 328ms/step - accuracy: 0.9127 - loss: 0.3190 - val_accuracy: 0.8929 - val_loss: 0.3798 - learning_rate: 5.0000e-04\n",
            "Epoch 99/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 325ms/step - accuracy: 0.9123 - loss: 0.3166 - val_accuracy: 0.8952 - val_loss: 0.3770 - learning_rate: 5.0000e-04\n",
            "Epoch 100/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 327ms/step - accuracy: 0.9127 - loss: 0.3141 - val_accuracy: 0.8929 - val_loss: 0.3748 - learning_rate: 5.0000e-04\n",
            "\n",
            "Final train acc: 91.38% | Final val acc: 89.29%\n",
            "Avg  train acc : 78.03% | Avg  val acc : 76.71%\n",
            "Best val acc   : 89.52% (epoch 99)\n",
            "Final loss     : train 0.3110 | val 0.3748\n",
            "\n",
            "[Paper metrics] Test accuracy: 89.29% | Cross-entropy: 0.374829\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         NOR     0.8700    0.9667    0.9158        90\n",
            "         LBB     0.8723    0.9111    0.8913        90\n",
            "         RBB     0.9865    0.8111    0.8902        90\n",
            "         PVC     0.7121    0.7833    0.7460        60\n",
            "         APC     1.0000    0.9556    0.9773        90\n",
            "\n",
            "    accuracy                         0.8929       420\n",
            "   macro avg     0.8882    0.8856    0.8841       420\n",
            "weighted avg     0.9008    0.8929    0.8940       420\n",
            "\n",
            "Confusion matrix:\n",
            " [[87  1  0  2  0]\n",
            " [ 1 82  0  7  0]\n",
            " [ 7  0 73 10  0]\n",
            " [ 4  8  1 47  0]\n",
            " [ 1  3  0  0 86]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# full code with different batch sizes"
      ],
      "metadata": {
        "id": "CIDN9gHO5Pqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# ECG Arrhythmia Classification (Paper-faithful full pipeline)\n",
        "# MIT-BIH: STFT (512 Hann) -> 256x256 spectrogram -> 2D-CNN\n",
        "# ============================================================\n",
        "\n",
        "# -------------------------\n",
        "# 0) Config & dependencies\n",
        "# -------------------------\n",
        "import os, random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import wfdb\n",
        "from wfdb import processing\n",
        "\n",
        "# Reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\n",
        "\n",
        "# Records per class (from the paper)\n",
        "RECORDS = {\n",
        "    \"NOR\": [100, 105, 215],\n",
        "    \"LBB\": [109, 111, 214],\n",
        "    \"RBB\": [118, 124, 212],\n",
        "    \"PVC\": [106, 233],\n",
        "    \"APC\": [207, 209, 232]\n",
        "}\n",
        "\n",
        "# Target split\n",
        "TARGET_TRAIN = {\"NOR\":450, \"LBB\":450, \"RBB\":450, \"APC\":450, \"PVC\":300}\n",
        "TARGET_TEST  = {\"NOR\": 90, \"LBB\": 90, \"RBB\": 90, \"APC\": 90, \"PVC\": 60}\n",
        "\n",
        "# Sampling\n",
        "FS = 360\n",
        "WIN_SEC = 10\n",
        "WIN_SAMPLES = FS * WIN_SEC\n",
        "\n",
        "# STFT params\n",
        "STFT_NPERSEG  = 512\n",
        "STFT_NOVERLAP = 256\n",
        "SPEC_SIZE     = 256\n",
        "\n",
        "# Class mapping\n",
        "class_to_idx = {\"NOR\":0, \"LBB\":1, \"RBB\":2, \"PVC\":3, \"APC\":4}\n",
        "idx_to_class = {v:k for k,v in class_to_idx.items()}\n",
        "\n",
        "print(\"Config ready.\")\n",
        "\n",
        "# ------------------------------------------\n",
        "# 1) Read signals & extract labeled segments\n",
        "# ------------------------------------------\n",
        "def read_signal(record_num, fs_target=FS):\n",
        "    rec = wfdb.rdrecord(str(record_num), pn_dir=\"mitdb\")\n",
        "    names = [n.lower() for n in rec.sig_name]\n",
        "    if \"v5\" in names: ch = names.index(\"v5\")\n",
        "    elif \"mlii\" in names: ch = names.index(\"mlii\")\n",
        "    else: ch = 0\n",
        "    sig = rec.p_signal[:, ch].astype(np.float32)\n",
        "    fs = int(rec.fs)\n",
        "    if fs != fs_target:\n",
        "        sig = processing.resample_sig(sig, fs, fs_target)[0]\n",
        "    return sig, fs_target\n",
        "\n",
        "def extract_segments(record_num, label, win_samples=WIN_SAMPLES):\n",
        "    sig, fs = read_signal(record_num)\n",
        "    ann = wfdb.rdann(str(record_num), \"atr\", pn_dir=\"mitdb\")\n",
        "\n",
        "    out = []\n",
        "    for idx, sym in zip(ann.sample, ann.symbol):\n",
        "        if   label==\"NOR\" and sym==\"N\": center = idx\n",
        "        elif label==\"LBB\" and sym==\"L\": center = idx\n",
        "        elif label==\"RBB\" and sym==\"R\": center = idx\n",
        "        elif label==\"PVC\" and sym==\"V\": center = idx\n",
        "        elif label==\"APC\" and sym in (\"A\",\"a\"): center = idx\n",
        "        else: continue\n",
        "\n",
        "        start = max(center - win_samples//2, 0)\n",
        "        end   = start + win_samples\n",
        "        if end <= len(sig):\n",
        "            out.append(sig[start:end])\n",
        "    return out\n",
        "\n",
        "# Build pools per class\n",
        "pool = {cls: [] for cls in RECORDS}\n",
        "for cls, recs in RECORDS.items():\n",
        "    for r in recs:\n",
        "        pool[cls].extend(extract_segments(r, cls))\n",
        "    print(f\"{cls}: segments extracted = {len(pool[cls])}\")\n",
        "\n",
        "# ---------------------------------------\n",
        "# 2) Paper's fixed train/test split (1D)\n",
        "# ---------------------------------------\n",
        "rng = np.random.default_rng(SEED)\n",
        "\n",
        "def take_n(lst, n):\n",
        "    idx = rng.choice(len(lst), size=min(n, len(lst)), replace=False)\n",
        "    return [lst[i] for i in idx]\n",
        "\n",
        "train_X_1d, train_y = [], []\n",
        "test_X_1d,  test_y  = [], []\n",
        "\n",
        "for cls in [\"NOR\",\"LBB\",\"RBB\",\"APC\",\"PVC\"]:\n",
        "    tr_n, te_n = TARGET_TRAIN[cls], TARGET_TEST[cls]\n",
        "    cls_pool = pool[cls]\n",
        "\n",
        "    train_segs = take_n(cls_pool, tr_n)\n",
        "    chosen = set(id(x) for x in train_segs)\n",
        "    remaining = [x for x in cls_pool if id(x) not in chosen]\n",
        "    test_segs = take_n(remaining, te_n)\n",
        "\n",
        "    train_X_1d += train_segs\n",
        "    train_y    += [class_to_idx[cls]] * len(train_segs)\n",
        "    test_X_1d  += test_segs\n",
        "    test_y     += [class_to_idx[cls]] * len(test_segs)\n",
        "\n",
        "train_X_1d = np.stack(train_X_1d)\n",
        "test_X_1d  = np.stack(test_X_1d)\n",
        "train_y    = np.array(train_y)\n",
        "test_y     = np.array(test_y)\n",
        "\n",
        "print(\"Train:\", train_X_1d.shape)\n",
        "print(\"Test :\", test_X_1d.shape)\n",
        "\n",
        "# ------------------------------------------\n",
        "# 3) STFT -> 256x256 grayscale spectrograms\n",
        "# ------------------------------------------\n",
        "from PIL import Image\n",
        "from scipy import signal\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "def stft_to_image(seg, fs=FS):\n",
        "    hann_sym = signal.windows.hann(STFT_NPERSEG, sym=True)\n",
        "    f, t, Z = signal.stft(seg, fs=fs, window=hann_sym,\n",
        "                          nperseg=STFT_NPERSEG, noverlap=STFT_NOVERLAP,\n",
        "                          nfft=STFT_NPERSEG, boundary=None, padded=False)\n",
        "    S = np.abs(Z) + 1e-12\n",
        "    S_db = 20*np.log10(S / S.max())\n",
        "    S01 = (S_db - S_db.min()) / (S_db.max() - S_db.min() + 1e-12)\n",
        "    img = Image.fromarray((S01*255).astype(np.uint8)).resize((SPEC_SIZE, SPEC_SIZE))\n",
        "    return np.array(img, np.uint8)\n",
        "\n",
        "def make_spec_set(X_1d, y):\n",
        "    imgs = [stft_to_image(seg, FS) for seg in X_1d]\n",
        "    X = np.expand_dims(np.array(imgs, np.float32)/255.0, axis=-1)\n",
        "    Y = to_categorical(y, num_classes=5)\n",
        "    return X, Y\n",
        "\n",
        "train_X_2d, train_y_oh = make_spec_set(train_X_1d, train_y)\n",
        "test_X_2d,  test_y_oh  = make_spec_set(test_X_1d,  test_y)\n",
        "\n",
        "# free RAM\n",
        "import gc\n",
        "del train_X_1d, test_X_1d\n",
        "gc.collect()\n",
        "\n",
        "# ---------------------------\n",
        "# 4) 2D-CNN (paper structure)\n",
        "# ---------------------------\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def make_2d_cnn(input_shape=(SPEC_SIZE, SPEC_SIZE, 1), num_classes=5):\n",
        "    x = inp = keras.Input(shape=input_shape)\n",
        "    x = layers.Conv2D(8, (4,4), activation='relu', padding='same')(x)\n",
        "    x = layers.MaxPooling2D((2,2))(x)\n",
        "    x = layers.Conv2D(13, (2,2), activation='relu', padding='same')(x)\n",
        "    x = layers.MaxPooling2D((2,2))(x)\n",
        "    x = layers.Conv2D(13, (2,2), activation='relu', padding='same')(x)\n",
        "    x = layers.MaxPooling2D((2,2))(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(64, activation='relu')(x)\n",
        "    out = layers.Dense(num_classes, activation='softmax')(x)\n",
        "    return keras.Model(inp, out)\n",
        "\n",
        "# =================================================================\n",
        "# 5) *** BATCH SIZE SWEEP EXPERIMENT (PAPER REPLICATION) ***\n",
        "# =================================================================\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "LR = 0.001\n",
        "EPOCHS = 100\n",
        "batch_sizes = [100, 250, 500, 750, 1000, 1500]\n",
        "\n",
        "results = []\n",
        "acc_curves = {}\n",
        "loss_curves = {}\n",
        "\n",
        "for BATCH in batch_sizes:\n",
        "    print(f\"\\n========== Running Batch Size {BATCH} ==========\\n\")\n",
        "\n",
        "    model = make_2d_cnn()\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(LR),\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    hist = model.fit(\n",
        "        train_X_2d, train_y_oh,\n",
        "        validation_data=(test_X_2d, test_y_oh),\n",
        "        epochs=EPOCHS,\n",
        "        batch_size=BATCH,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    acc = hist.history[\"val_accuracy\"]\n",
        "    loss = hist.history[\"val_loss\"]\n",
        "\n",
        "    acc_curves[BATCH] = acc\n",
        "    loss_curves[BATCH] = loss\n",
        "\n",
        "    # Test accuracy on final model\n",
        "    y_prob = model.predict(test_X_2d, verbose=0)\n",
        "    y_pred = y_prob.argmax(axis=1)\n",
        "    y_true = test_y_oh.argmax(axis=1)\n",
        "    test_acc = (y_pred == y_true).mean() * 100\n",
        "\n",
        "    results.append([BATCH, np.mean(acc)*100, np.mean(loss), test_acc])\n",
        "\n",
        "    # save individual plots\n",
        "    plt.figure(); plt.plot(acc); plt.title(f\"Accuracy (Batch {BATCH})\")\n",
        "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Val Accuracy\"); plt.grid()\n",
        "    plt.savefig(f\"acc_batch_{BATCH}.png\"); plt.close()\n",
        "\n",
        "    plt.figure(); plt.plot(loss); plt.title(f\"Loss (Batch {BATCH})\")\n",
        "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Val Loss\"); plt.grid()\n",
        "    plt.savefig(f\"loss_batch_{BATCH}.png\"); plt.close()\n",
        "\n",
        "# Save combined plots\n",
        "plt.figure(figsize=(10,6))\n",
        "for B in batch_sizes:\n",
        "    plt.plot(acc_curves[B], label=f\"batch={B}\")\n",
        "plt.legend(); plt.grid()\n",
        "plt.title(\"Combined Accuracy (LR=0.001)\")\n",
        "plt.savefig(\"combined_accuracy.png\"); plt.close()\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "for B in batch_sizes:\n",
        "    plt.plot(loss_curves[B], label=f\"batch={B}\")\n",
        "plt.legend(); plt.grid()\n",
        "plt.title(\"Combined Loss (LR=0.001)\")\n",
        "plt.savefig(\"combined_loss.png\"); plt.close()\n",
        "\n",
        "# Save CSV\n",
        "df = pd.DataFrame(results, columns=[\"Batch Size\",\"Avg Val Acc (%)\",\"Avg Val Loss\",\"Final Test Acc (%)\"])\n",
        "df.to_csv(\"batch_sweep_results.csv\", index=False)\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwWLEpkR5UIc",
        "outputId": "11d3790d-133c-487e-85fa-df2383cf92ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config ready.\n",
            "NOR: segments extracted = 7936\n",
            "LBB: segments extracted = 6600\n",
            "RBB: segments extracted = 5513\n",
            "PVC: segments extracted = 1347\n",
            "APC: segments extracted = 1860\n",
            "Train: (2100, 3600)\n",
            "Test : (420, 3600)\n",
            "\n",
            "========== Running Batch Size 100 ==========\n",
            "\n",
            "Epoch 1/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 150ms/step - accuracy: 0.2017 - loss: 1.6367 - val_accuracy: 0.2143 - val_loss: 1.5947\n",
            "Epoch 2/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.2702 - loss: 1.5865 - val_accuracy: 0.3048 - val_loss: 1.5662\n",
            "Epoch 3/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.3748 - loss: 1.5445 - val_accuracy: 0.3714 - val_loss: 1.4798\n",
            "Epoch 4/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.4575 - loss: 1.4073 - val_accuracy: 0.5310 - val_loss: 1.2289\n",
            "Epoch 5/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.5762 - loss: 1.1752 - val_accuracy: 0.6000 - val_loss: 1.0735\n",
            "Epoch 6/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.6705 - loss: 0.9655 - val_accuracy: 0.7167 - val_loss: 0.8786\n",
            "Epoch 7/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.7416 - loss: 0.7827 - val_accuracy: 0.7524 - val_loss: 0.7393\n",
            "Epoch 8/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.7752 - loss: 0.6855 - val_accuracy: 0.7833 - val_loss: 0.6771\n",
            "Epoch 9/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8000 - loss: 0.5786 - val_accuracy: 0.8429 - val_loss: 0.5482\n",
            "Epoch 10/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8551 - loss: 0.4770 - val_accuracy: 0.8643 - val_loss: 0.4803\n",
            "Epoch 11/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.8656 - loss: 0.4271 - val_accuracy: 0.8690 - val_loss: 0.4415\n",
            "Epoch 12/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.8836 - loss: 0.3799 - val_accuracy: 0.8690 - val_loss: 0.4160\n",
            "Epoch 13/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 0.8951 - loss: 0.3425 - val_accuracy: 0.8548 - val_loss: 0.4359\n",
            "Epoch 14/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9079 - loss: 0.3221 - val_accuracy: 0.8905 - val_loss: 0.3562\n",
            "Epoch 15/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9196 - loss: 0.2779 - val_accuracy: 0.9000 - val_loss: 0.3391\n",
            "Epoch 16/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9292 - loss: 0.2601 - val_accuracy: 0.9095 - val_loss: 0.3154\n",
            "Epoch 17/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9468 - loss: 0.2315 - val_accuracy: 0.9143 - val_loss: 0.3140\n",
            "Epoch 18/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9441 - loss: 0.2183 - val_accuracy: 0.9190 - val_loss: 0.3063\n",
            "Epoch 19/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9578 - loss: 0.1965 - val_accuracy: 0.9167 - val_loss: 0.2861\n",
            "Epoch 20/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9591 - loss: 0.1765 - val_accuracy: 0.9238 - val_loss: 0.2763\n",
            "Epoch 21/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9621 - loss: 0.1608 - val_accuracy: 0.9238 - val_loss: 0.2755\n",
            "Epoch 22/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9642 - loss: 0.1455 - val_accuracy: 0.9071 - val_loss: 0.2906\n",
            "Epoch 23/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 0.9675 - loss: 0.1352 - val_accuracy: 0.9024 - val_loss: 0.2928\n",
            "Epoch 24/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9676 - loss: 0.1288 - val_accuracy: 0.9357 - val_loss: 0.2322\n",
            "Epoch 25/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9687 - loss: 0.1126 - val_accuracy: 0.9452 - val_loss: 0.2077\n",
            "Epoch 26/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9810 - loss: 0.0958 - val_accuracy: 0.9405 - val_loss: 0.2079\n",
            "Epoch 27/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9811 - loss: 0.0880 - val_accuracy: 0.9500 - val_loss: 0.1986\n",
            "Epoch 28/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9822 - loss: 0.0807 - val_accuracy: 0.9500 - val_loss: 0.1883\n",
            "Epoch 29/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9822 - loss: 0.0721 - val_accuracy: 0.9452 - val_loss: 0.1946\n",
            "Epoch 30/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9809 - loss: 0.0719 - val_accuracy: 0.9429 - val_loss: 0.1878\n",
            "Epoch 31/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - accuracy: 0.9860 - loss: 0.0638 - val_accuracy: 0.9429 - val_loss: 0.1874\n",
            "Epoch 32/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 0.9871 - loss: 0.0570 - val_accuracy: 0.9405 - val_loss: 0.1791\n",
            "Epoch 33/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9901 - loss: 0.0568 - val_accuracy: 0.9405 - val_loss: 0.1850\n",
            "Epoch 34/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9877 - loss: 0.0597 - val_accuracy: 0.9381 - val_loss: 0.2066\n",
            "Epoch 35/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9741 - loss: 0.0803 - val_accuracy: 0.9262 - val_loss: 0.2684\n",
            "Epoch 36/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9591 - loss: 0.1304 - val_accuracy: 0.9024 - val_loss: 0.3401\n",
            "Epoch 37/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9541 - loss: 0.1268 - val_accuracy: 0.9333 - val_loss: 0.1919\n",
            "Epoch 38/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9835 - loss: 0.0681 - val_accuracy: 0.9333 - val_loss: 0.2045\n",
            "Epoch 39/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9794 - loss: 0.0733 - val_accuracy: 0.9000 - val_loss: 0.2887\n",
            "Epoch 40/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.9705 - loss: 0.0964 - val_accuracy: 0.9167 - val_loss: 0.2618\n",
            "Epoch 41/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9674 - loss: 0.0987 - val_accuracy: 0.9452 - val_loss: 0.1635\n",
            "Epoch 42/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9859 - loss: 0.0519 - val_accuracy: 0.9452 - val_loss: 0.2046\n",
            "Epoch 43/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9840 - loss: 0.0499 - val_accuracy: 0.9476 - val_loss: 0.1893\n",
            "Epoch 44/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9935 - loss: 0.0284 - val_accuracy: 0.9333 - val_loss: 0.2068\n",
            "Epoch 45/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9972 - loss: 0.0217 - val_accuracy: 0.9405 - val_loss: 0.1952\n",
            "Epoch 46/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9989 - loss: 0.0173 - val_accuracy: 0.9452 - val_loss: 0.1966\n",
            "Epoch 47/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9986 - loss: 0.0150 - val_accuracy: 0.9429 - val_loss: 0.1938\n",
            "Epoch 48/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.9990 - loss: 0.0144 - val_accuracy: 0.9476 - val_loss: 0.1872\n",
            "Epoch 49/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9990 - loss: 0.0131 - val_accuracy: 0.9500 - val_loss: 0.1823\n",
            "Epoch 50/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9990 - loss: 0.0119 - val_accuracy: 0.9500 - val_loss: 0.1775\n",
            "Epoch 51/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0117 - val_accuracy: 0.9548 - val_loss: 0.1724\n",
            "Epoch 52/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0104 - val_accuracy: 0.9571 - val_loss: 0.1663\n",
            "Epoch 53/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0105 - val_accuracy: 0.9595 - val_loss: 0.1640\n",
            "Epoch 54/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0092 - val_accuracy: 0.9595 - val_loss: 0.1583\n",
            "Epoch 55/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.0096 - val_accuracy: 0.9595 - val_loss: 0.1514\n",
            "Epoch 56/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.0080 - val_accuracy: 0.9571 - val_loss: 0.1540\n",
            "Epoch 57/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.9997 - loss: 0.0090 - val_accuracy: 0.9619 - val_loss: 0.1471\n",
            "Epoch 58/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0064 - val_accuracy: 0.9524 - val_loss: 0.1602\n",
            "Epoch 59/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9981 - loss: 0.0097 - val_accuracy: 0.9619 - val_loss: 0.1389\n",
            "Epoch 60/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.9500 - val_loss: 0.1598\n",
            "Epoch 61/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9975 - loss: 0.0097 - val_accuracy: 0.9643 - val_loss: 0.1376\n",
            "Epoch 62/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.9524 - val_loss: 0.1484\n",
            "Epoch 63/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 0.9571 - val_loss: 0.1466\n",
            "Epoch 64/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.9595 - val_loss: 0.1478\n",
            "Epoch 65/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9571 - val_loss: 0.1453\n",
            "Epoch 66/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9548 - val_loss: 0.1531\n",
            "Epoch 67/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9571 - val_loss: 0.1554\n",
            "Epoch 68/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9548 - val_loss: 0.1517\n",
            "Epoch 69/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9571 - val_loss: 0.1571\n",
            "Epoch 70/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9548 - val_loss: 0.1566\n",
            "Epoch 71/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9548 - val_loss: 0.1574\n",
            "Epoch 72/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9548 - val_loss: 0.1578\n",
            "Epoch 73/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9524 - val_loss: 0.1570\n",
            "Epoch 74/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9524 - val_loss: 0.1565\n",
            "Epoch 75/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9524 - val_loss: 0.1558\n",
            "Epoch 76/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9524 - val_loss: 0.1548\n",
            "Epoch 77/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9524 - val_loss: 0.1536\n",
            "Epoch 78/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9524 - val_loss: 0.1526\n",
            "Epoch 79/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9524 - val_loss: 0.1514\n",
            "Epoch 80/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9524 - val_loss: 0.1503\n",
            "Epoch 81/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9524 - val_loss: 0.1493\n",
            "Epoch 82/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 9.9487e-04 - val_accuracy: 0.9524 - val_loss: 0.1478\n",
            "Epoch 83/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 9.6071e-04 - val_accuracy: 0.9524 - val_loss: 0.1467\n",
            "Epoch 84/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 9.2580e-04 - val_accuracy: 0.9524 - val_loss: 0.1458\n",
            "Epoch 85/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 8.8841e-04 - val_accuracy: 0.9524 - val_loss: 0.1446\n",
            "Epoch 86/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 8.5707e-04 - val_accuracy: 0.9524 - val_loss: 0.1435\n",
            "Epoch 87/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 8.2561e-04 - val_accuracy: 0.9524 - val_loss: 0.1425\n",
            "Epoch 88/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 7.9509e-04 - val_accuracy: 0.9548 - val_loss: 0.1413\n",
            "Epoch 89/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 7.6757e-04 - val_accuracy: 0.9548 - val_loss: 0.1403\n",
            "Epoch 90/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 7.3761e-04 - val_accuracy: 0.9548 - val_loss: 0.1393\n",
            "Epoch 91/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 7.0736e-04 - val_accuracy: 0.9595 - val_loss: 0.1384\n",
            "Epoch 92/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 6.7614e-04 - val_accuracy: 0.9595 - val_loss: 0.1377\n",
            "Epoch 93/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 6.4278e-04 - val_accuracy: 0.9595 - val_loss: 0.1367\n",
            "Epoch 94/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 6.1753e-04 - val_accuracy: 0.9619 - val_loss: 0.1368\n",
            "Epoch 95/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 5.8022e-04 - val_accuracy: 0.9619 - val_loss: 0.1365\n",
            "Epoch 96/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 5.5021e-04 - val_accuracy: 0.9619 - val_loss: 0.1364\n",
            "Epoch 97/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 5.2275e-04 - val_accuracy: 0.9619 - val_loss: 0.1370\n",
            "Epoch 98/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 4.9397e-04 - val_accuracy: 0.9595 - val_loss: 0.1376\n",
            "Epoch 99/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 4.6772e-04 - val_accuracy: 0.9595 - val_loss: 0.1387\n",
            "Epoch 100/100\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 4.3959e-04 - val_accuracy: 0.9548 - val_loss: 0.1399\n",
            "\n",
            "========== Running Batch Size 250 ==========\n",
            "\n",
            "Epoch 1/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 787ms/step - accuracy: 0.1915 - loss: 1.7870 - val_accuracy: 0.2143 - val_loss: 1.6091\n",
            "Epoch 2/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.2112 - loss: 1.6024 - val_accuracy: 0.2143 - val_loss: 1.5823\n",
            "Epoch 3/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - accuracy: 0.3486 - loss: 1.5744 - val_accuracy: 0.4714 - val_loss: 1.5709\n",
            "Epoch 4/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.4712 - loss: 1.5627 - val_accuracy: 0.4714 - val_loss: 1.5507\n",
            "Epoch 5/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - accuracy: 0.5107 - loss: 1.5371 - val_accuracy: 0.5881 - val_loss: 1.5142\n",
            "Epoch 6/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.5869 - loss: 1.4916 - val_accuracy: 0.5762 - val_loss: 1.4563\n",
            "Epoch 7/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - accuracy: 0.5982 - loss: 1.4233 - val_accuracy: 0.5952 - val_loss: 1.3691\n",
            "Epoch 8/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - accuracy: 0.6042 - loss: 1.3239 - val_accuracy: 0.6238 - val_loss: 1.2595\n",
            "Epoch 9/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 156ms/step - accuracy: 0.6316 - loss: 1.2012 - val_accuracy: 0.6548 - val_loss: 1.1279\n",
            "Epoch 10/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - accuracy: 0.6722 - loss: 1.0799 - val_accuracy: 0.6810 - val_loss: 1.0420\n",
            "Epoch 11/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.6929 - loss: 0.9679 - val_accuracy: 0.7357 - val_loss: 0.9353\n",
            "Epoch 12/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.7287 - loss: 0.8723 - val_accuracy: 0.7548 - val_loss: 0.8467\n",
            "Epoch 13/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.7452 - loss: 0.7910 - val_accuracy: 0.7238 - val_loss: 0.8453\n",
            "Epoch 14/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.7602 - loss: 0.7287 - val_accuracy: 0.7690 - val_loss: 0.7541\n",
            "Epoch 15/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.8112 - loss: 0.6448 - val_accuracy: 0.8119 - val_loss: 0.6763\n",
            "Epoch 16/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.8371 - loss: 0.5712 - val_accuracy: 0.8262 - val_loss: 0.6162\n",
            "Epoch 17/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - accuracy: 0.8346 - loss: 0.5442 - val_accuracy: 0.7952 - val_loss: 0.6065\n",
            "Epoch 18/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.8243 - loss: 0.5362 - val_accuracy: 0.8190 - val_loss: 0.5692\n",
            "Epoch 19/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - accuracy: 0.8539 - loss: 0.4769 - val_accuracy: 0.8595 - val_loss: 0.5195\n",
            "Epoch 20/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - accuracy: 0.8839 - loss: 0.4175 - val_accuracy: 0.8667 - val_loss: 0.4728\n",
            "Epoch 21/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.9007 - loss: 0.3759 - val_accuracy: 0.8667 - val_loss: 0.4418\n",
            "Epoch 22/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.9005 - loss: 0.3625 - val_accuracy: 0.8667 - val_loss: 0.4350\n",
            "Epoch 23/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - accuracy: 0.8897 - loss: 0.3612 - val_accuracy: 0.8357 - val_loss: 0.4453\n",
            "Epoch 24/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.8909 - loss: 0.3538 - val_accuracy: 0.8524 - val_loss: 0.4257\n",
            "Epoch 25/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.8984 - loss: 0.3195 - val_accuracy: 0.9024 - val_loss: 0.3490\n",
            "Epoch 26/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.9287 - loss: 0.2759 - val_accuracy: 0.9119 - val_loss: 0.3383\n",
            "Epoch 27/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.9405 - loss: 0.2332 - val_accuracy: 0.9167 - val_loss: 0.3050\n",
            "Epoch 28/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.9515 - loss: 0.2171 - val_accuracy: 0.9214 - val_loss: 0.2887\n",
            "Epoch 29/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - accuracy: 0.9581 - loss: 0.2000 - val_accuracy: 0.9262 - val_loss: 0.2710\n",
            "Epoch 30/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - accuracy: 0.9613 - loss: 0.1834 - val_accuracy: 0.9262 - val_loss: 0.2667\n",
            "Epoch 31/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.9670 - loss: 0.1693 - val_accuracy: 0.9310 - val_loss: 0.2487\n",
            "Epoch 32/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - accuracy: 0.9693 - loss: 0.1539 - val_accuracy: 0.9310 - val_loss: 0.2383\n",
            "Epoch 33/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.9696 - loss: 0.1431 - val_accuracy: 0.9310 - val_loss: 0.2248\n",
            "Epoch 34/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 129ms/step - accuracy: 0.9707 - loss: 0.1315 - val_accuracy: 0.9310 - val_loss: 0.2178\n",
            "Epoch 35/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.9727 - loss: 0.1215 - val_accuracy: 0.9286 - val_loss: 0.2131\n",
            "Epoch 36/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.9726 - loss: 0.1114 - val_accuracy: 0.9333 - val_loss: 0.2056\n",
            "Epoch 37/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.9760 - loss: 0.1010 - val_accuracy: 0.9262 - val_loss: 0.2083\n",
            "Epoch 38/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.9757 - loss: 0.0943 - val_accuracy: 0.9381 - val_loss: 0.1909\n",
            "Epoch 39/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - accuracy: 0.9812 - loss: 0.0846 - val_accuracy: 0.9333 - val_loss: 0.2121\n",
            "Epoch 40/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 125ms/step - accuracy: 0.9808 - loss: 0.0860 - val_accuracy: 0.9286 - val_loss: 0.1984\n",
            "Epoch 41/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.9836 - loss: 0.0762 - val_accuracy: 0.8952 - val_loss: 0.2661\n",
            "Epoch 42/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.9440 - loss: 0.1861 - val_accuracy: 0.7500 - val_loss: 1.1223\n",
            "Epoch 43/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.8194 - loss: 0.6866 - val_accuracy: 0.8381 - val_loss: 0.3994\n",
            "Epoch 44/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.9255 - loss: 0.2238 - val_accuracy: 0.9167 - val_loss: 0.2940\n",
            "Epoch 45/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.9542 - loss: 0.1723 - val_accuracy: 0.9333 - val_loss: 0.2172\n",
            "Epoch 46/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.9656 - loss: 0.1277 - val_accuracy: 0.9381 - val_loss: 0.2239\n",
            "Epoch 47/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - accuracy: 0.9673 - loss: 0.1218 - val_accuracy: 0.9452 - val_loss: 0.1986\n",
            "Epoch 48/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 162ms/step - accuracy: 0.9693 - loss: 0.1028 - val_accuracy: 0.9524 - val_loss: 0.1911\n",
            "Epoch 49/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.9781 - loss: 0.0889 - val_accuracy: 0.9476 - val_loss: 0.1853\n",
            "Epoch 50/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.9797 - loss: 0.0839 - val_accuracy: 0.9524 - val_loss: 0.1809\n",
            "Epoch 51/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.9802 - loss: 0.0817 - val_accuracy: 0.9548 - val_loss: 0.1680\n",
            "Epoch 52/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.9807 - loss: 0.0760 - val_accuracy: 0.9595 - val_loss: 0.1530\n",
            "Epoch 53/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.9810 - loss: 0.0695 - val_accuracy: 0.9619 - val_loss: 0.1391\n",
            "Epoch 54/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - accuracy: 0.9824 - loss: 0.0641 - val_accuracy: 0.9619 - val_loss: 0.1272\n",
            "Epoch 55/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.9870 - loss: 0.0571 - val_accuracy: 0.9643 - val_loss: 0.1261\n",
            "Epoch 56/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.9858 - loss: 0.0590 - val_accuracy: 0.9619 - val_loss: 0.1393\n",
            "Epoch 57/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - accuracy: 0.9846 - loss: 0.0625 - val_accuracy: 0.9476 - val_loss: 0.1705\n",
            "Epoch 58/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - accuracy: 0.9790 - loss: 0.0738 - val_accuracy: 0.9476 - val_loss: 0.1784\n",
            "Epoch 59/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.9763 - loss: 0.0773 - val_accuracy: 0.9500 - val_loss: 0.1676\n",
            "Epoch 60/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.9760 - loss: 0.0774 - val_accuracy: 0.9595 - val_loss: 0.1337\n",
            "Epoch 61/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.9867 - loss: 0.0638 - val_accuracy: 0.9714 - val_loss: 0.1117\n",
            "Epoch 62/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.9859 - loss: 0.0549 - val_accuracy: 0.9690 - val_loss: 0.1140\n",
            "Epoch 63/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.9925 - loss: 0.0391 - val_accuracy: 0.9571 - val_loss: 0.1370\n",
            "Epoch 64/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.9917 - loss: 0.0434 - val_accuracy: 0.9619 - val_loss: 0.1470\n",
            "Epoch 65/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.9863 - loss: 0.0551 - val_accuracy: 0.9571 - val_loss: 0.1525\n",
            "Epoch 66/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.9791 - loss: 0.0650 - val_accuracy: 0.9571 - val_loss: 0.1694\n",
            "Epoch 67/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - accuracy: 0.9786 - loss: 0.0729 - val_accuracy: 0.9524 - val_loss: 0.1907\n",
            "Epoch 68/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 125ms/step - accuracy: 0.9754 - loss: 0.0779 - val_accuracy: 0.9476 - val_loss: 0.1994\n",
            "Epoch 69/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.9752 - loss: 0.0790 - val_accuracy: 0.9500 - val_loss: 0.1667\n",
            "Epoch 70/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.9789 - loss: 0.0764 - val_accuracy: 0.9667 - val_loss: 0.1137\n",
            "Epoch 71/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.9841 - loss: 0.0562 - val_accuracy: 0.9690 - val_loss: 0.1034\n",
            "Epoch 72/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.9960 - loss: 0.0266 - val_accuracy: 0.9690 - val_loss: 0.1058\n",
            "Epoch 73/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.9993 - loss: 0.0172 - val_accuracy: 0.9786 - val_loss: 0.0949\n",
            "Epoch 74/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.9985 - loss: 0.0182 - val_accuracy: 0.9762 - val_loss: 0.0887\n",
            "Epoch 75/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - accuracy: 0.9994 - loss: 0.0139 - val_accuracy: 0.9714 - val_loss: 0.0920\n",
            "Epoch 76/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - accuracy: 0.9998 - loss: 0.0127 - val_accuracy: 0.9738 - val_loss: 0.0891\n",
            "Epoch 77/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.9998 - loss: 0.0124 - val_accuracy: 0.9762 - val_loss: 0.0876\n",
            "Epoch 78/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.9998 - loss: 0.0112 - val_accuracy: 0.9738 - val_loss: 0.0886\n",
            "Epoch 79/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.9998 - loss: 0.0110 - val_accuracy: 0.9762 - val_loss: 0.0873\n",
            "Epoch 80/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.9998 - loss: 0.0103 - val_accuracy: 0.9762 - val_loss: 0.0864\n",
            "Epoch 81/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - accuracy: 0.9998 - loss: 0.0099 - val_accuracy: 0.9762 - val_loss: 0.0865\n",
            "Epoch 82/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - accuracy: 0.9998 - loss: 0.0095 - val_accuracy: 0.9762 - val_loss: 0.0859\n",
            "Epoch 83/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - accuracy: 1.0000 - loss: 0.0090 - val_accuracy: 0.9762 - val_loss: 0.0854\n",
            "Epoch 84/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 1.0000 - loss: 0.0087 - val_accuracy: 0.9762 - val_loss: 0.0852\n",
            "Epoch 85/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 0.0083 - val_accuracy: 0.9762 - val_loss: 0.0848\n",
            "Epoch 86/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - accuracy: 1.0000 - loss: 0.0080 - val_accuracy: 0.9762 - val_loss: 0.0846\n",
            "Epoch 87/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 1.0000 - loss: 0.0077 - val_accuracy: 0.9762 - val_loss: 0.0842\n",
            "Epoch 88/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 1.0000 - loss: 0.0074 - val_accuracy: 0.9762 - val_loss: 0.0841\n",
            "Epoch 89/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.9762 - val_loss: 0.0839\n",
            "Epoch 90/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 0.9762 - val_loss: 0.0835\n",
            "Epoch 91/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 1.0000 - loss: 0.0066 - val_accuracy: 0.9762 - val_loss: 0.0834\n",
            "Epoch 92/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - accuracy: 1.0000 - loss: 0.0064 - val_accuracy: 0.9738 - val_loss: 0.0833\n",
            "Epoch 93/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.9738 - val_loss: 0.0825\n",
            "Epoch 94/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 159ms/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 0.9738 - val_loss: 0.0820\n",
            "Epoch 95/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 125ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.9738 - val_loss: 0.0814\n",
            "Epoch 96/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.9762 - val_loss: 0.0809\n",
            "Epoch 97/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.9762 - val_loss: 0.0805\n",
            "Epoch 98/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.9762 - val_loss: 0.0805\n",
            "Epoch 99/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.9762 - val_loss: 0.0805\n",
            "Epoch 100/100\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.9762 - val_loss: 0.0807\n",
            "\n",
            "========== Running Batch Size 500 ==========\n",
            "\n",
            "Epoch 1/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.2408 - loss: 1.6186 - val_accuracy: 0.4024 - val_loss: 1.5974\n",
            "Epoch 2/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 219ms/step - accuracy: 0.3265 - loss: 1.5954 - val_accuracy: 0.2167 - val_loss: 1.5885\n",
            "Epoch 3/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 220ms/step - accuracy: 0.3349 - loss: 1.5853 - val_accuracy: 0.4571 - val_loss: 1.5757\n",
            "Epoch 4/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 270ms/step - accuracy: 0.3587 - loss: 1.5714 - val_accuracy: 0.3595 - val_loss: 1.5621\n",
            "Epoch 5/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - accuracy: 0.4510 - loss: 1.5549 - val_accuracy: 0.4119 - val_loss: 1.5378\n",
            "Epoch 6/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 219ms/step - accuracy: 0.4421 - loss: 1.5272 - val_accuracy: 0.4452 - val_loss: 1.5015\n",
            "Epoch 7/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 220ms/step - accuracy: 0.4960 - loss: 1.4850 - val_accuracy: 0.4262 - val_loss: 1.4577\n",
            "Epoch 8/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 218ms/step - accuracy: 0.4834 - loss: 1.4344 - val_accuracy: 0.4762 - val_loss: 1.4045\n",
            "Epoch 9/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 219ms/step - accuracy: 0.5168 - loss: 1.3729 - val_accuracy: 0.5095 - val_loss: 1.3499\n",
            "Epoch 10/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 218ms/step - accuracy: 0.5504 - loss: 1.3120 - val_accuracy: 0.5762 - val_loss: 1.2763\n",
            "Epoch 11/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 219ms/step - accuracy: 0.5861 - loss: 1.2441 - val_accuracy: 0.6595 - val_loss: 1.1791\n",
            "Epoch 12/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 232ms/step - accuracy: 0.6327 - loss: 1.1633 - val_accuracy: 0.6810 - val_loss: 1.1038\n",
            "Epoch 13/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 240ms/step - accuracy: 0.6752 - loss: 1.0778 - val_accuracy: 0.6810 - val_loss: 1.0355\n",
            "Epoch 14/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - accuracy: 0.6890 - loss: 0.9990 - val_accuracy: 0.6810 - val_loss: 0.9791\n",
            "Epoch 15/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 219ms/step - accuracy: 0.7009 - loss: 0.9325 - val_accuracy: 0.7071 - val_loss: 0.9602\n",
            "Epoch 16/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 218ms/step - accuracy: 0.7160 - loss: 0.8892 - val_accuracy: 0.7286 - val_loss: 0.9524\n",
            "Epoch 17/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 223ms/step - accuracy: 0.7280 - loss: 0.8598 - val_accuracy: 0.7310 - val_loss: 0.9121\n",
            "Epoch 18/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 221ms/step - accuracy: 0.7395 - loss: 0.8275 - val_accuracy: 0.7571 - val_loss: 0.8193\n",
            "Epoch 19/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 219ms/step - accuracy: 0.7673 - loss: 0.7712 - val_accuracy: 0.7190 - val_loss: 0.8048\n",
            "Epoch 20/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 220ms/step - accuracy: 0.7639 - loss: 0.7324 - val_accuracy: 0.7333 - val_loss: 0.7842\n",
            "Epoch 21/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 235ms/step - accuracy: 0.7764 - loss: 0.6965 - val_accuracy: 0.8024 - val_loss: 0.7025\n",
            "Epoch 22/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step - accuracy: 0.8078 - loss: 0.6409 - val_accuracy: 0.8071 - val_loss: 0.7037\n",
            "Epoch 23/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 222ms/step - accuracy: 0.8183 - loss: 0.6224 - val_accuracy: 0.8119 - val_loss: 0.6721\n",
            "Epoch 24/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 220ms/step - accuracy: 0.8276 - loss: 0.6015 - val_accuracy: 0.8214 - val_loss: 0.6256\n",
            "Epoch 25/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 220ms/step - accuracy: 0.8419 - loss: 0.5719 - val_accuracy: 0.8357 - val_loss: 0.5996\n",
            "Epoch 26/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 220ms/step - accuracy: 0.8548 - loss: 0.5439 - val_accuracy: 0.8476 - val_loss: 0.5764\n",
            "Epoch 27/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step - accuracy: 0.8672 - loss: 0.5163 - val_accuracy: 0.8405 - val_loss: 0.5698\n",
            "Epoch 28/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 218ms/step - accuracy: 0.8575 - loss: 0.4963 - val_accuracy: 0.8619 - val_loss: 0.5423\n",
            "Epoch 29/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 219ms/step - accuracy: 0.8735 - loss: 0.4779 - val_accuracy: 0.8619 - val_loss: 0.5206\n",
            "Epoch 30/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 230ms/step - accuracy: 0.8785 - loss: 0.4599 - val_accuracy: 0.8619 - val_loss: 0.5003\n",
            "Epoch 31/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 236ms/step - accuracy: 0.8849 - loss: 0.4372 - val_accuracy: 0.8762 - val_loss: 0.4750\n",
            "Epoch 32/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 220ms/step - accuracy: 0.8880 - loss: 0.4183 - val_accuracy: 0.8762 - val_loss: 0.4626\n",
            "Epoch 33/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 219ms/step - accuracy: 0.9038 - loss: 0.3876 - val_accuracy: 0.8929 - val_loss: 0.4306\n",
            "Epoch 34/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 218ms/step - accuracy: 0.9146 - loss: 0.3602 - val_accuracy: 0.9024 - val_loss: 0.4009\n",
            "Epoch 35/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 222ms/step - accuracy: 0.9251 - loss: 0.3333 - val_accuracy: 0.9071 - val_loss: 0.3780\n",
            "Epoch 36/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 218ms/step - accuracy: 0.9331 - loss: 0.3125 - val_accuracy: 0.9143 - val_loss: 0.3573\n",
            "Epoch 37/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 219ms/step - accuracy: 0.9331 - loss: 0.3005 - val_accuracy: 0.9167 - val_loss: 0.3383\n",
            "Epoch 38/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 217ms/step - accuracy: 0.9408 - loss: 0.2824 - val_accuracy: 0.9238 - val_loss: 0.3241\n",
            "Epoch 39/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 219ms/step - accuracy: 0.9432 - loss: 0.2676 - val_accuracy: 0.9310 - val_loss: 0.3108\n",
            "Epoch 40/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 273ms/step - accuracy: 0.9472 - loss: 0.2588 - val_accuracy: 0.9381 - val_loss: 0.2956\n",
            "Epoch 41/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 222ms/step - accuracy: 0.9501 - loss: 0.2445 - val_accuracy: 0.9476 - val_loss: 0.2835\n",
            "Epoch 42/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 221ms/step - accuracy: 0.9563 - loss: 0.2334 - val_accuracy: 0.9429 - val_loss: 0.2735\n",
            "Epoch 43/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 219ms/step - accuracy: 0.9561 - loss: 0.2253 - val_accuracy: 0.9452 - val_loss: 0.2628\n",
            "Epoch 44/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 221ms/step - accuracy: 0.9601 - loss: 0.2134 - val_accuracy: 0.9476 - val_loss: 0.2522\n",
            "Epoch 45/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 218ms/step - accuracy: 0.9634 - loss: 0.2025 - val_accuracy: 0.9524 - val_loss: 0.2430\n",
            "Epoch 46/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 218ms/step - accuracy: 0.9647 - loss: 0.1947 - val_accuracy: 0.9595 - val_loss: 0.2349\n",
            "Epoch 47/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 218ms/step - accuracy: 0.9642 - loss: 0.1888 - val_accuracy: 0.9548 - val_loss: 0.2279\n",
            "Epoch 48/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 219ms/step - accuracy: 0.9646 - loss: 0.1825 - val_accuracy: 0.9571 - val_loss: 0.2213\n",
            "Epoch 49/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 272ms/step - accuracy: 0.9688 - loss: 0.1745 - val_accuracy: 0.9595 - val_loss: 0.2149\n",
            "Epoch 50/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 237ms/step - accuracy: 0.9678 - loss: 0.1671 - val_accuracy: 0.9595 - val_loss: 0.2088\n",
            "Epoch 51/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 221ms/step - accuracy: 0.9677 - loss: 0.1618 - val_accuracy: 0.9595 - val_loss: 0.2031\n",
            "Epoch 52/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 220ms/step - accuracy: 0.9667 - loss: 0.1590 - val_accuracy: 0.9595 - val_loss: 0.1994\n",
            "Epoch 53/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 219ms/step - accuracy: 0.9680 - loss: 0.1563 - val_accuracy: 0.9595 - val_loss: 0.1946\n",
            "Epoch 54/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 219ms/step - accuracy: 0.9693 - loss: 0.1443 - val_accuracy: 0.9595 - val_loss: 0.1904\n",
            "Epoch 55/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 217ms/step - accuracy: 0.9717 - loss: 0.1388 - val_accuracy: 0.9619 - val_loss: 0.1857\n",
            "Epoch 56/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 218ms/step - accuracy: 0.9707 - loss: 0.1343 - val_accuracy: 0.9690 - val_loss: 0.1787\n",
            "Epoch 57/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 219ms/step - accuracy: 0.9715 - loss: 0.1335 - val_accuracy: 0.9619 - val_loss: 0.1776\n",
            "Epoch 58/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 222ms/step - accuracy: 0.9653 - loss: 0.1410 - val_accuracy: 0.9667 - val_loss: 0.1721\n",
            "Epoch 59/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 219ms/step - accuracy: 0.9760 - loss: 0.1210 - val_accuracy: 0.9619 - val_loss: 0.1733\n",
            "Epoch 60/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 220ms/step - accuracy: 0.9740 - loss: 0.1191 - val_accuracy: 0.9690 - val_loss: 0.1639\n",
            "Epoch 61/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 220ms/step - accuracy: 0.9751 - loss: 0.1142 - val_accuracy: 0.9690 - val_loss: 0.1579\n",
            "Epoch 62/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 215ms/step - accuracy: 0.9771 - loss: 0.1084 - val_accuracy: 0.9714 - val_loss: 0.1528\n",
            "Epoch 63/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 216ms/step - accuracy: 0.9764 - loss: 0.1025 - val_accuracy: 0.9690 - val_loss: 0.1502\n",
            "Epoch 64/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 217ms/step - accuracy: 0.9775 - loss: 0.0998 - val_accuracy: 0.9690 - val_loss: 0.1462\n",
            "Epoch 65/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 218ms/step - accuracy: 0.9784 - loss: 0.0956 - val_accuracy: 0.9690 - val_loss: 0.1413\n",
            "Epoch 66/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 223ms/step - accuracy: 0.9796 - loss: 0.0918 - val_accuracy: 0.9690 - val_loss: 0.1376\n",
            "Epoch 67/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 232ms/step - accuracy: 0.9803 - loss: 0.0906 - val_accuracy: 0.9643 - val_loss: 0.1388\n",
            "Epoch 68/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 225ms/step - accuracy: 0.9769 - loss: 0.0985 - val_accuracy: 0.9595 - val_loss: 0.1482\n",
            "Epoch 69/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 222ms/step - accuracy: 0.9700 - loss: 0.1044 - val_accuracy: 0.9500 - val_loss: 0.1693\n",
            "Epoch 70/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 222ms/step - accuracy: 0.9681 - loss: 0.1140 - val_accuracy: 0.9405 - val_loss: 0.1836\n",
            "Epoch 71/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 218ms/step - accuracy: 0.9613 - loss: 0.1453 - val_accuracy: 0.8548 - val_loss: 0.3975\n",
            "Epoch 72/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 219ms/step - accuracy: 0.9155 - loss: 0.2287 - val_accuracy: 0.9667 - val_loss: 0.1469\n",
            "Epoch 73/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 219ms/step - accuracy: 0.9477 - loss: 0.1611 - val_accuracy: 0.9310 - val_loss: 0.2072\n",
            "Epoch 74/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 219ms/step - accuracy: 0.9590 - loss: 0.1360 - val_accuracy: 0.9357 - val_loss: 0.1939\n",
            "Epoch 75/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 221ms/step - accuracy: 0.9676 - loss: 0.1098 - val_accuracy: 0.9548 - val_loss: 0.1652\n",
            "Epoch 76/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 272ms/step - accuracy: 0.9743 - loss: 0.1032 - val_accuracy: 0.9286 - val_loss: 0.2105\n",
            "Epoch 77/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - accuracy: 0.9648 - loss: 0.1237 - val_accuracy: 0.9476 - val_loss: 0.1797\n",
            "Epoch 78/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 226ms/step - accuracy: 0.9737 - loss: 0.0924 - val_accuracy: 0.9214 - val_loss: 0.2178\n",
            "Epoch 79/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 240ms/step - accuracy: 0.9705 - loss: 0.0987 - val_accuracy: 0.9310 - val_loss: 0.2083\n",
            "Epoch 80/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 223ms/step - accuracy: 0.9709 - loss: 0.0974 - val_accuracy: 0.9333 - val_loss: 0.2011\n",
            "Epoch 81/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 219ms/step - accuracy: 0.9722 - loss: 0.0976 - val_accuracy: 0.9048 - val_loss: 0.2954\n",
            "Epoch 82/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 218ms/step - accuracy: 0.9527 - loss: 0.1454 - val_accuracy: 0.8357 - val_loss: 0.4756\n",
            "Epoch 83/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 269ms/step - accuracy: 0.9218 - loss: 0.2222 - val_accuracy: 0.8762 - val_loss: 0.3366\n",
            "Epoch 84/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 228ms/step - accuracy: 0.9341 - loss: 0.1743 - val_accuracy: 0.9095 - val_loss: 0.2561\n",
            "Epoch 85/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 221ms/step - accuracy: 0.9474 - loss: 0.1499 - val_accuracy: 0.9643 - val_loss: 0.1328\n",
            "Epoch 86/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 220ms/step - accuracy: 0.9789 - loss: 0.0785 - val_accuracy: 0.9690 - val_loss: 0.1240\n",
            "Epoch 87/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 220ms/step - accuracy: 0.9809 - loss: 0.0726 - val_accuracy: 0.9333 - val_loss: 0.1891\n",
            "Epoch 88/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 221ms/step - accuracy: 0.9755 - loss: 0.0802 - val_accuracy: 0.9452 - val_loss: 0.1576\n",
            "Epoch 89/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step - accuracy: 0.9755 - loss: 0.0755 - val_accuracy: 0.9429 - val_loss: 0.1851\n",
            "Epoch 90/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 220ms/step - accuracy: 0.9755 - loss: 0.0853 - val_accuracy: 0.9548 - val_loss: 0.1500\n",
            "Epoch 91/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 231ms/step - accuracy: 0.9795 - loss: 0.0685 - val_accuracy: 0.9738 - val_loss: 0.1034\n",
            "Epoch 92/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 238ms/step - accuracy: 0.9910 - loss: 0.0434 - val_accuracy: 0.9714 - val_loss: 0.1144\n",
            "Epoch 93/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 220ms/step - accuracy: 0.9917 - loss: 0.0419 - val_accuracy: 0.9714 - val_loss: 0.1029\n",
            "Epoch 94/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 221ms/step - accuracy: 0.9911 - loss: 0.0412 - val_accuracy: 0.9690 - val_loss: 0.1139\n",
            "Epoch 95/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 217ms/step - accuracy: 0.9939 - loss: 0.0411 - val_accuracy: 0.9762 - val_loss: 0.0980\n",
            "Epoch 96/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 220ms/step - accuracy: 0.9955 - loss: 0.0366 - val_accuracy: 0.9738 - val_loss: 0.1047\n",
            "Epoch 97/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 221ms/step - accuracy: 0.9957 - loss: 0.0337 - val_accuracy: 0.9762 - val_loss: 0.0946\n",
            "Epoch 98/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 220ms/step - accuracy: 0.9957 - loss: 0.0334 - val_accuracy: 0.9714 - val_loss: 0.1037\n",
            "Epoch 99/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 220ms/step - accuracy: 0.9954 - loss: 0.0327 - val_accuracy: 0.9738 - val_loss: 0.0956\n",
            "Epoch 100/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 275ms/step - accuracy: 0.9963 - loss: 0.0325 - val_accuracy: 0.9714 - val_loss: 0.0997\n",
            "\n",
            "========== Running Batch Size 750 ==========\n",
            "\n",
            "Epoch 1/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 8s/step - accuracy: 0.2211 - loss: 1.6095 - val_accuracy: 0.2143 - val_loss: 1.5968\n",
            "Epoch 2/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 380ms/step - accuracy: 0.1989 - loss: 1.5936 - val_accuracy: 0.2143 - val_loss: 1.5901\n",
            "Epoch 3/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 382ms/step - accuracy: 0.2267 - loss: 1.5861 - val_accuracy: 0.3595 - val_loss: 1.5831\n",
            "Epoch 4/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 377ms/step - accuracy: 0.3994 - loss: 1.5782 - val_accuracy: 0.4048 - val_loss: 1.5748\n",
            "Epoch 5/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 386ms/step - accuracy: 0.4085 - loss: 1.5679 - val_accuracy: 0.3714 - val_loss: 1.5615\n",
            "Epoch 6/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 381ms/step - accuracy: 0.3747 - loss: 1.5521 - val_accuracy: 0.4690 - val_loss: 1.5424\n",
            "Epoch 7/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 383ms/step - accuracy: 0.5103 - loss: 1.5292 - val_accuracy: 0.5381 - val_loss: 1.5163\n",
            "Epoch 8/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 494ms/step - accuracy: 0.5669 - loss: 1.4991 - val_accuracy: 0.5429 - val_loss: 1.4816\n",
            "Epoch 9/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 379ms/step - accuracy: 0.5502 - loss: 1.4602 - val_accuracy: 0.5381 - val_loss: 1.4461\n",
            "Epoch 10/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 383ms/step - accuracy: 0.5443 - loss: 1.4194 - val_accuracy: 0.5476 - val_loss: 1.4075\n",
            "Epoch 11/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 380ms/step - accuracy: 0.5580 - loss: 1.3741 - val_accuracy: 0.5595 - val_loss: 1.3661\n",
            "Epoch 12/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 382ms/step - accuracy: 0.5605 - loss: 1.3274 - val_accuracy: 0.5524 - val_loss: 1.3216\n",
            "Epoch 13/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 386ms/step - accuracy: 0.5746 - loss: 1.2787 - val_accuracy: 0.5357 - val_loss: 1.2736\n",
            "Epoch 14/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 379ms/step - accuracy: 0.5848 - loss: 1.2278 - val_accuracy: 0.6000 - val_loss: 1.2516\n",
            "Epoch 15/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 383ms/step - accuracy: 0.5802 - loss: 1.2107 - val_accuracy: 0.6095 - val_loss: 1.2110\n",
            "Epoch 16/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 412ms/step - accuracy: 0.6219 - loss: 1.1446 - val_accuracy: 0.6000 - val_loss: 1.1674\n",
            "Epoch 17/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 381ms/step - accuracy: 0.6159 - loss: 1.1144 - val_accuracy: 0.6238 - val_loss: 1.1314\n",
            "Epoch 18/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 381ms/step - accuracy: 0.6474 - loss: 1.0655 - val_accuracy: 0.6452 - val_loss: 1.0888\n",
            "Epoch 19/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 378ms/step - accuracy: 0.6541 - loss: 1.0138 - val_accuracy: 0.6500 - val_loss: 1.0378\n",
            "Epoch 20/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 383ms/step - accuracy: 0.6721 - loss: 0.9765 - val_accuracy: 0.6738 - val_loss: 1.0130\n",
            "Epoch 21/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 382ms/step - accuracy: 0.6882 - loss: 0.9410 - val_accuracy: 0.6500 - val_loss: 0.9899\n",
            "Epoch 22/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 386ms/step - accuracy: 0.6898 - loss: 0.9109 - val_accuracy: 0.6952 - val_loss: 0.9419\n",
            "Epoch 23/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 379ms/step - accuracy: 0.7149 - loss: 0.8660 - val_accuracy: 0.6976 - val_loss: 0.8994\n",
            "Epoch 24/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 488ms/step - accuracy: 0.7228 - loss: 0.8169 - val_accuracy: 0.7452 - val_loss: 0.8695\n",
            "Epoch 25/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 392ms/step - accuracy: 0.7579 - loss: 0.7801 - val_accuracy: 0.7238 - val_loss: 0.8414\n",
            "Epoch 26/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 381ms/step - accuracy: 0.7234 - loss: 0.7931 - val_accuracy: 0.7095 - val_loss: 0.8698\n",
            "Epoch 27/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 381ms/step - accuracy: 0.7325 - loss: 0.7713 - val_accuracy: 0.7619 - val_loss: 0.7967\n",
            "Epoch 28/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 383ms/step - accuracy: 0.7614 - loss: 0.7131 - val_accuracy: 0.7524 - val_loss: 0.7805\n",
            "Epoch 29/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 382ms/step - accuracy: 0.7614 - loss: 0.7136 - val_accuracy: 0.6619 - val_loss: 0.8500\n",
            "Epoch 30/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 382ms/step - accuracy: 0.7298 - loss: 0.7376 - val_accuracy: 0.6571 - val_loss: 0.8330\n",
            "Epoch 31/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 384ms/step - accuracy: 0.7229 - loss: 0.7161 - val_accuracy: 0.8119 - val_loss: 0.7072\n",
            "Epoch 32/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 381ms/step - accuracy: 0.8217 - loss: 0.6387 - val_accuracy: 0.7786 - val_loss: 0.7405\n",
            "Epoch 33/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 476ms/step - accuracy: 0.8059 - loss: 0.6262 - val_accuracy: 0.8190 - val_loss: 0.6759\n",
            "Epoch 34/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 411ms/step - accuracy: 0.8483 - loss: 0.5866 - val_accuracy: 0.7881 - val_loss: 0.6816\n",
            "Epoch 35/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 382ms/step - accuracy: 0.8380 - loss: 0.5875 - val_accuracy: 0.7905 - val_loss: 0.6542\n",
            "Epoch 36/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 383ms/step - accuracy: 0.8438 - loss: 0.5640 - val_accuracy: 0.8333 - val_loss: 0.6272\n",
            "Epoch 37/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 385ms/step - accuracy: 0.8686 - loss: 0.5308 - val_accuracy: 0.8405 - val_loss: 0.6198\n",
            "Epoch 38/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 385ms/step - accuracy: 0.8670 - loss: 0.5196 - val_accuracy: 0.8381 - val_loss: 0.6049\n",
            "Epoch 39/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 381ms/step - accuracy: 0.8680 - loss: 0.5082 - val_accuracy: 0.8167 - val_loss: 0.6029\n",
            "Epoch 40/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 395ms/step - accuracy: 0.8602 - loss: 0.5021 - val_accuracy: 0.8071 - val_loss: 0.6039\n",
            "Epoch 41/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 420ms/step - accuracy: 0.8524 - loss: 0.5065 - val_accuracy: 0.8119 - val_loss: 0.5927\n",
            "Epoch 42/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 383ms/step - accuracy: 0.8570 - loss: 0.5009 - val_accuracy: 0.8119 - val_loss: 0.5802\n",
            "Epoch 43/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 387ms/step - accuracy: 0.8522 - loss: 0.4922 - val_accuracy: 0.8024 - val_loss: 0.5803\n",
            "Epoch 44/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 385ms/step - accuracy: 0.8561 - loss: 0.4799 - val_accuracy: 0.8143 - val_loss: 0.5702\n",
            "Epoch 45/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 381ms/step - accuracy: 0.8632 - loss: 0.4589 - val_accuracy: 0.8500 - val_loss: 0.5310\n",
            "Epoch 46/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 383ms/step - accuracy: 0.8817 - loss: 0.4340 - val_accuracy: 0.8643 - val_loss: 0.4894\n",
            "Epoch 47/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 381ms/step - accuracy: 0.8960 - loss: 0.4174 - val_accuracy: 0.8429 - val_loss: 0.4980\n",
            "Epoch 48/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 383ms/step - accuracy: 0.8796 - loss: 0.4264 - val_accuracy: 0.8214 - val_loss: 0.5076\n",
            "Epoch 49/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 492ms/step - accuracy: 0.8807 - loss: 0.4184 - val_accuracy: 0.8738 - val_loss: 0.4674\n",
            "Epoch 50/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 384ms/step - accuracy: 0.9030 - loss: 0.3878 - val_accuracy: 0.8762 - val_loss: 0.4533\n",
            "Epoch 51/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 387ms/step - accuracy: 0.9163 - loss: 0.3729 - val_accuracy: 0.8738 - val_loss: 0.4525\n",
            "Epoch 52/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 384ms/step - accuracy: 0.9186 - loss: 0.3654 - val_accuracy: 0.8786 - val_loss: 0.4416\n",
            "Epoch 53/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 380ms/step - accuracy: 0.9171 - loss: 0.3585 - val_accuracy: 0.8857 - val_loss: 0.4269\n",
            "Epoch 54/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 384ms/step - accuracy: 0.9160 - loss: 0.3520 - val_accuracy: 0.8810 - val_loss: 0.4217\n",
            "Epoch 55/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 387ms/step - accuracy: 0.9118 - loss: 0.3532 - val_accuracy: 0.8786 - val_loss: 0.4262\n",
            "Epoch 56/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 384ms/step - accuracy: 0.9039 - loss: 0.3629 - val_accuracy: 0.8762 - val_loss: 0.4327\n",
            "Epoch 57/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 414ms/step - accuracy: 0.8962 - loss: 0.3724 - val_accuracy: 0.8690 - val_loss: 0.4329\n",
            "Epoch 58/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 382ms/step - accuracy: 0.8964 - loss: 0.3769 - val_accuracy: 0.8667 - val_loss: 0.4219\n",
            "Epoch 59/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 381ms/step - accuracy: 0.8936 - loss: 0.3767 - val_accuracy: 0.8762 - val_loss: 0.4067\n",
            "Epoch 60/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 380ms/step - accuracy: 0.8961 - loss: 0.3693 - val_accuracy: 0.8810 - val_loss: 0.4157\n",
            "Epoch 61/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 384ms/step - accuracy: 0.9082 - loss: 0.3476 - val_accuracy: 0.8762 - val_loss: 0.4236\n",
            "Epoch 62/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 382ms/step - accuracy: 0.9221 - loss: 0.3250 - val_accuracy: 0.8881 - val_loss: 0.3828\n",
            "Epoch 63/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 383ms/step - accuracy: 0.9284 - loss: 0.2981 - val_accuracy: 0.8952 - val_loss: 0.3697\n",
            "Epoch 64/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 478ms/step - accuracy: 0.9257 - loss: 0.3035 - val_accuracy: 0.9000 - val_loss: 0.3711\n",
            "Epoch 65/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 391ms/step - accuracy: 0.9331 - loss: 0.3026 - val_accuracy: 0.9071 - val_loss: 0.3527\n",
            "Epoch 66/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 388ms/step - accuracy: 0.9364 - loss: 0.2874 - val_accuracy: 0.8976 - val_loss: 0.3618\n",
            "Epoch 67/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 383ms/step - accuracy: 0.9340 - loss: 0.2873 - val_accuracy: 0.9000 - val_loss: 0.3547\n",
            "Epoch 68/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 385ms/step - accuracy: 0.9327 - loss: 0.2784 - val_accuracy: 0.9071 - val_loss: 0.3395\n",
            "Epoch 69/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 385ms/step - accuracy: 0.9377 - loss: 0.2719 - val_accuracy: 0.9119 - val_loss: 0.3358\n",
            "Epoch 70/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 382ms/step - accuracy: 0.9364 - loss: 0.2754 - val_accuracy: 0.9024 - val_loss: 0.3327\n",
            "Epoch 71/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 384ms/step - accuracy: 0.9326 - loss: 0.2754 - val_accuracy: 0.8976 - val_loss: 0.3333\n",
            "Epoch 72/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 483ms/step - accuracy: 0.9294 - loss: 0.2754 - val_accuracy: 0.9095 - val_loss: 0.3304\n",
            "Epoch 73/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 386ms/step - accuracy: 0.9322 - loss: 0.2703 - val_accuracy: 0.9095 - val_loss: 0.3236\n",
            "Epoch 74/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 382ms/step - accuracy: 0.9364 - loss: 0.2623 - val_accuracy: 0.9071 - val_loss: 0.3189\n",
            "Epoch 75/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 386ms/step - accuracy: 0.9353 - loss: 0.2616 - val_accuracy: 0.9024 - val_loss: 0.3193\n",
            "Epoch 76/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 383ms/step - accuracy: 0.9350 - loss: 0.2653 - val_accuracy: 0.9048 - val_loss: 0.3203\n",
            "Epoch 77/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 384ms/step - accuracy: 0.9361 - loss: 0.2676 - val_accuracy: 0.9024 - val_loss: 0.3217\n",
            "Epoch 78/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 382ms/step - accuracy: 0.9335 - loss: 0.2698 - val_accuracy: 0.9048 - val_loss: 0.3247\n",
            "Epoch 79/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 391ms/step - accuracy: 0.9332 - loss: 0.2699 - val_accuracy: 0.9024 - val_loss: 0.3257\n",
            "Epoch 80/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 406ms/step - accuracy: 0.9363 - loss: 0.2652 - val_accuracy: 0.9071 - val_loss: 0.3209\n",
            "Epoch 81/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 384ms/step - accuracy: 0.9407 - loss: 0.2570 - val_accuracy: 0.9071 - val_loss: 0.3095\n",
            "Epoch 82/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 390ms/step - accuracy: 0.9465 - loss: 0.2465 - val_accuracy: 0.9119 - val_loss: 0.2963\n",
            "Epoch 83/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 381ms/step - accuracy: 0.9510 - loss: 0.2377 - val_accuracy: 0.9286 - val_loss: 0.2879\n",
            "Epoch 84/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 382ms/step - accuracy: 0.9549 - loss: 0.2325 - val_accuracy: 0.9333 - val_loss: 0.2858\n",
            "Epoch 85/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 380ms/step - accuracy: 0.9559 - loss: 0.2291 - val_accuracy: 0.9286 - val_loss: 0.2868\n",
            "Epoch 86/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 386ms/step - accuracy: 0.9555 - loss: 0.2267 - val_accuracy: 0.9214 - val_loss: 0.2874\n",
            "Epoch 87/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 383ms/step - accuracy: 0.9538 - loss: 0.2245 - val_accuracy: 0.9214 - val_loss: 0.2858\n",
            "Epoch 88/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 481ms/step - accuracy: 0.9545 - loss: 0.2218 - val_accuracy: 0.9238 - val_loss: 0.2825\n",
            "Epoch 89/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 410ms/step - accuracy: 0.9529 - loss: 0.2193 - val_accuracy: 0.9310 - val_loss: 0.2784\n",
            "Epoch 90/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 381ms/step - accuracy: 0.9538 - loss: 0.2169 - val_accuracy: 0.9310 - val_loss: 0.2747\n",
            "Epoch 91/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 381ms/step - accuracy: 0.9559 - loss: 0.2149 - val_accuracy: 0.9286 - val_loss: 0.2719\n",
            "Epoch 92/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 383ms/step - accuracy: 0.9551 - loss: 0.2136 - val_accuracy: 0.9286 - val_loss: 0.2697\n",
            "Epoch 93/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 389ms/step - accuracy: 0.9553 - loss: 0.2123 - val_accuracy: 0.9310 - val_loss: 0.2677\n",
            "Epoch 94/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 385ms/step - accuracy: 0.9561 - loss: 0.2108 - val_accuracy: 0.9310 - val_loss: 0.2656\n",
            "Epoch 95/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 383ms/step - accuracy: 0.9557 - loss: 0.2093 - val_accuracy: 0.9310 - val_loss: 0.2636\n",
            "Epoch 96/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 385ms/step - accuracy: 0.9563 - loss: 0.2078 - val_accuracy: 0.9310 - val_loss: 0.2617\n",
            "Epoch 97/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 405ms/step - accuracy: 0.9559 - loss: 0.2063 - val_accuracy: 0.9333 - val_loss: 0.2599\n",
            "Epoch 98/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 494ms/step - accuracy: 0.9558 - loss: 0.2049 - val_accuracy: 0.9333 - val_loss: 0.2582\n",
            "Epoch 99/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 385ms/step - accuracy: 0.9558 - loss: 0.2032 - val_accuracy: 0.9333 - val_loss: 0.2564\n",
            "Epoch 100/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 383ms/step - accuracy: 0.9568 - loss: 0.2013 - val_accuracy: 0.9357 - val_loss: 0.2548\n",
            "\n",
            "========== Running Batch Size 1000 ==========\n",
            "\n",
            "Epoch 1/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1s/step - accuracy: 0.1689 - loss: 1.6986 - val_accuracy: 0.2143 - val_loss: 1.6089\n",
            "Epoch 2/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 329ms/step - accuracy: 0.1867 - loss: 1.6164 - val_accuracy: 0.2143 - val_loss: 1.6094\n",
            "Epoch 3/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 336ms/step - accuracy: 0.2141 - loss: 1.6035 - val_accuracy: 0.2143 - val_loss: 1.5880\n",
            "Epoch 4/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 355ms/step - accuracy: 0.2175 - loss: 1.5849 - val_accuracy: 0.2976 - val_loss: 1.5806\n",
            "Epoch 5/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 326ms/step - accuracy: 0.2773 - loss: 1.5780 - val_accuracy: 0.5714 - val_loss: 1.5748\n",
            "Epoch 6/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 330ms/step - accuracy: 0.5461 - loss: 1.5718 - val_accuracy: 0.5452 - val_loss: 1.5681\n",
            "Epoch 7/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 329ms/step - accuracy: 0.5370 - loss: 1.5645 - val_accuracy: 0.4167 - val_loss: 1.5585\n",
            "Epoch 8/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 326ms/step - accuracy: 0.4173 - loss: 1.5543 - val_accuracy: 0.5595 - val_loss: 1.5472\n",
            "Epoch 9/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 328ms/step - accuracy: 0.5232 - loss: 1.5421 - val_accuracy: 0.3905 - val_loss: 1.5306\n",
            "Epoch 10/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 327ms/step - accuracy: 0.4040 - loss: 1.5247 - val_accuracy: 0.4786 - val_loss: 1.5109\n",
            "Epoch 11/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 344ms/step - accuracy: 0.4842 - loss: 1.5037 - val_accuracy: 0.5548 - val_loss: 1.4849\n",
            "Epoch 12/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 338ms/step - accuracy: 0.5496 - loss: 1.4754 - val_accuracy: 0.5762 - val_loss: 1.4507\n",
            "Epoch 13/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 329ms/step - accuracy: 0.5723 - loss: 1.4379 - val_accuracy: 0.6095 - val_loss: 1.4053\n",
            "Epoch 14/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 330ms/step - accuracy: 0.6302 - loss: 1.3892 - val_accuracy: 0.6381 - val_loss: 1.3479\n",
            "Epoch 15/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 328ms/step - accuracy: 0.6575 - loss: 1.3269 - val_accuracy: 0.6762 - val_loss: 1.2781\n",
            "Epoch 16/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 327ms/step - accuracy: 0.6871 - loss: 1.2499 - val_accuracy: 0.6905 - val_loss: 1.2056\n",
            "Epoch 17/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 339ms/step - accuracy: 0.6959 - loss: 1.1724 - val_accuracy: 0.7000 - val_loss: 1.1218\n",
            "Epoch 18/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 327ms/step - accuracy: 0.6986 - loss: 1.0904 - val_accuracy: 0.6810 - val_loss: 1.0565\n",
            "Epoch 19/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 336ms/step - accuracy: 0.7041 - loss: 1.0081 - val_accuracy: 0.4786 - val_loss: 1.2704\n",
            "Epoch 20/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 428ms/step - accuracy: 0.5450 - loss: 1.1368 - val_accuracy: 0.5143 - val_loss: 1.0514\n",
            "Epoch 21/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 329ms/step - accuracy: 0.5946 - loss: 0.9860 - val_accuracy: 0.6571 - val_loss: 1.0928\n",
            "Epoch 22/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 331ms/step - accuracy: 0.6711 - loss: 0.9907 - val_accuracy: 0.6810 - val_loss: 0.9222\n",
            "Epoch 23/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 328ms/step - accuracy: 0.7061 - loss: 0.8834 - val_accuracy: 0.7167 - val_loss: 0.9014\n",
            "Epoch 24/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 326ms/step - accuracy: 0.7331 - loss: 0.8431 - val_accuracy: 0.7810 - val_loss: 0.8316\n",
            "Epoch 25/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 329ms/step - accuracy: 0.7801 - loss: 0.7831 - val_accuracy: 0.7405 - val_loss: 0.8301\n",
            "Epoch 26/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 329ms/step - accuracy: 0.7633 - loss: 0.7657 - val_accuracy: 0.7595 - val_loss: 0.8079\n",
            "Epoch 27/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 328ms/step - accuracy: 0.7793 - loss: 0.7379 - val_accuracy: 0.7619 - val_loss: 0.7732\n",
            "Epoch 28/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 348ms/step - accuracy: 0.7820 - loss: 0.7143 - val_accuracy: 0.7762 - val_loss: 0.7452\n",
            "Epoch 29/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 329ms/step - accuracy: 0.7985 - loss: 0.6733 - val_accuracy: 0.7643 - val_loss: 0.7564\n",
            "Epoch 30/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 329ms/step - accuracy: 0.7975 - loss: 0.6758 - val_accuracy: 0.7905 - val_loss: 0.7250\n",
            "Epoch 31/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 328ms/step - accuracy: 0.8076 - loss: 0.6518 - val_accuracy: 0.8214 - val_loss: 0.7062\n",
            "Epoch 32/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 327ms/step - accuracy: 0.8266 - loss: 0.6367 - val_accuracy: 0.8286 - val_loss: 0.7032\n",
            "Epoch 33/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 328ms/step - accuracy: 0.8345 - loss: 0.6122 - val_accuracy: 0.8143 - val_loss: 0.6719\n",
            "Epoch 34/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 332ms/step - accuracy: 0.8258 - loss: 0.5883 - val_accuracy: 0.8071 - val_loss: 0.6656\n",
            "Epoch 35/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 330ms/step - accuracy: 0.8331 - loss: 0.5748 - val_accuracy: 0.8119 - val_loss: 0.6572\n",
            "Epoch 36/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 436ms/step - accuracy: 0.8377 - loss: 0.5710 - val_accuracy: 0.8381 - val_loss: 0.6273\n",
            "Epoch 37/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 331ms/step - accuracy: 0.8522 - loss: 0.5589 - val_accuracy: 0.8119 - val_loss: 0.6453\n",
            "Epoch 38/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 331ms/step - accuracy: 0.8384 - loss: 0.5695 - val_accuracy: 0.8190 - val_loss: 0.6555\n",
            "Epoch 39/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 331ms/step - accuracy: 0.8473 - loss: 0.5468 - val_accuracy: 0.8119 - val_loss: 0.6221\n",
            "Epoch 40/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 330ms/step - accuracy: 0.8473 - loss: 0.5263 - val_accuracy: 0.8190 - val_loss: 0.5967\n",
            "Epoch 41/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 330ms/step - accuracy: 0.8634 - loss: 0.5054 - val_accuracy: 0.8238 - val_loss: 0.5825\n",
            "Epoch 42/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 335ms/step - accuracy: 0.8610 - loss: 0.4935 - val_accuracy: 0.8524 - val_loss: 0.5761\n",
            "Epoch 43/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 329ms/step - accuracy: 0.8689 - loss: 0.4939 - val_accuracy: 0.8571 - val_loss: 0.5575\n",
            "Epoch 44/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 343ms/step - accuracy: 0.8744 - loss: 0.4792 - val_accuracy: 0.8619 - val_loss: 0.5525\n",
            "Epoch 45/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 439ms/step - accuracy: 0.8740 - loss: 0.4672 - val_accuracy: 0.8524 - val_loss: 0.5463\n",
            "Epoch 46/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 328ms/step - accuracy: 0.8726 - loss: 0.4645 - val_accuracy: 0.8548 - val_loss: 0.5364\n",
            "Epoch 47/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 329ms/step - accuracy: 0.8743 - loss: 0.4691 - val_accuracy: 0.8643 - val_loss: 0.5481\n",
            "Epoch 48/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 322ms/step - accuracy: 0.8675 - loss: 0.4899 - val_accuracy: 0.8452 - val_loss: 0.6181\n",
            "Epoch 49/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 330ms/step - accuracy: 0.8521 - loss: 0.5240 - val_accuracy: 0.7976 - val_loss: 0.6361\n",
            "Epoch 50/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 331ms/step - accuracy: 0.8356 - loss: 0.5147 - val_accuracy: 0.7857 - val_loss: 0.6431\n",
            "Epoch 51/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 328ms/step - accuracy: 0.8526 - loss: 0.5028 - val_accuracy: 0.8690 - val_loss: 0.5091\n",
            "Epoch 52/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 333ms/step - accuracy: 0.8958 - loss: 0.4448 - val_accuracy: 0.8429 - val_loss: 0.5132\n",
            "Epoch 53/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 352ms/step - accuracy: 0.8822 - loss: 0.4391 - val_accuracy: 0.8500 - val_loss: 0.4907\n",
            "Epoch 54/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 336ms/step - accuracy: 0.8969 - loss: 0.4011 - val_accuracy: 0.8762 - val_loss: 0.4792\n",
            "Epoch 55/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 331ms/step - accuracy: 0.9070 - loss: 0.3969 - val_accuracy: 0.8905 - val_loss: 0.4684\n",
            "Epoch 56/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 328ms/step - accuracy: 0.9201 - loss: 0.3817 - val_accuracy: 0.8738 - val_loss: 0.4508\n",
            "Epoch 57/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 327ms/step - accuracy: 0.9180 - loss: 0.3724 - val_accuracy: 0.8690 - val_loss: 0.4518\n",
            "Epoch 58/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 328ms/step - accuracy: 0.9076 - loss: 0.3689 - val_accuracy: 0.8833 - val_loss: 0.4303\n",
            "Epoch 59/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 332ms/step - accuracy: 0.9170 - loss: 0.3563 - val_accuracy: 0.8952 - val_loss: 0.4291\n",
            "Epoch 60/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 337ms/step - accuracy: 0.9246 - loss: 0.3487 - val_accuracy: 0.8881 - val_loss: 0.4203\n",
            "Epoch 61/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 330ms/step - accuracy: 0.9285 - loss: 0.3412 - val_accuracy: 0.8810 - val_loss: 0.4222\n",
            "Epoch 62/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 362ms/step - accuracy: 0.9269 - loss: 0.3353 - val_accuracy: 0.8905 - val_loss: 0.4106\n",
            "Epoch 63/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 334ms/step - accuracy: 0.9263 - loss: 0.3282 - val_accuracy: 0.8952 - val_loss: 0.4007\n",
            "Epoch 64/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 327ms/step - accuracy: 0.9282 - loss: 0.3242 - val_accuracy: 0.8905 - val_loss: 0.3917\n",
            "Epoch 65/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 332ms/step - accuracy: 0.9317 - loss: 0.3197 - val_accuracy: 0.8881 - val_loss: 0.3911\n",
            "Epoch 66/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 331ms/step - accuracy: 0.9280 - loss: 0.3205 - val_accuracy: 0.8810 - val_loss: 0.3931\n",
            "Epoch 67/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 329ms/step - accuracy: 0.9213 - loss: 0.3269 - val_accuracy: 0.8810 - val_loss: 0.4004\n",
            "Epoch 68/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 331ms/step - accuracy: 0.9142 - loss: 0.3438 - val_accuracy: 0.8548 - val_loss: 0.4374\n",
            "Epoch 69/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 337ms/step - accuracy: 0.8922 - loss: 0.3935 - val_accuracy: 0.8310 - val_loss: 0.4999\n",
            "Epoch 70/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 331ms/step - accuracy: 0.8699 - loss: 0.4364 - val_accuracy: 0.8595 - val_loss: 0.4304\n",
            "Epoch 71/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 435ms/step - accuracy: 0.9085 - loss: 0.3448 - val_accuracy: 0.9000 - val_loss: 0.3753\n",
            "Epoch 72/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 332ms/step - accuracy: 0.9269 - loss: 0.3042 - val_accuracy: 0.9000 - val_loss: 0.4159\n",
            "Epoch 73/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 332ms/step - accuracy: 0.9261 - loss: 0.3111 - val_accuracy: 0.9143 - val_loss: 0.3738\n",
            "Epoch 74/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 329ms/step - accuracy: 0.9367 - loss: 0.2933 - val_accuracy: 0.9048 - val_loss: 0.3443\n",
            "Epoch 75/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 334ms/step - accuracy: 0.9421 - loss: 0.2885 - val_accuracy: 0.8881 - val_loss: 0.3601\n",
            "Epoch 76/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 329ms/step - accuracy: 0.9335 - loss: 0.2909 - val_accuracy: 0.8952 - val_loss: 0.3554\n",
            "Epoch 77/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 330ms/step - accuracy: 0.9366 - loss: 0.2747 - val_accuracy: 0.9167 - val_loss: 0.3372\n",
            "Epoch 78/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 329ms/step - accuracy: 0.9421 - loss: 0.2653 - val_accuracy: 0.9119 - val_loss: 0.3337\n",
            "Epoch 79/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 370ms/step - accuracy: 0.9485 - loss: 0.2636 - val_accuracy: 0.9167 - val_loss: 0.3254\n",
            "Epoch 80/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 330ms/step - accuracy: 0.9519 - loss: 0.2574 - val_accuracy: 0.9143 - val_loss: 0.3317\n",
            "Epoch 81/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 329ms/step - accuracy: 0.9460 - loss: 0.2610 - val_accuracy: 0.9071 - val_loss: 0.3237\n",
            "Epoch 82/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 329ms/step - accuracy: 0.9446 - loss: 0.2572 - val_accuracy: 0.9143 - val_loss: 0.3144\n",
            "Epoch 83/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 329ms/step - accuracy: 0.9487 - loss: 0.2499 - val_accuracy: 0.9167 - val_loss: 0.3110\n",
            "Epoch 84/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 332ms/step - accuracy: 0.9520 - loss: 0.2432 - val_accuracy: 0.9167 - val_loss: 0.3105\n",
            "Epoch 85/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 330ms/step - accuracy: 0.9542 - loss: 0.2400 - val_accuracy: 0.9167 - val_loss: 0.3046\n",
            "Epoch 86/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 336ms/step - accuracy: 0.9524 - loss: 0.2375 - val_accuracy: 0.9190 - val_loss: 0.3001\n",
            "Epoch 87/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 349ms/step - accuracy: 0.9523 - loss: 0.2384 - val_accuracy: 0.9238 - val_loss: 0.3026\n",
            "Epoch 88/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 333ms/step - accuracy: 0.9508 - loss: 0.2432 - val_accuracy: 0.9190 - val_loss: 0.3122\n",
            "Epoch 89/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 331ms/step - accuracy: 0.9421 - loss: 0.2565 - val_accuracy: 0.9024 - val_loss: 0.3329\n",
            "Epoch 90/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 330ms/step - accuracy: 0.9327 - loss: 0.2871 - val_accuracy: 0.8810 - val_loss: 0.3932\n",
            "Epoch 91/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 329ms/step - accuracy: 0.8789 - loss: 0.3799 - val_accuracy: 0.8571 - val_loss: 0.4884\n",
            "Epoch 92/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 332ms/step - accuracy: 0.8222 - loss: 0.5080 - val_accuracy: 0.7952 - val_loss: 0.5929\n",
            "Epoch 93/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 328ms/step - accuracy: 0.8132 - loss: 0.5226 - val_accuracy: 0.8238 - val_loss: 0.4847\n",
            "Epoch 94/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 331ms/step - accuracy: 0.8929 - loss: 0.3608 - val_accuracy: 0.9190 - val_loss: 0.3287\n",
            "Epoch 95/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 330ms/step - accuracy: 0.9232 - loss: 0.2766 - val_accuracy: 0.8738 - val_loss: 0.4426\n",
            "Epoch 96/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 444ms/step - accuracy: 0.9239 - loss: 0.3166 - val_accuracy: 0.9119 - val_loss: 0.3217\n",
            "Epoch 97/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 326ms/step - accuracy: 0.9405 - loss: 0.2609 - val_accuracy: 0.9048 - val_loss: 0.3120\n",
            "Epoch 98/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 331ms/step - accuracy: 0.9459 - loss: 0.2382 - val_accuracy: 0.9286 - val_loss: 0.2966\n",
            "Epoch 99/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 332ms/step - accuracy: 0.9580 - loss: 0.2241 - val_accuracy: 0.9095 - val_loss: 0.3088\n",
            "Epoch 100/100\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 329ms/step - accuracy: 0.9481 - loss: 0.2297 - val_accuracy: 0.9286 - val_loss: 0.2899\n",
            "\n",
            "========== Running Batch Size 1500 ==========\n",
            "\n",
            "Epoch 1/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 3s/step - accuracy: 0.2014 - loss: 1.6524 - val_accuracy: 0.2143 - val_loss: 1.6279\n",
            "Epoch 2/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 436ms/step - accuracy: 0.2101 - loss: 1.6232 - val_accuracy: 0.2143 - val_loss: 1.5965\n",
            "Epoch 3/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 442ms/step - accuracy: 0.2126 - loss: 1.5977 - val_accuracy: 0.2143 - val_loss: 1.6024\n",
            "Epoch 4/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 436ms/step - accuracy: 0.2142 - loss: 1.6009 - val_accuracy: 0.2238 - val_loss: 1.5883\n",
            "Epoch 5/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 437ms/step - accuracy: 0.2372 - loss: 1.5878 - val_accuracy: 0.2381 - val_loss: 1.5815\n",
            "Epoch 6/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 473ms/step - accuracy: 0.2537 - loss: 1.5807 - val_accuracy: 0.4548 - val_loss: 1.5702\n",
            "Epoch 7/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 648ms/step - accuracy: 0.3952 - loss: 1.5695 - val_accuracy: 0.2310 - val_loss: 1.5622\n",
            "Epoch 8/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 438ms/step - accuracy: 0.2324 - loss: 1.5605 - val_accuracy: 0.5143 - val_loss: 1.5508\n",
            "Epoch 9/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 435ms/step - accuracy: 0.5343 - loss: 1.5485 - val_accuracy: 0.4833 - val_loss: 1.5393\n",
            "Epoch 10/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 438ms/step - accuracy: 0.4532 - loss: 1.5372 - val_accuracy: 0.5071 - val_loss: 1.5254\n",
            "Epoch 11/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 440ms/step - accuracy: 0.4999 - loss: 1.5226 - val_accuracy: 0.5548 - val_loss: 1.5084\n",
            "Epoch 12/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 435ms/step - accuracy: 0.5610 - loss: 1.5048 - val_accuracy: 0.5548 - val_loss: 1.4876\n",
            "Epoch 13/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 437ms/step - accuracy: 0.5665 - loss: 1.4832 - val_accuracy: 0.5405 - val_loss: 1.4642\n",
            "Epoch 14/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 443ms/step - accuracy: 0.5515 - loss: 1.4589 - val_accuracy: 0.5571 - val_loss: 1.4355\n",
            "Epoch 15/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 473ms/step - accuracy: 0.5666 - loss: 1.4293 - val_accuracy: 0.5786 - val_loss: 1.4023\n",
            "Epoch 16/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 442ms/step - accuracy: 0.5827 - loss: 1.3943 - val_accuracy: 0.5643 - val_loss: 1.3653\n",
            "Epoch 17/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 444ms/step - accuracy: 0.5756 - loss: 1.3561 - val_accuracy: 0.5833 - val_loss: 1.3217\n",
            "Epoch 18/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 444ms/step - accuracy: 0.5846 - loss: 1.3107 - val_accuracy: 0.5738 - val_loss: 1.2766\n",
            "Epoch 19/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 437ms/step - accuracy: 0.5823 - loss: 1.2644 - val_accuracy: 0.5881 - val_loss: 1.2295\n",
            "Epoch 20/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 437ms/step - accuracy: 0.5916 - loss: 1.2144 - val_accuracy: 0.5833 - val_loss: 1.1784\n",
            "Epoch 21/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 438ms/step - accuracy: 0.5886 - loss: 1.1628 - val_accuracy: 0.5857 - val_loss: 1.1299\n",
            "Epoch 22/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 441ms/step - accuracy: 0.5970 - loss: 1.1118 - val_accuracy: 0.5905 - val_loss: 1.0847\n",
            "Epoch 23/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 438ms/step - accuracy: 0.6077 - loss: 1.0658 - val_accuracy: 0.6000 - val_loss: 1.0715\n",
            "Epoch 24/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 436ms/step - accuracy: 0.6228 - loss: 1.0395 - val_accuracy: 0.6333 - val_loss: 0.9957\n",
            "Epoch 25/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 452ms/step - accuracy: 0.6410 - loss: 0.9731 - val_accuracy: 0.6024 - val_loss: 0.9788\n",
            "Epoch 26/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 440ms/step - accuracy: 0.6105 - loss: 0.9592 - val_accuracy: 0.6000 - val_loss: 0.9542\n",
            "Epoch 27/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 443ms/step - accuracy: 0.6188 - loss: 0.9175 - val_accuracy: 0.6452 - val_loss: 0.9170\n",
            "Epoch 28/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 454ms/step - accuracy: 0.6501 - loss: 0.8830 - val_accuracy: 0.6119 - val_loss: 0.9123\n",
            "Epoch 29/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 438ms/step - accuracy: 0.6271 - loss: 0.8757 - val_accuracy: 0.6381 - val_loss: 0.8562\n",
            "Epoch 30/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 438ms/step - accuracy: 0.6646 - loss: 0.8235 - val_accuracy: 0.6357 - val_loss: 0.8381\n",
            "Epoch 31/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 640ms/step - accuracy: 0.6718 - loss: 0.8039 - val_accuracy: 0.6190 - val_loss: 0.8591\n",
            "Epoch 32/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 441ms/step - accuracy: 0.6436 - loss: 0.8096 - val_accuracy: 0.6571 - val_loss: 0.8038\n",
            "Epoch 33/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 447ms/step - accuracy: 0.6845 - loss: 0.7683 - val_accuracy: 0.6595 - val_loss: 0.7854\n",
            "Epoch 34/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 436ms/step - accuracy: 0.6748 - loss: 0.7490 - val_accuracy: 0.6571 - val_loss: 0.8051\n",
            "Epoch 35/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 442ms/step - accuracy: 0.6690 - loss: 0.7545 - val_accuracy: 0.6857 - val_loss: 0.7582\n",
            "Epoch 36/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 435ms/step - accuracy: 0.7075 - loss: 0.7171 - val_accuracy: 0.6905 - val_loss: 0.7439\n",
            "Epoch 37/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 445ms/step - accuracy: 0.7100 - loss: 0.6966 - val_accuracy: 0.7167 - val_loss: 0.7450\n",
            "Epoch 38/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 447ms/step - accuracy: 0.7270 - loss: 0.6858 - val_accuracy: 0.7214 - val_loss: 0.7108\n",
            "Epoch 39/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 635ms/step - accuracy: 0.7477 - loss: 0.6661 - val_accuracy: 0.6952 - val_loss: 0.7124\n",
            "Epoch 40/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 438ms/step - accuracy: 0.7162 - loss: 0.6767 - val_accuracy: 0.6786 - val_loss: 0.7288\n",
            "Epoch 41/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 437ms/step - accuracy: 0.7108 - loss: 0.6760 - val_accuracy: 0.7548 - val_loss: 0.6853\n",
            "Epoch 42/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 438ms/step - accuracy: 0.7651 - loss: 0.6326 - val_accuracy: 0.7476 - val_loss: 0.6867\n",
            "Epoch 43/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 439ms/step - accuracy: 0.7656 - loss: 0.6286 - val_accuracy: 0.7238 - val_loss: 0.6691\n",
            "Epoch 44/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 440ms/step - accuracy: 0.7473 - loss: 0.6155 - val_accuracy: 0.7690 - val_loss: 0.6486\n",
            "Epoch 45/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 435ms/step - accuracy: 0.7836 - loss: 0.5969 - val_accuracy: 0.7500 - val_loss: 0.6457\n",
            "Epoch 46/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 438ms/step - accuracy: 0.7708 - loss: 0.5908 - val_accuracy: 0.7571 - val_loss: 0.6329\n",
            "Epoch 47/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 649ms/step - accuracy: 0.7870 - loss: 0.5715 - val_accuracy: 0.7976 - val_loss: 0.6076\n",
            "Epoch 48/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 438ms/step - accuracy: 0.8117 - loss: 0.5550 - val_accuracy: 0.7738 - val_loss: 0.6038\n",
            "Epoch 49/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 444ms/step - accuracy: 0.7927 - loss: 0.5549 - val_accuracy: 0.7738 - val_loss: 0.5984\n",
            "Epoch 50/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 441ms/step - accuracy: 0.8014 - loss: 0.5385 - val_accuracy: 0.8071 - val_loss: 0.5753\n",
            "Epoch 51/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 441ms/step - accuracy: 0.8337 - loss: 0.5167 - val_accuracy: 0.8024 - val_loss: 0.5613\n",
            "Epoch 52/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 437ms/step - accuracy: 0.8207 - loss: 0.5097 - val_accuracy: 0.7738 - val_loss: 0.5832\n",
            "Epoch 53/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 444ms/step - accuracy: 0.7972 - loss: 0.5255 - val_accuracy: 0.8167 - val_loss: 0.5332\n",
            "Epoch 54/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 440ms/step - accuracy: 0.8479 - loss: 0.4823 - val_accuracy: 0.8190 - val_loss: 0.5244\n",
            "Epoch 55/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 634ms/step - accuracy: 0.8538 - loss: 0.4749 - val_accuracy: 0.8024 - val_loss: 0.5307\n",
            "Epoch 56/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 439ms/step - accuracy: 0.8237 - loss: 0.4876 - val_accuracy: 0.8167 - val_loss: 0.5192\n",
            "Epoch 57/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 445ms/step - accuracy: 0.8423 - loss: 0.4647 - val_accuracy: 0.8333 - val_loss: 0.5026\n",
            "Epoch 58/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 438ms/step - accuracy: 0.8633 - loss: 0.4391 - val_accuracy: 0.8143 - val_loss: 0.5411\n",
            "Epoch 59/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 438ms/step - accuracy: 0.8448 - loss: 0.4657 - val_accuracy: 0.7905 - val_loss: 0.5913\n",
            "Epoch 60/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 436ms/step - accuracy: 0.8203 - loss: 0.4954 - val_accuracy: 0.8524 - val_loss: 0.4694\n",
            "Epoch 61/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 441ms/step - accuracy: 0.8714 - loss: 0.4290 - val_accuracy: 0.8619 - val_loss: 0.4666\n",
            "Epoch 62/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 437ms/step - accuracy: 0.8788 - loss: 0.4180 - val_accuracy: 0.8238 - val_loss: 0.4994\n",
            "Epoch 63/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 440ms/step - accuracy: 0.8525 - loss: 0.4238 - val_accuracy: 0.8619 - val_loss: 0.4375\n",
            "Epoch 64/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 439ms/step - accuracy: 0.8917 - loss: 0.3791 - val_accuracy: 0.8690 - val_loss: 0.4303\n",
            "Epoch 65/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 437ms/step - accuracy: 0.8937 - loss: 0.3807 - val_accuracy: 0.8262 - val_loss: 0.4473\n",
            "Epoch 66/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 442ms/step - accuracy: 0.8626 - loss: 0.3948 - val_accuracy: 0.8452 - val_loss: 0.4277\n",
            "Epoch 67/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 439ms/step - accuracy: 0.8857 - loss: 0.3663 - val_accuracy: 0.8810 - val_loss: 0.4013\n",
            "Epoch 68/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 434ms/step - accuracy: 0.9102 - loss: 0.3428 - val_accuracy: 0.8857 - val_loss: 0.3897\n",
            "Epoch 69/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 443ms/step - accuracy: 0.9122 - loss: 0.3373 - val_accuracy: 0.8500 - val_loss: 0.4171\n",
            "Epoch 70/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 467ms/step - accuracy: 0.8772 - loss: 0.3644 - val_accuracy: 0.8429 - val_loss: 0.4330\n",
            "Epoch 71/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 519ms/step - accuracy: 0.8833 - loss: 0.3608 - val_accuracy: 0.8833 - val_loss: 0.3761\n",
            "Epoch 72/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 437ms/step - accuracy: 0.9205 - loss: 0.3140 - val_accuracy: 0.9000 - val_loss: 0.3623\n",
            "Epoch 73/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 435ms/step - accuracy: 0.9259 - loss: 0.3055 - val_accuracy: 0.8810 - val_loss: 0.3796\n",
            "Epoch 74/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 441ms/step - accuracy: 0.8974 - loss: 0.3298 - val_accuracy: 0.9071 - val_loss: 0.3599\n",
            "Epoch 75/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 440ms/step - accuracy: 0.9187 - loss: 0.3055 - val_accuracy: 0.9095 - val_loss: 0.3468\n",
            "Epoch 76/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 436ms/step - accuracy: 0.9319 - loss: 0.2921 - val_accuracy: 0.9167 - val_loss: 0.3400\n",
            "Epoch 77/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 440ms/step - accuracy: 0.9297 - loss: 0.2891 - val_accuracy: 0.9143 - val_loss: 0.3425\n",
            "Epoch 78/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 435ms/step - accuracy: 0.9242 - loss: 0.2898 - val_accuracy: 0.9143 - val_loss: 0.3254\n",
            "Epoch 79/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 490ms/step - accuracy: 0.9407 - loss: 0.2639 - val_accuracy: 0.8976 - val_loss: 0.3411\n",
            "Epoch 80/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 442ms/step - accuracy: 0.9316 - loss: 0.2715 - val_accuracy: 0.9000 - val_loss: 0.3405\n",
            "Epoch 81/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 437ms/step - accuracy: 0.9287 - loss: 0.2661 - val_accuracy: 0.9238 - val_loss: 0.3104\n",
            "Epoch 82/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 439ms/step - accuracy: 0.9414 - loss: 0.2521 - val_accuracy: 0.9310 - val_loss: 0.3031\n",
            "Epoch 83/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 436ms/step - accuracy: 0.9414 - loss: 0.2479 - val_accuracy: 0.9262 - val_loss: 0.2932\n",
            "Epoch 84/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 437ms/step - accuracy: 0.9479 - loss: 0.2325 - val_accuracy: 0.9238 - val_loss: 0.2957\n",
            "Epoch 85/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 441ms/step - accuracy: 0.9462 - loss: 0.2338 - val_accuracy: 0.9167 - val_loss: 0.3032\n",
            "Epoch 86/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 439ms/step - accuracy: 0.9436 - loss: 0.2303 - val_accuracy: 0.9310 - val_loss: 0.2727\n",
            "Epoch 87/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 479ms/step - accuracy: 0.9541 - loss: 0.2122 - val_accuracy: 0.9357 - val_loss: 0.2741\n",
            "Epoch 88/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 523ms/step - accuracy: 0.9499 - loss: 0.2167 - val_accuracy: 0.9333 - val_loss: 0.2726\n",
            "Epoch 89/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 450ms/step - accuracy: 0.9505 - loss: 0.2125 - val_accuracy: 0.9333 - val_loss: 0.2583\n",
            "Epoch 90/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 439ms/step - accuracy: 0.9581 - loss: 0.1968 - val_accuracy: 0.9333 - val_loss: 0.2609\n",
            "Epoch 91/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 445ms/step - accuracy: 0.9561 - loss: 0.1967 - val_accuracy: 0.9333 - val_loss: 0.2688\n",
            "Epoch 92/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 443ms/step - accuracy: 0.9538 - loss: 0.2008 - val_accuracy: 0.9381 - val_loss: 0.2469\n",
            "Epoch 93/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 443ms/step - accuracy: 0.9602 - loss: 0.1842 - val_accuracy: 0.9381 - val_loss: 0.2439\n",
            "Epoch 94/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 435ms/step - accuracy: 0.9603 - loss: 0.1826 - val_accuracy: 0.9357 - val_loss: 0.2440\n",
            "Epoch 95/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 496ms/step - accuracy: 0.9606 - loss: 0.1814 - val_accuracy: 0.9452 - val_loss: 0.2349\n",
            "Epoch 96/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 466ms/step - accuracy: 0.9648 - loss: 0.1731 - val_accuracy: 0.9357 - val_loss: 0.2504\n",
            "Epoch 97/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 436ms/step - accuracy: 0.9509 - loss: 0.1919 - val_accuracy: 0.9238 - val_loss: 0.2639\n",
            "Epoch 98/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 447ms/step - accuracy: 0.9404 - loss: 0.2060 - val_accuracy: 0.9214 - val_loss: 0.3038\n",
            "Epoch 99/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 456ms/step - accuracy: 0.9350 - loss: 0.2294 - val_accuracy: 0.9286 - val_loss: 0.2506\n",
            "Epoch 100/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 440ms/step - accuracy: 0.9569 - loss: 0.1810 - val_accuracy: 0.9476 - val_loss: 0.2245\n",
            "   Batch Size  Avg Val Acc (%)  Avg Val Loss  Final Test Acc (%)\n",
            "0         100        90.814286      0.276758           95.476190\n",
            "1         250        88.773809      0.355201           97.619048\n",
            "2         500        85.845238      0.454171           97.142857\n",
            "3         750        79.152381      0.642692           93.571429\n",
            "4        1000        78.550000      0.685279           92.857143\n",
            "5        1500        73.880952      0.717547           94.761905\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}